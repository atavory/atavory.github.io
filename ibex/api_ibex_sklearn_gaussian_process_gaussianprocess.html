
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>GaussianProcess &#8212; ibex latest documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     'latest',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/logo.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="gaussianprocess">
<h1><code class="docutils literal"><span class="pre">GaussianProcess</span></code><a class="headerlink" href="#gaussianprocess" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="ibex.sklearn.gaussian_process.GaussianProcess">
<em class="property">class </em><code class="descclassname">ibex.sklearn.gaussian_process.</code><code class="descname">GaussianProcess</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.gaussian_process.GaussianProcess" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.gaussian_process.gaussian_process.GaussianProcess</span></code>, <code class="xref py py-class docutils literal"><span class="pre">ibex._base.FrameMixin</span></code></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>The legacy Gaussian Process model class.</p>
<blockquote>
<div><div class="deprecated">
<p><span class="versionmodified">Deprecated since version 0.18: </span>This class will be removed in 0.20.
Use the <code class="xref py py-class docutils literal"><span class="pre">GaussianProcessRegressor</span></code> instead.</p>
</div>
<p>Read more in the <a class="reference external" href="http://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process" title="(in scikit-learn v0.19.1)"><span class="xref std std-ref">User Guide</span></a>.</p>
<dl class="docutils">
<dt>regr <span class="classifier-delimiter">:</span> <span class="classifier">string or callable, optional</span></dt>
<dd><p class="first">A regression function returning an array of outputs of the linear
regression functional basis. The number of observations n_samples
should be greater than the size p of this basis.
Default assumes a simple constant regression trend.
Available built-in regression models are:</p>
<div class="last highlight-default"><div class="highlight"><pre><span></span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;quadratic&#39;</span>
</pre></div>
</div>
</dd>
<dt>corr <span class="classifier-delimiter">:</span> <span class="classifier">string or callable, optional</span></dt>
<dd><p class="first">A stationary autocorrelation function returning the autocorrelation
between two points x and x’.
Default assumes a squared-exponential autocorrelation model.
Built-in correlation models are:</p>
<div class="last highlight-default"><div class="highlight"><pre><span></span><span class="s1">&#39;absolute_exponential&#39;</span><span class="p">,</span> <span class="s1">&#39;squared_exponential&#39;</span><span class="p">,</span>
<span class="s1">&#39;generalized_exponential&#39;</span><span class="p">,</span> <span class="s1">&#39;cubic&#39;</span><span class="p">,</span> <span class="s1">&#39;linear&#39;</span>
</pre></div>
</div>
</dd>
<dt>beta0 <span class="classifier-delimiter">:</span> <span class="classifier">double array_like, optional</span></dt>
<dd>The regression weight vector to perform Ordinary Kriging (OK).
Default assumes Universal Kriging (UK) so that the vector beta of
regression weights is estimated using the maximum likelihood
principle.</dd>
<dt>storage_mode <span class="classifier-delimiter">:</span> <span class="classifier">string, optional</span></dt>
<dd>A string specifying whether the Cholesky decomposition of the
correlation matrix should be stored in the class (storage_mode =
‘full’) or not (storage_mode = ‘light’).
Default assumes storage_mode = ‘full’, so that the
Cholesky decomposition of the correlation matrix is stored.
This might be a useful parameter when one is not interested in the
MSE and only plan to estimate the BLUP, for which the correlation
matrix is not required.</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">boolean, optional</span></dt>
<dd>A boolean specifying the verbose level.
Default is verbose = False.</dd>
<dt>theta0 <span class="classifier-delimiter">:</span> <span class="classifier">double array_like, optional</span></dt>
<dd>An array with shape (n_features, ) or (1, ).
The parameters in the autocorrelation model.
If thetaL and thetaU are also specified, theta0 is considered as
the starting point for the maximum likelihood estimation of the
best set of parameters.
Default assumes isotropic autocorrelation model with theta0 = 1e-1.</dd>
<dt>thetaL <span class="classifier-delimiter">:</span> <span class="classifier">double array_like, optional</span></dt>
<dd>An array with shape matching theta0’s.
Lower bound on the autocorrelation parameters for maximum
likelihood estimation.
Default is None, so that it skips maximum likelihood estimation and
it uses theta0.</dd>
<dt>thetaU <span class="classifier-delimiter">:</span> <span class="classifier">double array_like, optional</span></dt>
<dd>An array with shape matching theta0’s.
Upper bound on the autocorrelation parameters for maximum
likelihood estimation.
Default is None, so that it skips maximum likelihood estimation and
it uses theta0.</dd>
<dt>normalize <span class="classifier-delimiter">:</span> <span class="classifier">boolean, optional</span></dt>
<dd>Input X and observations y are centered and reduced wrt
means and standard deviations estimated from the n_samples
observations provided.
Default is normalize = True so that data is normalized to ease
maximum likelihood estimation.</dd>
<dt>nugget <span class="classifier-delimiter">:</span> <span class="classifier">double or ndarray, optional</span></dt>
<dd>Introduce a nugget effect to allow smooth predictions from noisy
data.  If nugget is an ndarray, it must be the same length as the
number of data points used for the fit.
The nugget is added to the diagonal of the assumed training covariance;
in this way it acts as a Tikhonov regularization in the problem.  In
the special case of the squared exponential correlation function, the
nugget mathematically represents the variance of the input values.
Default assumes a nugget close to machine precision for the sake of
robustness (nugget = 10. * MACHINE_EPSILON).</dd>
<dt>optimizer <span class="classifier-delimiter">:</span> <span class="classifier">string, optional</span></dt>
<dd><p class="first">A string specifying the optimization algorithm to be used.
Default uses ‘fmin_cobyla’ algorithm from scipy.optimize.
Available optimizers are:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="s1">&#39;fmin_cobyla&#39;</span><span class="p">,</span> <span class="s1">&#39;Welch&#39;</span>
</pre></div>
</div>
<p class="last">‘Welch’ optimizer is dued to Welch et al., see reference <a class="reference internal" href="#wbswm1992" id="id1">[WBSWM1992]</a>.
It consists in iterating over several one-dimensional optimizations
instead of running one single multi-dimensional optimization.</p>
</dd>
<dt>random_start <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd>The number of times the Maximum Likelihood Estimation should be
performed from a random starting point.
The first MLE always uses the specified starting point (theta0),
the next starting points are picked at random according to an
exponential distribution (log-uniform on [thetaL, thetaU]).
Default does not use random starting point (random_start = 1).</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional (default=None)</span></dt>
<dd>The generator used to shuffle the sequence of coordinates of theta in
the Welch optimizer. If int, random_state is the seed used by the
random number generator; If RandomState instance, random_state is the
random number generator; If None, the random number generator is the
RandomState instance used by <cite>np.random</cite>.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id3"><span class="problematic" id="id4">theta_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd>Specified theta OR the best set of autocorrelation parameters (the         sought maximizer of the reduced likelihood function).</dd>
<dt><a href="#id5"><span class="problematic" id="id6">reduced_likelihood_function_value_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd>The optimal reduced likelihood function value.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.gaussian_process</span> <span class="k">import</span> <span class="n">GaussianProcess</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">))</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span> <span class="o">=</span> <span class="n">GaussianProcess</span><span class="p">(</span><span class="n">theta0</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">thetaL</span><span class="o">=.</span><span class="mi">001</span><span class="p">,</span> <span class="n">thetaU</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>                                      
<span class="go">GaussianProcess(beta0=None...</span>
<span class="go">        ...</span>
</pre></div>
</div>
<p>The presentation implementation is based on a translation of the DACE
Matlab toolbox, see reference <a class="reference internal" href="#nlns2002" id="id2">[NLNS2002]</a>.</p>
<table class="docutils citation" frame="void" id="nlns2002" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[NLNS2002]</a></td><td><cite>H.B. Nielsen, S.N. Lophaven, H. B. Nielsen and J.
Sondergaard.  DACE - A MATLAB Kriging Toolbox.</cite> (2002)
<a class="reference external" href="http://imedea.uib-csic.es/master/cambioglobal/Modulo_V_cod101615/Lab/lab_maps/krigging/DACE-krigingsoft/dace/dace.pdf">http://imedea.uib-csic.es/master/cambioglobal/Modulo_V_cod101615/Lab/lab_maps/krigging/DACE-krigingsoft/dace/dace.pdf</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="wbswm1992" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[WBSWM1992]</a></td><td><cite>W.J. Welch, R.J. Buck, J. Sacks, H.P. Wynn, T.J. Mitchell,
and M.D.  Morris (1992). Screening, predicting, and computer
experiments.  Technometrics, 34(1) 15–25.</cite>
<a class="reference external" href="http://www.jstor.org/stable/1269548">http://www.jstor.org/stable/1269548</a></td></tr>
</tbody>
</table>
</div></blockquote>
<dl class="method">
<dt id="ibex.sklearn.gaussian_process.GaussianProcess.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/gaussian_process/gaussian_process.html#GaussianProcess.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.gaussian_process.GaussianProcess.fit" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<blockquote>
<div><p>The Gaussian Process model fitting method.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">double array_like</span></dt>
<dd>An array with shape (n_samples, n_features) with the input at which
observations were made.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">double array_like</span></dt>
<dd>An array with shape (n_samples, ) or shape (n_samples, n_targets)
with the observations of the output to be predicted.</dd>
</dl>
<dl class="docutils">
<dt>gp <span class="classifier-delimiter">:</span> <span class="classifier">self</span></dt>
<dd>A fitted Gaussian Process model object awaiting data to perform
predictions.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.gaussian_process.GaussianProcess.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>eval_MSE=False</em>, <em>batch_size=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/gaussian_process/gaussian_process.html#GaussianProcess.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.gaussian_process.GaussianProcess.predict" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<blockquote>
<div><p>This function evaluates the Gaussian Process model at x.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd>An array with shape (n_eval, n_features) giving the point(s) at
which the prediction(s) should be made.</dd>
<dt>eval_MSE <span class="classifier-delimiter">:</span> <span class="classifier">boolean, optional</span></dt>
<dd>A boolean specifying whether the Mean Squared Error should be
evaluated or not.
Default assumes evalMSE = False and evaluates only the BLUP (mean
prediction).</dd>
<dt>batch_size <span class="classifier-delimiter">:</span> <span class="classifier">integer, optional</span></dt>
<dd>An integer giving the maximum number of points that can be
evaluated simultaneously (depending on the available memory).
Default is None so that all given points are evaluated at the same
time.</dd>
</dl>
<dl class="docutils">
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array_like, shape (n_samples, ) or (n_samples, n_targets)</span></dt>
<dd>An array with shape (n_eval, ) if the Gaussian Process was trained
on an array of shape (n_samples, ) or an array with shape
(n_eval, n_targets) if the Gaussian Process was trained on an array
of shape (n_samples, n_targets) with the Best Linear Unbiased
Prediction at x.</dd>
<dt>MSE <span class="classifier-delimiter">:</span> <span class="classifier">array_like, optional (if eval_MSE == True)</span></dt>
<dd>An array with shape (n_eval, ) or (n_eval, n_targets) as with y,
with the Mean Squared Error at x.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.gaussian_process.GaussianProcess.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>x</em>, <em>y</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.gaussian_process.GaussianProcess.score" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Returns the coefficient of determination R^2 of the prediction.</p>
<blockquote>
<div><p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) ** 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) ** 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, n_features)</span></dt>
<dd>Test samples.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples) or (n_samples, n_outputs)</span></dt>
<dd>True values for X.</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples], optional</span></dt>
<dd>Sample weights.</dd>
</dl>
<dl class="docutils">
<dt>score <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>R^2 of self.predict(X) wrt. y.</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.jpeg" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Ibex</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="frame_adapter.html">Adapting Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="input_verification_and_output_processing.html">Verification and Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_transformer.html">Transforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipelines.html">Pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_union.html">Uniting Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="sklearn.html"><code class="docutils literal"><span class="pre">sklearn</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorflow.html"><code class="docutils literal"><span class="pre">tensorflow</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost.html"><code class="docutils literal"><span class="pre">xgboost</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="extending.html">Extending</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/api_ibex_sklearn_gaussian_process_gaussianprocess.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Ami Tavory, Shahar Azulay, Tali Raveh-Sadka.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/api_ibex_sklearn_gaussian_process_gaussianprocess.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/atavory/ibex" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>