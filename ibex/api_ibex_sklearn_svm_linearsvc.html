
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>LinearSVC &#8212; ibex latest documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     'latest',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/logo.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="linearsvc">
<h1><code class="docutils literal"><span class="pre">LinearSVC</span></code><a class="headerlink" href="#linearsvc" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="ibex.sklearn.svm.LinearSVC">
<em class="property">class </em><code class="descclassname">ibex.sklearn.svm.</code><code class="descname">LinearSVC</code><span class="sig-paren">(</span><em>penalty='l2'</em>, <em>loss='squared_hinge'</em>, <em>dual=True</em>, <em>tol=0.0001</em>, <em>C=1.0</em>, <em>multi_class='ovr'</em>, <em>fit_intercept=True</em>, <em>intercept_scaling=1</em>, <em>class_weight=None</em>, <em>verbose=0</em>, <em>random_state=None</em>, <em>max_iter=1000</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.svm.LinearSVC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.svm.classes.LinearSVC</span></code>, <code class="xref py py-class docutils literal"><span class="pre">ibex._base.FrameMixin</span></code></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Linear Support Vector Classification.</p>
<blockquote>
<div><p>Similar to SVC with parameter kernel=’linear’, but implemented in terms of
liblinear rather than libsvm, so it has more flexibility in the choice of
penalties and loss functions and should scale better to large numbers of
samples.</p>
<p>This class supports both dense and sparse input and the multiclass support
is handled according to a one-vs-the-rest scheme.</p>
<p>Read more in the <a class="reference external" href="http://scikit-learn.org/stable/modules/svm.html#svm-classification" title="(in scikit-learn v0.19.1)"><span class="xref std std-ref">User Guide</span></a>.</p>
<dl class="docutils">
<dt>penalty <span class="classifier-delimiter">:</span> <span class="classifier">string, ‘l1’ or ‘l2’ (default=’l2’)</span></dt>
<dd>Specifies the norm used in the penalization. The ‘l2’
penalty is the standard used in SVC. The ‘l1’ leads to <code class="docutils literal"><span class="pre">coef_</span></code>
vectors that are sparse.</dd>
<dt>loss <span class="classifier-delimiter">:</span> <span class="classifier">string, ‘hinge’ or ‘squared_hinge’ (default=’squared_hinge’)</span></dt>
<dd>Specifies the loss function. ‘hinge’ is the standard SVM loss
(used e.g. by the SVC class) while ‘squared_hinge’ is the
square of the hinge loss.</dd>
<dt>dual <span class="classifier-delimiter">:</span> <span class="classifier">bool, (default=True)</span></dt>
<dd>Select the algorithm to either solve the dual or primal
optimization problem. Prefer dual=False when n_samples &gt; n_features.</dd>
<dt>tol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional (default=1e-4)</span></dt>
<dd>Tolerance for stopping criteria.</dd>
<dt>C <span class="classifier-delimiter">:</span> <span class="classifier">float, optional (default=1.0)</span></dt>
<dd>Penalty parameter C of the error term.</dd>
<dt>multi_class <span class="classifier-delimiter">:</span> <span class="classifier">string, ‘ovr’ or ‘crammer_singer’ (default=’ovr’)</span></dt>
<dd>Determines the multi-class strategy if <cite>y</cite> contains more than
two classes.
<code class="docutils literal"><span class="pre">&quot;ovr&quot;</span></code> trains n_classes one-vs-rest classifiers, while
<code class="docutils literal"><span class="pre">&quot;crammer_singer&quot;</span></code> optimizes a joint objective over all classes.
While <cite>crammer_singer</cite> is interesting from a theoretical perspective
as it is consistent, it is seldom used in practice as it rarely leads
to better accuracy and is more expensive to compute.
If <code class="docutils literal"><span class="pre">&quot;crammer_singer&quot;</span></code> is chosen, the options loss, penalty and dual
will be ignored.</dd>
<dt>fit_intercept <span class="classifier-delimiter">:</span> <span class="classifier">boolean, optional (default=True)</span></dt>
<dd>Whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(i.e. data is expected to be already centered).</dd>
<dt>intercept_scaling <span class="classifier-delimiter">:</span> <span class="classifier">float, optional (default=1)</span></dt>
<dd>When self.fit_intercept is True, instance vector x becomes
<code class="docutils literal"><span class="pre">[x,</span> <span class="pre">self.intercept_scaling]</span></code>,
i.e. a “synthetic” feature with constant value equals to
intercept_scaling is appended to the instance vector.
The intercept becomes intercept_scaling * synthetic feature weight
Note! the synthetic feature weight is subject to l1/l2 regularization
as all other features.
To lessen the effect of regularization on synthetic feature weight
(and therefore on the intercept) intercept_scaling has to be increased.</dd>
<dt>class_weight <span class="classifier-delimiter">:</span> <span class="classifier">{dict, ‘balanced’}, optional</span></dt>
<dd>Set the parameter C of class i to <code class="docutils literal"><span class="pre">class_weight[i]*C</span></code> for
SVC. If not given, all classes are supposed to have
weight one.
The “balanced” mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code class="docutils literal"><span class="pre">n_samples</span> <span class="pre">/</span> <span class="pre">(n_classes</span> <span class="pre">*</span> <span class="pre">np.bincount(y))</span></code></dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">int, (default=0)</span></dt>
<dd>Enable verbose output. Note that this setting takes advantage of a
per-process runtime setting in liblinear that, if enabled, may not work
properly in a multithreaded context.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional (default=None)</span></dt>
<dd>The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <cite>np.random</cite>.</dd>
<dt>max_iter <span class="classifier-delimiter">:</span> <span class="classifier">int, (default=1000)</span></dt>
<dd>The maximum number of iterations to be run.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id1"><span class="problematic" id="id2">coef_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = [n_features] if n_classes == 2 else [n_classes, n_features]</span></dt>
<dd><p class="first">Weights assigned to the features (coefficients in the primal
problem). This is only available in the case of a linear kernel.</p>
<p class="last"><code class="docutils literal"><span class="pre">coef_</span></code> is a readonly property derived from <code class="docutils literal"><span class="pre">raw_coef_</span></code> that
follows the internal memory layout of liblinear.</p>
</dd>
<dt><a href="#id3"><span class="problematic" id="id4">intercept_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = [1] if n_classes == 2 else [n_classes]</span></dt>
<dd>Constants in decision function.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="k">import</span> <span class="n">LinearSVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,</span>
<span class="go">     intercept_scaling=1, loss=&#39;squared_hinge&#39;, max_iter=1000,</span>
<span class="go">     multi_class=&#39;ovr&#39;, penalty=&#39;l2&#39;, random_state=0, tol=0.0001,</span>
<span class="go">     verbose=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="go">[[ 0.08551385  0.39414796  0.49847831  0.37513797]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="go">[ 0.28418066]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
<span class="go">[1]</span>
</pre></div>
</div>
<p>The underlying C implementation uses a random number generator to
select features when fitting the model. It is thus not uncommon
to have slightly different results for the same input data. If
that happens, try with a smaller <code class="docutils literal"><span class="pre">tol</span></code> parameter.</p>
<p>The underlying implementation, liblinear, uses a sparse internal
representation for the data that will incur a memory copy.</p>
<p>Predict output may not match that of standalone liblinear in certain
cases. See <a class="reference external" href="http://scikit-learn.org/stable/modules/linear_model.html#liblinear-differences" title="(in scikit-learn v0.19.1)"><span class="xref std std-ref">differences from liblinear</span></a>
in the narrative documentation.</p>
<p><a class="reference external" href="http://www.csie.ntu.edu.tw/~cjlin/liblinear/">LIBLINEAR: A Library for Large Linear Classification</a></p>
<dl class="docutils">
<dt>SVC</dt>
<dd><p class="first">Implementation of Support Vector Machine classifier using libsvm:
the kernel can be non-linear but its SMO algorithm does not
scale to large number of samples as LinearSVC does.</p>
<p>Furthermore SVC multi-class mode is implemented using one
vs one scheme while LinearSVC uses one vs the rest. It is
possible to implement one vs the rest with SVC by using the
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier" title="(in scikit-learn v0.19.1)"><code class="xref py py-class docutils literal"><span class="pre">sklearn.multiclass.OneVsRestClassifier</span></code></a> wrapper.</p>
<p class="last">Finally SVC can fit dense data without memory copy if the input
is C-contiguous. Sparse data will still incur memory copy though.</p>
</dd>
<dt>sklearn.linear_model.SGDClassifier</dt>
<dd>SGDClassifier can optimize the same cost function as LinearSVC
by adjusting the penalty and loss parameters. In addition it requires
less memory, allows incremental (online) learning, and implements
various loss functions and regularization regimes.</dd>
</dl>
</div></blockquote>
<dl class="method">
<dt id="ibex.sklearn.svm.LinearSVC.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.svm.LinearSVC.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Predict confidence scores for samples.</p>
<blockquote>
<div><p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = (n_samples, n_features)</span></dt>
<dd>Samples.</dd>
</dl>
<dl class="docutils">
<dt>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)</dt>
<dd>Confidence scores per (sample, class) combination. In the binary
case, confidence score for self.classes_[1] where &gt;0 means this
class would be predicted.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.svm.LinearSVC.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/svm/classes.html#LinearSVC.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.svm.LinearSVC.fit" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Fit the model according to the given training data.</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vector, where n_samples in the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target vector relative to X</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples], optional</span></dt>
<dd>Array of weights that are assigned to individual
samples. If not provided,
then each sample is given unit weight.</dd>
</dl>
<dl class="docutils">
<dt>self <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd>Returns self.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.svm.LinearSVC.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.svm.LinearSVC.predict" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Predict class labels for samples in X.</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Samples.</dd>
</dl>
<dl class="docutils">
<dt>C <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = [n_samples]</span></dt>
<dd>Predicted class label per sample.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.svm.LinearSVC.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>x</em>, <em>y</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.svm.LinearSVC.score" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Returns the mean accuracy on the given test data and labels.</p>
<blockquote>
<div><p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, n_features)</span></dt>
<dd>Test samples.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples) or (n_samples, n_outputs)</span></dt>
<dd>True labels for X.</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples], optional</span></dt>
<dd>Sample weights.</dd>
</dl>
<dl class="docutils">
<dt>score <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Mean accuracy of self.predict(X) wrt. y.</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.jpeg" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Ibex</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="frame_adapter.html">Adapting Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="input_verification_and_output_processing.html">Verification and Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_transformer.html">Transforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipelines.html">Pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_union.html">Uniting Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="sklearn.html"><code class="docutils literal"><span class="pre">sklearn</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorflow.html"><code class="docutils literal"><span class="pre">tensorflow</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost.html"><code class="docutils literal"><span class="pre">xgboost</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="extending.html">Extending</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/api_ibex_sklearn_svm_linearsvc.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Ami Tavory, Shahar Azulay, Tali Raveh-Sadka.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/api_ibex_sklearn_svm_linearsvc.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/atavory/ibex" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>