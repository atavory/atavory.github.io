
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>SGDRegressor &#8212; ibex latest documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     'latest',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/logo.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="sgdregressor">
<h1><code class="docutils literal"><span class="pre">SGDRegressor</span></code><a class="headerlink" href="#sgdregressor" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="ibex.sklearn.linear_model.SGDRegressor">
<em class="property">class </em><code class="descclassname">ibex.sklearn.linear_model.</code><code class="descname">SGDRegressor</code><span class="sig-paren">(</span><em>loss='squared_loss'</em>, <em>penalty='l2'</em>, <em>alpha=0.0001</em>, <em>l1_ratio=0.15</em>, <em>fit_intercept=True</em>, <em>max_iter=None</em>, <em>tol=None</em>, <em>shuffle=True</em>, <em>verbose=0</em>, <em>epsilon=0.1</em>, <em>random_state=None</em>, <em>learning_rate='invscaling'</em>, <em>eta0=0.01</em>, <em>power_t=0.25</em>, <em>warm_start=False</em>, <em>average=False</em>, <em>n_iter=None</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.linear_model.SGDRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.linear_model.stochastic_gradient.SGDRegressor</span></code>, <code class="xref py py-class docutils literal"><span class="pre">ibex._base.FrameMixin</span></code></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Linear model fitted by minimizing a regularized empirical loss with SGD</p>
<blockquote>
<div><p>SGD stands for Stochastic Gradient Descent: the gradient of the loss is
estimated each sample at a time and the model is updated along the way with
a decreasing strength schedule (aka learning rate).</p>
<p>The regularizer is a penalty added to the loss function that shrinks model
parameters towards the zero vector using either the squared euclidean norm
L2 or the absolute norm L1 or a combination of both (Elastic Net). If the
parameter update crosses the 0.0 value because of the regularizer, the
update is truncated to 0.0 to allow for learning sparse models and achieve
online feature selection.</p>
<p>This implementation works with data represented as dense numpy arrays of
floating point values for the features.</p>
<p>Read more in the <a class="reference external" href="http://scikit-learn.org/stable/modules/sgd.html#sgd" title="(in scikit-learn v0.19.1)"><span class="xref std std-ref">User Guide</span></a>.</p>
<dl class="docutils">
<dt>loss <span class="classifier-delimiter">:</span> <span class="classifier">str, default: ‘squared_loss’</span></dt>
<dd><p class="first">The loss function to be used. The possible values are ‘squared_loss’,
‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’</p>
<p class="last">The ‘squared_loss’ refers to the ordinary least squares fit.
‘huber’ modifies ‘squared_loss’ to focus less on getting outliers
correct by switching from squared to linear loss past a distance of
epsilon. ‘epsilon_insensitive’ ignores errors less than epsilon and is
linear past that; this is the loss function used in SVR.
‘squared_epsilon_insensitive’ is the same but becomes squared loss past
a tolerance of epsilon.</p>
</dd>
<dt>penalty <span class="classifier-delimiter">:</span> <span class="classifier">str, ‘none’, ‘l2’, ‘l1’, or ‘elasticnet’</span></dt>
<dd>The penalty (aka regularization term) to be used. Defaults to ‘l2’
which is the standard regularizer for linear SVM models. ‘l1’ and
‘elasticnet’ might bring sparsity to the model (feature selection)
not achievable with ‘l2’.</dd>
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Constant that multiplies the regularization term. Defaults to 0.0001
Also used to compute learning_rate when set to ‘optimal’.</dd>
<dt>l1_ratio <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The Elastic Net mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.
l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.
Defaults to 0.15.</dd>
<dt>fit_intercept <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>Whether the intercept should be estimated or not. If False, the
data is assumed to be already centered. Defaults to True.</dd>
<dt>max_iter <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first">The maximum number of passes over the training data (aka epochs).
It only impacts the behavior in the <code class="docutils literal"><span class="pre">fit</span></code> method, and not the
<cite>partial_fit</cite>.
Defaults to 5. Defaults to 1000 from 0.21, or if tol is not None.</p>
<div class="last versionadded">
<p><span class="versionmodified">New in version 0.19.</span></p>
</div>
</dd>
<dt>tol <span class="classifier-delimiter">:</span> <span class="classifier">float or None, optional</span></dt>
<dd><p class="first">The stopping criterion. If it is not None, the iterations will stop
when (loss &gt; previous_loss - tol). Defaults to None.
Defaults to 1e-3 from 0.21.</p>
<div class="last versionadded">
<p><span class="versionmodified">New in version 0.19.</span></p>
</div>
</dd>
<dt>shuffle <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd>Whether or not the training data should be shuffled after each epoch.
Defaults to True.</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">integer, optional</span></dt>
<dd>The verbosity level.</dd>
<dt>epsilon <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Epsilon in the epsilon-insensitive loss functions; only if <cite>loss</cite> is
‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’.
For ‘huber’, determines the threshold at which it becomes less
important to get the prediction exactly right.
For epsilon-insensitive, any differences between the current prediction
and the correct label are ignored if they are less than this threshold.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional (default=None)</span></dt>
<dd>The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <cite>np.random</cite>.</dd>
<dt>learning_rate <span class="classifier-delimiter">:</span> <span class="classifier">string, optional</span></dt>
<dd><p class="first">The learning rate schedule:</p>
<ul class="simple">
<li>‘constant’: eta = eta0</li>
<li>‘optimal’: eta = 1.0 / (alpha * (t + t0)) [default]</li>
<li>‘invscaling’: eta = eta0 / pow(t, power_t)</li>
</ul>
<p class="last">where t0 is chosen by a heuristic proposed by Leon Bottou.</p>
</dd>
<dt>eta0 <span class="classifier-delimiter">:</span> <span class="classifier">double, optional</span></dt>
<dd>The initial learning rate [default 0.01].</dd>
<dt>power_t <span class="classifier-delimiter">:</span> <span class="classifier">double, optional</span></dt>
<dd>The exponent for inverse scaling learning rate [default 0.25].</dd>
<dt>warm_start <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd>When set to True, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.</dd>
<dt>average <span class="classifier-delimiter">:</span> <span class="classifier">bool or int, optional</span></dt>
<dd>When set to True, computes the averaged SGD weights and stores the
result in the <code class="docutils literal"><span class="pre">coef_</span></code> attribute. If set to an int greater than 1,
averaging will begin once the total number of samples seen reaches
average. So <code class="docutils literal"><span class="pre">average=10</span></code> will begin averaging after seeing 10
samples.</dd>
<dt>n_iter <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first">The number of passes over the training data (aka epochs).
Defaults to None. Deprecated, will be removed in 0.21.</p>
<div class="last versionchanged">
<p><span class="versionmodified">Changed in version 0.19: </span>Deprecated</p>
</div>
</dd>
</dl>
<dl class="docutils">
<dt><a href="#id1"><span class="problematic" id="id2">coef_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_features,)</span></dt>
<dd>Weights assigned to the features.</dd>
<dt><a href="#id3"><span class="problematic" id="id4">intercept_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (1,)</span></dt>
<dd>The intercept term.</dd>
<dt><a href="#id5"><span class="problematic" id="id6">average_coef_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_features,)</span></dt>
<dd>Averaged weights assigned to the features.</dd>
<dt><a href="#id7"><span class="problematic" id="id8">average_intercept_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (1,)</span></dt>
<dd>The averaged intercept term.</dd>
<dt><a href="#id9"><span class="problematic" id="id10">n_iter_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>The actual number of iterations to reach the stopping criterion.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">linear_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">SGDRegressor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">... </span>
<span class="go">SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,</span>
<span class="go">       fit_intercept=True, l1_ratio=0.15, learning_rate=&#39;invscaling&#39;,</span>
<span class="go">       loss=&#39;squared_loss&#39;, max_iter=5, n_iter=None, penalty=&#39;l2&#39;,</span>
<span class="go">       power_t=0.25, random_state=None, shuffle=True, tol=None,</span>
<span class="go">       verbose=0, warm_start=False)</span>
</pre></div>
</div>
<p>Ridge, ElasticNet, Lasso, SVR</p>
</div></blockquote>
<dl class="method">
<dt id="ibex.sklearn.linear_model.SGDRegressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>coef_init=None</em>, <em>intercept_init=None</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.linear_model.SGDRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Fit linear model with Stochastic Gradient Descent.</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape (n_samples, n_features)</span></dt>
<dd>Training data</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">numpy array, shape (n_samples,)</span></dt>
<dd>Target values</dd>
<dt>coef_init <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_features,)</span></dt>
<dd>The initial coefficients to warm-start the optimization.</dd>
<dt>intercept_init <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (1,)</span></dt>
<dd>The initial intercept to warm-start the optimization.</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (n_samples,), optional</span></dt>
<dd>Weights applied to individual samples (1. for unweighted).</dd>
</dl>
<p>self : returns an instance of self.</p>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.linear_model.SGDRegressor.partial_fit">
<code class="descname">partial_fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.linear_model.SGDRegressor.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Fit linear model with Stochastic Gradient Descent.</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape (n_samples, n_features)</span></dt>
<dd>Subset of training data</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">numpy array of shape (n_samples,)</span></dt>
<dd>Subset of target values</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (n_samples,), optional</span></dt>
<dd>Weights applied to individual samples.
If not provided, uniform weights are assumed.</dd>
</dl>
<p>self : returns an instance of self.</p>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.linear_model.SGDRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.linear_model.SGDRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Predict using the linear model</p>
<blockquote>
<div><p>X : {array-like, sparse matrix}, shape (n_samples, n_features)</p>
<dl class="docutils">
<dt>array, shape (n_samples,)</dt>
<dd>Predicted target values per element in X.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.linear_model.SGDRegressor.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>x</em>, <em>y</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.linear_model.SGDRegressor.score" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Returns the coefficient of determination R^2 of the prediction.</p>
<blockquote>
<div><p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) ** 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) ** 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, n_features)</span></dt>
<dd>Test samples.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples) or (n_samples, n_outputs)</span></dt>
<dd>True values for X.</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples], optional</span></dt>
<dd>Sample weights.</dd>
</dl>
<dl class="docutils">
<dt>score <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>R^2 of self.predict(X) wrt. y.</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.jpeg" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Ibex</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="frame_adapter.html">Adapting Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="input_verification_and_output_processing.html">Verification and Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_transformer.html">Transforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipelines.html">Pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_union.html">Uniting Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="sklearn.html"><code class="docutils literal"><span class="pre">sklearn</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorflow.html"><code class="docutils literal"><span class="pre">tensorflow</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost.html"><code class="docutils literal"><span class="pre">xgboost</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="extending.html">Extending</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/api_ibex_sklearn_linear_model_sgdregressor.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Ami Tavory, Shahar Azulay, Tali Raveh-Sadka.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/api_ibex_sklearn_linear_model_sgdregressor.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/atavory/ibex" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>