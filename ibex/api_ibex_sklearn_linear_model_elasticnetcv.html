
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>ElasticNetCV &#8212; ibex latest documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     'latest',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/logo.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="elasticnetcv">
<h1><code class="docutils literal"><span class="pre">ElasticNetCV</span></code><a class="headerlink" href="#elasticnetcv" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="ibex.sklearn.linear_model.ElasticNetCV">
<em class="property">class </em><code class="descclassname">ibex.sklearn.linear_model.</code><code class="descname">ElasticNetCV</code><span class="sig-paren">(</span><em>l1_ratio=0.5</em>, <em>eps=0.001</em>, <em>n_alphas=100</em>, <em>alphas=None</em>, <em>fit_intercept=True</em>, <em>normalize=False</em>, <em>precompute='auto'</em>, <em>max_iter=1000</em>, <em>tol=0.0001</em>, <em>cv=None</em>, <em>copy_X=True</em>, <em>verbose=0</em>, <em>n_jobs=1</em>, <em>positive=False</em>, <em>random_state=None</em>, <em>selection='cyclic'</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.linear_model.ElasticNetCV" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.linear_model.coordinate_descent.ElasticNetCV</span></code>, <code class="xref py py-class docutils literal"><span class="pre">ibex._base.FrameMixin</span></code></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. This class wraps the attribute <code class="docutils literal"><span class="pre">intercept_</span></code>
Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ibex.sklearn</span> <span class="k">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ibex.sklearn.linear_model</span> <span class="k">import</span> <span class="n">LinearRegression</span> <span class="k">as</span> <span class="n">PdLinearRegression</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">features</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">iris</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">],</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]],</span>
<span class="gp">... </span>    <span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="o">+</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="go">sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)</span>
<span class="go">0                5.1               3.5                1.4               0.2</span>
<span class="go">1                4.9               3.0                1.4               0.2</span>
<span class="go">2                4.7               3.2                1.3               0.2</span>
<span class="go">3                4.6               3.1                1.5               0.2</span>
<span class="go">4                5.0               3.6                1.4               0.2</span>
<span class="gp">...</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">prd</span> <span class="o">=</span>  <span class="n">PdLinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prd</span><span class="o">.</span><span class="n">coef_</span>
<span class="go">sepal length (cm)   -0.109741</span>
<span class="go">sepal width (cm)    -0.044240</span>
<span class="go">petal length (cm)    0.227001</span>
<span class="go">petal width (cm)     0.609894</span>
<span class="go">dtype: float64</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prd</span><span class="o">.</span><span class="n">intercept_</span>
<span class="go">0.19208...</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ibex.sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span> <span class="k">as</span> <span class="n">PdLogisticRegression</span>
</pre></div>
</div>
<div class="last highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span>  <span class="n">PdLogisticRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">coef_</span>
<span class="go">sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)</span>
<span class="go">0...           0.414988          1.461297          -2.262141         -1.029095</span>
<span class="go">1...           0.416640         -1.600833           0.577658         -1.385538</span>
<span class="go">2...          -1.707525         -1.534268           2.470972          2.555382</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">intercept_</span>
<span class="go">0    0.265606</span>
<span class="go">1    1.085424</span>
<span class="go">2   -1.214715</span>
<span class="go">dtype: float64</span>
</pre></div>
</div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. This class wraps the attribute <code class="docutils literal"><span class="pre">coef_</span></code>
Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ibex.sklearn</span> <span class="k">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ibex.sklearn.linear_model</span> <span class="k">import</span> <span class="n">LinearRegression</span> <span class="k">as</span> <span class="n">PdLinearRegression</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">features</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">iris</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">],</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]],</span>
<span class="gp">... </span>    <span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="o">+</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="go">sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)</span>
<span class="go">0                5.1               3.5                1.4               0.2</span>
<span class="go">1                4.9               3.0                1.4               0.2</span>
<span class="go">2                4.7               3.2                1.3               0.2</span>
<span class="go">3                4.6               3.1                1.5               0.2</span>
<span class="go">4                5.0               3.6                1.4               0.2</span>
<span class="gp">...</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">prd</span> <span class="o">=</span>  <span class="n">PdLinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prd</span><span class="o">.</span><span class="n">coef_</span>
<span class="go">sepal length (cm)   -0.109741</span>
<span class="go">sepal width (cm)    -0.044240</span>
<span class="go">petal length (cm)    0.227001</span>
<span class="go">petal width (cm)     0.609894</span>
<span class="go">dtype: float64</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prd</span><span class="o">.</span><span class="n">intercept_</span>
<span class="go">0.19208...</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ibex.sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span> <span class="k">as</span> <span class="n">PdLogisticRegression</span>
</pre></div>
</div>
<div class="last highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span>  <span class="n">PdLogisticRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">coef_</span>
<span class="go">sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)</span>
<span class="go">0...           0.414988          1.461297          -2.262141         -1.029095</span>
<span class="go">1...           0.416640         -1.600833           0.577658         -1.385538</span>
<span class="go">2...          -1.707525         -1.534268           2.470972          2.555382</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">intercept_</span>
<span class="go">0    0.265606</span>
<span class="go">1    1.085424</span>
<span class="go">2   -1.214715</span>
<span class="go">dtype: float64</span>
</pre></div>
</div>
</div>
<p>Elastic Net model with iterative fitting along a regularization path</p>
<blockquote>
<div><p>The best model is selected by cross-validation.</p>
<p>Read more in the <a class="reference external" href="http://scikit-learn.org/stable/modules/linear_model.html#elastic-net" title="(in scikit-learn v0.19.1)"><span class="xref std std-ref">User Guide</span></a>.</p>
<dl class="docutils">
<dt>l1_ratio <span class="classifier-delimiter">:</span> <span class="classifier">float or array of floats, optional</span></dt>
<dd>float between 0 and 1 passed to ElasticNet (scaling between
l1 and l2 penalties). For <code class="docutils literal"><span class="pre">l1_ratio</span> <span class="pre">=</span> <span class="pre">0</span></code>
the penalty is an L2 penalty. For <code class="docutils literal"><span class="pre">l1_ratio</span> <span class="pre">=</span> <span class="pre">1</span></code> it is an L1 penalty.
For <code class="docutils literal"><span class="pre">0</span> <span class="pre">&lt;</span> <span class="pre">l1_ratio</span> <span class="pre">&lt;</span> <span class="pre">1</span></code>, the penalty is a combination of L1 and L2
This parameter can be a list, in which case the different
values are tested by cross-validation and the one giving the best
prediction score is used. Note that a good choice of list of
values for l1_ratio is often to put more values close to 1
(i.e. Lasso) and less close to 0 (i.e. Ridge), as in <code class="docutils literal"><span class="pre">[.1,</span> <span class="pre">.5,</span> <span class="pre">.7,</span>
<span class="pre">.9,</span> <span class="pre">.95,</span> <span class="pre">.99,</span> <span class="pre">1]</span></code></dd>
<dt>eps <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd>Length of the path. <code class="docutils literal"><span class="pre">eps=1e-3</span></code> means that
<code class="docutils literal"><span class="pre">alpha_min</span> <span class="pre">/</span> <span class="pre">alpha_max</span> <span class="pre">=</span> <span class="pre">1e-3</span></code>.</dd>
<dt>n_alphas <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd>Number of alphas along the regularization path, used for each l1_ratio.</dd>
<dt>alphas <span class="classifier-delimiter">:</span> <span class="classifier">numpy array, optional</span></dt>
<dd>List of alphas where to compute the models.
If None alphas are set automatically</dd>
<dt>fit_intercept <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd>whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(e.g. data is expected to be already centered).</dd>
<dt>normalize <span class="classifier-delimiter">:</span> <span class="classifier">boolean, optional, default False</span></dt>
<dd>This parameter is ignored when <code class="docutils literal"><span class="pre">fit_intercept</span></code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="(in scikit-learn v0.19.1)"><code class="xref py py-class docutils literal"><span class="pre">sklearn.preprocessing.StandardScaler</span></code></a> before calling <code class="docutils literal"><span class="pre">fit</span></code>
on an estimator with <code class="docutils literal"><span class="pre">normalize=False</span></code>.</dd>
<dt>precompute <span class="classifier-delimiter">:</span> <span class="classifier">True | False | ‘auto’ | array-like</span></dt>
<dd>Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code class="docutils literal"><span class="pre">'auto'</span></code> let us decide. The Gram
matrix can also be passed as argument.</dd>
<dt>max_iter <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd>The maximum number of iterations</dd>
<dt>tol <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd>The tolerance for the optimization: if the updates are
smaller than <code class="docutils literal"><span class="pre">tol</span></code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code class="docutils literal"><span class="pre">tol</span></code>.</dd>
<dt>cv <span class="classifier-delimiter">:</span> <span class="classifier">int, cross-validation generator or an iterable, optional</span></dt>
<dd><p class="first">Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul class="simple">
<li>None, to use the default 3-fold cross-validation,</li>
<li>integer, to specify the number of folds.</li>
<li>An object to be used as a cross-validation generator.</li>
<li>An iterable yielding train/test splits.</li>
</ul>
<p>For integer/None inputs, <code class="xref py py-class docutils literal"><span class="pre">KFold</span></code> is used.</p>
<p class="last">Refer <a class="reference external" href="http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation" title="(in scikit-learn v0.19.1)"><span class="xref std std-ref">User Guide</span></a> for the various
cross-validation strategies that can be used here.</p>
</dd>
<dt>copy_X <span class="classifier-delimiter">:</span> <span class="classifier">boolean, optional, default True</span></dt>
<dd>If <code class="docutils literal"><span class="pre">True</span></code>, X will be copied; else, it may be overwritten.</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">bool or integer</span></dt>
<dd>Amount of verbosity.</dd>
<dt>n_jobs <span class="classifier-delimiter">:</span> <span class="classifier">integer, optional</span></dt>
<dd>Number of CPUs to use during the cross validation. If <code class="docutils literal"><span class="pre">-1</span></code>, use
all the CPUs.</dd>
<dt>positive <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd>When set to <code class="docutils literal"><span class="pre">True</span></code>, forces the coefficients to be positive.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional, default None</span></dt>
<dd>The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <cite>np.random</cite>. Used when <code class="docutils literal"><span class="pre">selection</span></code> ==
‘random’.</dd>
<dt>selection <span class="classifier-delimiter">:</span> <span class="classifier">str, default ‘cyclic’</span></dt>
<dd>If set to ‘random’, a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to ‘random’) often leads to significantly faster convergence
especially when tol is higher than 1e-4.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id1"><span class="problematic" id="id2">alpha_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The amount of penalization chosen by cross validation</dd>
<dt><a href="#id3"><span class="problematic" id="id4">l1_ratio_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The compromise between l1 and l2 penalization chosen by
cross validation</dd>
<dt><a href="#id5"><span class="problematic" id="id6">coef_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_features,) | (n_targets, n_features)</span></dt>
<dd>Parameter vector (w in the cost function formula),</dd>
<dt><a href="#id7"><span class="problematic" id="id8">intercept_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">float | array, shape (n_targets, n_features)</span></dt>
<dd>Independent term in the decision function.</dd>
<dt><a href="#id9"><span class="problematic" id="id10">mse_path_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_l1_ratio, n_alpha, n_folds)</span></dt>
<dd>Mean square error for the test set on each fold, varying l1_ratio and
alpha.</dd>
<dt><a href="#id11"><span class="problematic" id="id12">alphas_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">numpy array, shape (n_alphas,) or (n_l1_ratio, n_alphas)</span></dt>
<dd>The grid of alphas used for fitting, for each l1_ratio.</dd>
<dt><a href="#id13"><span class="problematic" id="id14">n_iter_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>number of iterations run by the coordinate descent solver to reach
the specified tolerance for the optimal alpha.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">ElasticNetCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">make_regression</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span> <span class="o">=</span> <span class="n">ElasticNetCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">ElasticNetCV(alphas=None, copy_X=True, cv=5, eps=0.001, fit_intercept=True,</span>
<span class="go">       l1_ratio=0.5, max_iter=1000, n_alphas=100, n_jobs=1,</span>
<span class="go">       normalize=False, positive=False, precompute=&#39;auto&#39;, random_state=0,</span>
<span class="go">       selection=&#39;cyclic&#39;, tol=0.0001, verbose=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">alpha_</span><span class="p">)</span> 
<span class="go">0.19947279427</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span> 
<span class="go">0.398882965428</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span> 
<span class="go">[ 0.39888297]</span>
</pre></div>
</div>
<p>For an example, see
<a class="reference external" href="http://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py" title="(in scikit-learn v0.19.1)"><span class="xref std std-ref">examples/linear_model/plot_lasso_model_selection.py</span></a>.</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<p>The parameter l1_ratio corresponds to alpha in the glmnet R package
while alpha corresponds to the lambda parameter in glmnet.
More specifically, the optimization objective is:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="o">||</span><span class="n">y</span> <span class="o">-</span> <span class="n">Xw</span><span class="o">||^</span><span class="mi">2</span><span class="n">_2</span>
<span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">l1_ratio</span> <span class="o">*</span> <span class="o">||</span><span class="n">w</span><span class="o">||</span><span class="n">_1</span>
<span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">l1_ratio</span><span class="p">)</span> <span class="o">*</span> <span class="o">||</span><span class="n">w</span><span class="o">||^</span><span class="mi">2</span><span class="n">_2</span>
</pre></div>
</div>
<p>If you are interested in controlling the L1 and L2 penalty
separately, keep in mind that this is equivalent to:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">*</span> <span class="n">L1</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">L2</span>
</pre></div>
</div>
<p>for:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="ow">and</span> <span class="n">l1_ratio</span> <span class="o">=</span> <span class="n">a</span> <span class="o">/</span> <span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span>
</pre></div>
</div>
<p>enet_path
ElasticNet</p>
</div></blockquote>
<dl class="method">
<dt id="ibex.sklearn.linear_model.ElasticNetCV.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.linear_model.ElasticNetCV.fit" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Fit linear model with coordinate descent</p>
<blockquote>
<div><p>Fit is on grid of alphas and best alpha estimated by cross-validation.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like}, shape (n_samples, n_features)</span></dt>
<dd>Training data. Pass directly as Fortran-contiguous data
to avoid unnecessary memory duplication. If y is mono-output,
X can be sparse.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (n_samples,) or (n_samples, n_targets)</span></dt>
<dd>Target values</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.linear_model.ElasticNetCV.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.linear_model.ElasticNetCV.predict" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Predict using the linear model</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = (n_samples, n_features)</span></dt>
<dd>Samples.</dd>
</dl>
<dl class="docutils">
<dt>C <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = (n_samples,)</span></dt>
<dd>Returns predicted values.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.linear_model.ElasticNetCV.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>x</em>, <em>y</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.linear_model.ElasticNetCV.score" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Returns the coefficient of determination R^2 of the prediction.</p>
<blockquote>
<div><p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) ** 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) ** 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, n_features)</span></dt>
<dd>Test samples.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples) or (n_samples, n_outputs)</span></dt>
<dd>True values for X.</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples], optional</span></dt>
<dd>Sample weights.</dd>
</dl>
<dl class="docutils">
<dt>score <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>R^2 of self.predict(X) wrt. y.</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.jpeg" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Ibex</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="frame_adapter.html">Adapting Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="input_verification_and_output_processing.html">Verification and Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_transformer.html">Transforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipelines.html">Pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_union.html">Uniting Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="sklearn.html"><code class="docutils literal"><span class="pre">sklearn</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorflow.html"><code class="docutils literal"><span class="pre">tensorflow</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost.html"><code class="docutils literal"><span class="pre">xgboost</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="extending.html">Extending</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/api_ibex_sklearn_linear_model_elasticnetcv.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Ami Tavory, Shahar Azulay, Tali Raveh-Sadka.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/api_ibex_sklearn_linear_model_elasticnetcv.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/atavory/ibex" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>