
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>BaggingRegressor &#8212; ibex latest documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     'latest',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/logo.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="baggingregressor">
<h1><code class="docutils literal"><span class="pre">BaggingRegressor</span></code><a class="headerlink" href="#baggingregressor" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="ibex.sklearn.ensemble.BaggingRegressor">
<em class="property">class </em><code class="descclassname">ibex.sklearn.ensemble.</code><code class="descname">BaggingRegressor</code><span class="sig-paren">(</span><em>base_estimator=None</em>, <em>n_estimators=10</em>, <em>max_samples=1.0</em>, <em>max_features=1.0</em>, <em>bootstrap=True</em>, <em>bootstrap_features=False</em>, <em>oob_score=False</em>, <em>warm_start=False</em>, <em>n_jobs=1</em>, <em>random_state=None</em>, <em>verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.ensemble.BaggingRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.ensemble.bagging.BaggingRegressor</span></code>, <code class="xref py py-class docutils literal"><span class="pre">ibex._base.FrameMixin</span></code></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>A Bagging regressor.</p>
<blockquote>
<div><p>A Bagging regressor is an ensemble meta-estimator that fits base
regressors each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.</p>
<p>This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting <a class="footnote-reference" href="#id5" id="id1">[1]</a>. If samples are drawn with
replacement, then the method is known as Bagging <a class="footnote-reference" href="#id6" id="id2">[2]</a>. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces <a class="footnote-reference" href="#id7" id="id3">[3]</a>. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches <a class="footnote-reference" href="#id8" id="id4">[4]</a>.</p>
<p>Read more in the <a class="reference external" href="http://scikit-learn.org/stable/modules/ensemble.html#bagging" title="(in scikit-learn v0.19.1)"><span class="xref std std-ref">User Guide</span></a>.</p>
<dl class="docutils">
<dt>base_estimator <span class="classifier-delimiter">:</span> <span class="classifier">object or None, optional (default=None)</span></dt>
<dd>The base estimator to fit on random subsets of the dataset.
If None, then the base estimator is a decision tree.</dd>
<dt>n_estimators <span class="classifier-delimiter">:</span> <span class="classifier">int, optional (default=10)</span></dt>
<dd>The number of base estimators in the ensemble.</dd>
<dt>max_samples <span class="classifier-delimiter">:</span> <span class="classifier">int or float, optional (default=1.0)</span></dt>
<dd><dl class="first last docutils">
<dt>The number of samples to draw from X to train each base estimator.</dt>
<dd><ul class="first last simple">
<li>If int, then draw <cite>max_samples</cite> samples.</li>
<li>If float, then draw <cite>max_samples * X.shape[0]</cite> samples.</li>
</ul>
</dd>
</dl>
</dd>
<dt>max_features <span class="classifier-delimiter">:</span> <span class="classifier">int or float, optional (default=1.0)</span></dt>
<dd><dl class="first last docutils">
<dt>The number of features to draw from X to train each base estimator.</dt>
<dd><ul class="first last simple">
<li>If int, then draw <cite>max_features</cite> features.</li>
<li>If float, then draw <cite>max_features * X.shape[1]</cite> features.</li>
</ul>
</dd>
</dl>
</dd>
<dt>bootstrap <span class="classifier-delimiter">:</span> <span class="classifier">boolean, optional (default=True)</span></dt>
<dd>Whether samples are drawn with replacement.</dd>
<dt>bootstrap_features <span class="classifier-delimiter">:</span> <span class="classifier">boolean, optional (default=False)</span></dt>
<dd>Whether features are drawn with replacement.</dd>
<dt>oob_score <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>Whether to use out-of-bag samples to estimate
the generalization error.</dd>
<dt>warm_start <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional (default=False)</span></dt>
<dd>When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble.</dd>
<dt>n_jobs <span class="classifier-delimiter">:</span> <span class="classifier">int, optional (default=1)</span></dt>
<dd>The number of jobs to run in parallel for both <cite>fit</cite> and <cite>predict</cite>.
If -1, then the number of jobs is set to the number of cores.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional (default=None)</span></dt>
<dd>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">int, optional (default=0)</span></dt>
<dd>Controls the verbosity of the building process.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id9"><span class="problematic" id="id10">estimators_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">list of estimators</span></dt>
<dd>The collection of fitted sub-estimators.</dd>
<dt><a href="#id11"><span class="problematic" id="id12">estimators_samples_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">list of arrays</span></dt>
<dd>The subset of drawn samples (i.e., the in-bag samples) for each base
estimator. Each subset is defined by a boolean mask.</dd>
<dt><a href="#id13"><span class="problematic" id="id14">estimators_features_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">list of arrays</span></dt>
<dd>The subset of drawn features for each base estimator.</dd>
<dt><a href="#id15"><span class="problematic" id="id16">oob_score_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Score of the training dataset obtained using an out-of-bag estimate.</dd>
<dt><a href="#id17"><span class="problematic" id="id18">oob_prediction_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array of shape = [n_samples]</span></dt>
<dd>Prediction computed with out-of-bag estimate on the training
set. If n_estimators is small it might be possible that a data point
was never left out during the bootstrap. In this case,
<cite>oob_prediction_</cite> might contain NaN.</dd>
</dl>
<table class="docutils footnote" frame="void" id="id5" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>L. Breiman, “Pasting small votes for classification in large
databases and on-line”, Machine Learning, 36(1), 85-103, 1999.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id6" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140,
1996.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id7" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[3]</a></td><td>T. Ho, “The random subspace method for constructing decision
forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844,
1998.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id8" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id4">[4]</a></td><td>G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine
Learning and Knowledge Discovery in Databases, 346-361, 2012.</td></tr>
</tbody>
</table>
</div></blockquote>
<dl class="method">
<dt id="ibex.sklearn.ensemble.BaggingRegressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.ensemble.BaggingRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<dl class="docutils">
<dt>Build a Bagging ensemble of estimators from the training</dt>
<dd><blockquote class="first">
<div>set (X, y).</div></blockquote>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix} of shape = [n_samples, n_features]</span></dt>
<dd>The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>The target values (class labels in classification, real numbers in
regression).</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples] or None</span></dt>
<dd>Sample weights. If None, then samples are equally weighted.
Note that this is supported only if the base estimator supports
sample weighting.</dd>
</dl>
<dl class="last docutils">
<dt>self <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd>Returns self.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.ensemble.BaggingRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/ensemble/bagging.html#BaggingRegressor.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.ensemble.BaggingRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Predict regression target for X.</p>
<blockquote>
<div><p>The predicted regression target of an input sample is computed as the
mean predicted regression targets of the estimators in the ensemble.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix} of shape = [n_samples, n_features]</span></dt>
<dd>The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</dd>
</dl>
<dl class="docutils">
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array of shape = [n_samples]</span></dt>
<dd>The predicted values.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.ensemble.BaggingRegressor.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>x</em>, <em>y</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.ensemble.BaggingRegressor.score" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Returns the coefficient of determination R^2 of the prediction.</p>
<blockquote>
<div><p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) ** 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) ** 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, n_features)</span></dt>
<dd>Test samples.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples) or (n_samples, n_outputs)</span></dt>
<dd>True values for X.</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples], optional</span></dt>
<dd>Sample weights.</dd>
</dl>
<dl class="docutils">
<dt>score <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>R^2 of self.predict(X) wrt. y.</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.jpeg" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Ibex</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="frame_adapter.html">Adapting Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="input_verification_and_output_processing.html">Verification and Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_transformer.html">Transforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipelines.html">Pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_union.html">Uniting Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="sklearn.html"><code class="docutils literal"><span class="pre">sklearn</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorflow.html"><code class="docutils literal"><span class="pre">tensorflow</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost.html"><code class="docutils literal"><span class="pre">xgboost</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="extending.html">Extending</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/api_ibex_sklearn_ensemble_baggingregressor.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Ami Tavory, Shahar Azulay, Tali Raveh-Sadka.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/api_ibex_sklearn_ensemble_baggingregressor.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/atavory/ibex" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>