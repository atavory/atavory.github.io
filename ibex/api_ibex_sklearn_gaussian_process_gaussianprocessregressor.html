
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>GaussianProcessRegressor &#8212; ibex latest documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     'latest',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/logo.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="gaussianprocessregressor">
<h1><code class="docutils literal"><span class="pre">GaussianProcessRegressor</span></code><a class="headerlink" href="#gaussianprocessregressor" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="ibex.sklearn.gaussian_process.GaussianProcessRegressor">
<em class="property">class </em><code class="descclassname">ibex.sklearn.gaussian_process.</code><code class="descname">GaussianProcessRegressor</code><span class="sig-paren">(</span><em>kernel=None</em>, <em>alpha=1e-10</em>, <em>optimizer='fmin_l_bfgs_b'</em>, <em>n_restarts_optimizer=0</em>, <em>normalize_y=False</em>, <em>copy_X_train=True</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.gaussian_process.GaussianProcessRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.gaussian_process.gpr.GaussianProcessRegressor</span></code>, <code class="xref py py-class docutils literal"><span class="pre">ibex._base.FrameMixin</span></code></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Gaussian process regression (GPR).</p>
<blockquote>
<div><p>The implementation is based on Algorithm 2.1 of Gaussian Processes
for Machine Learning (GPML) by Rasmussen and Williams.</p>
<p>In addition to standard scikit-learn estimator API,
GaussianProcessRegressor:</p>
<blockquote>
<div><ul class="simple">
<li>allows prediction without prior fitting (based on the GP prior)</li>
<li>provides an additional method sample_y(X), which evaluates samples
drawn from the GPR (prior or posterior) at given inputs</li>
<li>exposes a method log_marginal_likelihood(theta), which can be used
externally for other ways of selecting hyperparameters, e.g., via
Markov chain Monte Carlo.</li>
</ul>
</div></blockquote>
<p>Read more in the <a class="reference external" href="http://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process" title="(in scikit-learn v0.19.1)"><span class="xref std std-ref">User Guide</span></a>.</p>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.18.</span></p>
</div>
<dl class="docutils">
<dt>kernel <span class="classifier-delimiter">:</span> <span class="classifier">kernel object</span></dt>
<dd>The kernel specifying the covariance function of the GP. If None is
passed, the kernel “1.0 * RBF(1.0)” is used as default. Note that
the kernel’s hyperparameters are optimized during fitting.</dd>
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float or array-like, optional (default: 1e-10)</span></dt>
<dd>Value added to the diagonal of the kernel matrix during fitting.
Larger values correspond to increased noise level in the observations.
This can also prevent a potential numerical issue during fitting, by
ensuring that the calculated values form a positive definite matrix.
If an array is passed, it must have the same number of entries as the
data used for fitting and is used as datapoint-dependent noise level.
Note that this is equivalent to adding a WhiteKernel with c=alpha.
Allowing to specify the noise level directly as a parameter is mainly
for convenience and for consistency with Ridge.</dd>
<dt>optimizer <span class="classifier-delimiter">:</span> <span class="classifier">string or callable, optional (default: “fmin_l_bfgs_b”)</span></dt>
<dd><p class="first">Can either be one of the internally supported optimizers for optimizing
the kernel’s parameters, specified by a string, or an externally
defined optimizer passed as a callable. If a callable is passed, it
must have the signature:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">optimizer</span><span class="p">(</span><span class="n">obj_func</span><span class="p">,</span> <span class="n">initial_theta</span><span class="p">,</span> <span class="n">bounds</span><span class="p">):</span>
    <span class="c1"># * &#39;obj_func&#39; is the objective function to be maximized, which</span>
    <span class="c1">#   takes the hyperparameters theta as parameter and an</span>
    <span class="c1">#   optional flag eval_gradient, which determines if the</span>
    <span class="c1">#   gradient is returned additionally to the function value</span>
    <span class="c1"># * &#39;initial_theta&#39;: the initial value for theta, which can be</span>
    <span class="c1">#   used by local optimizers</span>
    <span class="c1"># * &#39;bounds&#39;: the bounds on the values of theta</span>
    <span class="o">....</span>
    <span class="c1"># Returned are the best found hyperparameters theta and</span>
    <span class="c1"># the corresponding value of the target function.</span>
    <span class="k">return</span> <span class="n">theta_opt</span><span class="p">,</span> <span class="n">func_min</span>
</pre></div>
</div>
<p>Per default, the ‘fmin_l_bfgs_b’ algorithm from scipy.optimize
is used. If None is passed, the kernel’s parameters are kept fixed.
Available internal optimizers are:</p>
<div class="last highlight-default"><div class="highlight"><pre><span></span><span class="s1">&#39;fmin_l_bfgs_b&#39;</span>
</pre></div>
</div>
</dd>
<dt>n_restarts_optimizer <span class="classifier-delimiter">:</span> <span class="classifier">int, optional (default: 0)</span></dt>
<dd>The number of restarts of the optimizer for finding the kernel’s
parameters which maximize the log-marginal likelihood. The first run
of the optimizer is performed from the kernel’s initial parameters,
the remaining ones (if any) from thetas sampled log-uniform randomly
from the space of allowed theta-values. If greater than 0, all bounds
must be finite. Note that n_restarts_optimizer == 0 implies that one
run is performed.</dd>
<dt>normalize_y <span class="classifier-delimiter">:</span> <span class="classifier">boolean, optional (default: False)</span></dt>
<dd>Whether the target values y are normalized, i.e., the mean of the
observed target values become zero. This parameter should be set to
True if the target values’ mean is expected to differ considerable from
zero. When enabled, the normalization effectively modifies the GP’s
prior based on the data, which contradicts the likelihood principle;
normalization is thus disabled per default.</dd>
<dt>copy_X_train <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional (default: True)</span></dt>
<dd>If True, a persistent copy of the training data is stored in the
object. Otherwise, just a reference to the training data is stored,
which might cause predictions to change if the data is modified
externally.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional (default: None)</span></dt>
<dd>The generator used to initialize the centers. If int, random_state is
the seed used by the random number generator; If RandomState instance,
random_state is the random number generator; If None, the random number
generator is the RandomState instance used by <cite>np.random</cite>.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id1"><span class="problematic" id="id2">X_train_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, n_features)</span></dt>
<dd>Feature values in training data (also required for prediction)</dd>
<dt><a href="#id3"><span class="problematic" id="id4">y_train_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, [n_output_dims])</span></dt>
<dd>Target values in training data (also required for prediction)</dd>
<dt><a href="#id5"><span class="problematic" id="id6">kernel_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">kernel object</span></dt>
<dd>The kernel used for prediction. The structure of the kernel is the
same as the one passed as parameter but with optimized hyperparameters</dd>
<dt><a href="#id7"><span class="problematic" id="id8">L_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, n_samples)</span></dt>
<dd>Lower-triangular Cholesky decomposition of the kernel in <code class="docutils literal"><span class="pre">X_train_</span></code></dd>
<dt><a href="#id9"><span class="problematic" id="id10">alpha_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples,)</span></dt>
<dd>Dual coefficients of training data points in kernel space</dd>
<dt><a href="#id11"><span class="problematic" id="id12">log_marginal_likelihood_value_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The log-marginal-likelihood of <code class="docutils literal"><span class="pre">self.kernel_.theta</span></code></dd>
</dl>
</div></blockquote>
<dl class="method">
<dt id="ibex.sklearn.gaussian_process.GaussianProcessRegressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/gaussian_process/gpr.html#GaussianProcessRegressor.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.gaussian_process.GaussianProcessRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Fit Gaussian process regression model.</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, n_features)</span></dt>
<dd>Training data</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, [n_output_dims])</span></dt>
<dd>Target values</dd>
</dl>
<p>self : returns an instance of self.</p>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.gaussian_process.GaussianProcessRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>return_std=False</em>, <em>return_cov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/gaussian_process/gpr.html#GaussianProcessRegressor.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.gaussian_process.GaussianProcessRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Predict using the Gaussian process regression model</p>
<blockquote>
<div><p>We can also predict based on an unfitted model by using the GP prior.
In addition to the mean of the predictive distribution, also its
standard deviation (return_std=True) or covariance (return_cov=True).
Note that at most one of the two can be requested.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, n_features)</span></dt>
<dd>Query points where the GP is evaluated</dd>
<dt>return_std <span class="classifier-delimiter">:</span> <span class="classifier">bool, default: False</span></dt>
<dd>If True, the standard-deviation of the predictive distribution at
the query points is returned along with the mean.</dd>
<dt>return_cov <span class="classifier-delimiter">:</span> <span class="classifier">bool, default: False</span></dt>
<dd>If True, the covariance of the joint predictive distribution at
the query points is returned along with the mean</dd>
</dl>
<dl class="docutils">
<dt>y_mean <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = (n_samples, [n_output_dims])</span></dt>
<dd>Mean of predictive distribution a query points</dd>
<dt>y_std <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = (n_samples,), optional</span></dt>
<dd>Standard deviation of predictive distribution at query points.
Only returned when return_std is True.</dd>
<dt>y_cov <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = (n_samples, n_samples), optional</span></dt>
<dd>Covariance of joint predictive distribution a query points.
Only returned when return_cov is True.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.gaussian_process.GaussianProcessRegressor.sample_y">
<code class="descname">sample_y</code><span class="sig-paren">(</span><em>X</em>, <em>n_samples=1</em>, <em>random_state=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/gaussian_process/gpr.html#GaussianProcessRegressor.sample_y"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.gaussian_process.GaussianProcessRegressor.sample_y" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Draw samples from Gaussian process and evaluate at X.</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples_X, n_features)</span></dt>
<dd>Query points where the GP samples are evaluated</dd>
<dt>n_samples <span class="classifier-delimiter">:</span> <span class="classifier">int, default: 1</span></dt>
<dd>The number of samples drawn from the Gaussian process</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional (default=0)</span></dt>
<dd>If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the
random number generator; If None, the random number
generator is the RandomState instance used by <cite>np.random</cite>.</dd>
</dl>
<dl class="docutils">
<dt>y_samples <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = (n_samples_X, [n_output_dims], n_samples)</span></dt>
<dd>Values of n_samples samples drawn from Gaussian process and
evaluated at query points.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.gaussian_process.GaussianProcessRegressor.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>x</em>, <em>y</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.gaussian_process.GaussianProcessRegressor.score" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Returns the coefficient of determination R^2 of the prediction.</p>
<blockquote>
<div><p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) ** 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) ** 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, n_features)</span></dt>
<dd>Test samples.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples) or (n_samples, n_outputs)</span></dt>
<dd>True values for X.</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples], optional</span></dt>
<dd>Sample weights.</dd>
</dl>
<dl class="docutils">
<dt>score <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>R^2 of self.predict(X) wrt. y.</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.jpeg" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Ibex</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="frame_adapter.html">Adapting Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="input_verification_and_output_processing.html">Verification and Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_transformer.html">Transforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipelines.html">Pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_union.html">Uniting Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="sklearn.html"><code class="docutils literal"><span class="pre">sklearn</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorflow.html"><code class="docutils literal"><span class="pre">tensorflow</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost.html"><code class="docutils literal"><span class="pre">xgboost</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="extending.html">Extending</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/api_ibex_sklearn_gaussian_process_gaussianprocessregressor.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Ami Tavory, Shahar Azulay, Tali Raveh-Sadka.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/api_ibex_sklearn_gaussian_process_gaussianprocessregressor.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/atavory/ibex" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>