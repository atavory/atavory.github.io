
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>sklearn.preprocessing.data &#8212; ibex latest documentation</title>
    <link rel="stylesheet" href="../../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     'latest',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for sklearn.preprocessing.data</h1><div class="highlight"><pre>
<span></span><span class="c1"># Authors: Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;</span>
<span class="c1">#          Mathieu Blondel &lt;mathieu@mblondel.org&gt;</span>
<span class="c1">#          Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="c1">#          Andreas Mueller &lt;amueller@ais.uni-bonn.de&gt;</span>
<span class="c1">#          Eric Martin &lt;eric@ericmart.in&gt;</span>
<span class="c1">#          Giorgio Patrini &lt;giorgio.patrini@anu.edu.au&gt;</span>
<span class="c1"># License: BSD 3 clause</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>

<span class="kn">from</span> <span class="nn">itertools</span> <span class="k">import</span> <span class="n">chain</span><span class="p">,</span> <span class="n">combinations</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="k">import</span> <span class="n">combinations_with_replacement</span> <span class="k">as</span> <span class="n">combinations_w_r</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">sparse</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">stats</span>

<span class="kn">from</span> <span class="nn">..base</span> <span class="k">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">..externals</span> <span class="k">import</span> <span class="n">six</span>
<span class="kn">from</span> <span class="nn">..externals.six</span> <span class="k">import</span> <span class="n">string_types</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="k">import</span> <span class="n">check_array</span>
<span class="kn">from</span> <span class="nn">..utils.extmath</span> <span class="k">import</span> <span class="n">row_norms</span>
<span class="kn">from</span> <span class="nn">..utils.extmath</span> <span class="k">import</span> <span class="n">_incremental_mean_and_var</span>
<span class="kn">from</span> <span class="nn">..utils.sparsefuncs_fast</span> <span class="k">import</span> <span class="p">(</span><span class="n">inplace_csr_row_normalize_l1</span><span class="p">,</span>
                                      <span class="n">inplace_csr_row_normalize_l2</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">..utils.sparsefuncs</span> <span class="k">import</span> <span class="p">(</span><span class="n">inplace_column_scale</span><span class="p">,</span>
                                 <span class="n">mean_variance_axis</span><span class="p">,</span> <span class="n">incr_mean_variance_axis</span><span class="p">,</span>
                                 <span class="n">min_max_axis</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="k">import</span> <span class="p">(</span><span class="n">check_is_fitted</span><span class="p">,</span> <span class="n">check_random_state</span><span class="p">,</span>
                                <span class="n">FLOAT_DTYPES</span><span class="p">)</span>
<span class="n">BOUNDS_THRESHOLD</span> <span class="o">=</span> <span class="mf">1e-7</span>


<span class="nb">zip</span> <span class="o">=</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">zip</span>
<span class="nb">map</span> <span class="o">=</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">map</span>
<span class="nb">range</span> <span class="o">=</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;Binarizer&#39;</span><span class="p">,</span>
    <span class="s1">&#39;KernelCenterer&#39;</span><span class="p">,</span>
    <span class="s1">&#39;MinMaxScaler&#39;</span><span class="p">,</span>
    <span class="s1">&#39;MaxAbsScaler&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Normalizer&#39;</span><span class="p">,</span>
    <span class="s1">&#39;OneHotEncoder&#39;</span><span class="p">,</span>
    <span class="s1">&#39;RobustScaler&#39;</span><span class="p">,</span>
    <span class="s1">&#39;StandardScaler&#39;</span><span class="p">,</span>
    <span class="s1">&#39;QuantileTransformer&#39;</span><span class="p">,</span>
    <span class="s1">&#39;add_dummy_feature&#39;</span><span class="p">,</span>
    <span class="s1">&#39;binarize&#39;</span><span class="p">,</span>
    <span class="s1">&#39;normalize&#39;</span><span class="p">,</span>
    <span class="s1">&#39;scale&#39;</span><span class="p">,</span>
    <span class="s1">&#39;robust_scale&#39;</span><span class="p">,</span>
    <span class="s1">&#39;maxabs_scale&#39;</span><span class="p">,</span>
    <span class="s1">&#39;minmax_scale&#39;</span><span class="p">,</span>
    <span class="s1">&#39;quantile_transform&#39;</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">def</span> <span class="nf">_handle_zeros_in_scale</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Makes sure that whenever scale is zero, we handle it correctly.</span>

<span class="sd">    This happens in most scalers when we have constant features.&#39;&#39;&#39;</span>

    <span class="c1"># if we are fitting on 1D arrays, scale might be a scalar</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">scale</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">scale</span> <span class="o">==</span> <span class="o">.</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.</span>
        <span class="k">return</span> <span class="n">scale</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">copy</span><span class="p">:</span>
            <span class="c1"># New array to avoid side-effects</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">scale</span><span class="p">[</span><span class="n">scale</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">return</span> <span class="n">scale</span>


<span class="k">def</span> <span class="nf">scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">with_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_std</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Standardize a dataset along any axis</span>

<span class="sd">    Center to the mean and component wise scale to unit variance.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_scaler&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {array-like, sparse matrix}</span>
<span class="sd">        The data to center and scale.</span>

<span class="sd">    axis : int (0 by default)</span>
<span class="sd">        axis used to compute the means and standard deviations along. If 0,</span>
<span class="sd">        independently standardize each feature, otherwise (if 1) standardize</span>
<span class="sd">        each sample.</span>

<span class="sd">    with_mean : boolean, True by default</span>
<span class="sd">        If True, center the data before scaling.</span>

<span class="sd">    with_std : boolean, True by default</span>
<span class="sd">        If True, scale the data to unit variance (or equivalently,</span>
<span class="sd">        unit standard deviation).</span>

<span class="sd">    copy : boolean, optional, default True</span>
<span class="sd">        set to False to perform inplace row normalization and avoid a</span>
<span class="sd">        copy (if the input is already a numpy array or a scipy.sparse</span>
<span class="sd">        CSC matrix and if axis is 1).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This implementation will refuse to center scipy.sparse matrices</span>
<span class="sd">    since it would make them non-sparse and would potentially crash the</span>
<span class="sd">    program with memory exhaustion problems.</span>

<span class="sd">    Instead the caller is expected to either set explicitly</span>
<span class="sd">    `with_mean=False` (in that case, only variance scaling will be</span>
<span class="sd">    performed on the features of the CSC matrix) or to call `X.toarray()`</span>
<span class="sd">    if he/she expects the materialized dense array to fit in memory.</span>

<span class="sd">    To avoid memory copy the caller should pass a CSC matrix.</span>

<span class="sd">    For a comparison of the different scalers, transformers, and normalizers,</span>
<span class="sd">    see :ref:`examples/preprocessing/plot_all_scaling.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    StandardScaler: Performs scaling to unit variance using the``Transformer`` API</span>
<span class="sd">        (e.g. as part of a preprocessing :class:`sklearn.pipeline.Pipeline`).</span>

<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s1">&#39;csc&#39;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">warn_on_dtype</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="s1">&#39;the scale function&#39;</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">with_mean</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot center sparse matrices: pass `with_mean=False` instead&quot;</span>
                <span class="s2">&quot; See docstring for motivation and alternatives.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Can only scale sparse matrix on axis=0, &quot;</span>
                             <span class="s2">&quot; got axis=</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">axis</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">with_std</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">var</span> <span class="o">=</span> <span class="n">mean_variance_axis</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">_handle_zeros_in_scale</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">inplace_column_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">with_mean</span><span class="p">:</span>
            <span class="n">mean_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">with_std</span><span class="p">:</span>
            <span class="n">scale_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
        <span class="c1"># Xr is a view on the original array that enables easy use of</span>
        <span class="c1"># broadcasting on the axis in which we are interested in</span>
        <span class="n">Xr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">rollaxis</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">with_mean</span><span class="p">:</span>
            <span class="n">Xr</span> <span class="o">-=</span> <span class="n">mean_</span>
            <span class="n">mean_1</span> <span class="o">=</span> <span class="n">Xr</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># Verify that mean_1 is &#39;close to zero&#39;. If X contains very</span>
            <span class="c1"># large values, mean_1 can also be very large, due to a lack of</span>
            <span class="c1"># precision of mean_. In this case, a pre-scaling of the</span>
            <span class="c1"># concerned feature is efficient, for instance by its mean or</span>
            <span class="c1"># maximum.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">mean_1</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Numerical issues were encountered &quot;</span>
                              <span class="s2">&quot;when centering the data &quot;</span>
                              <span class="s2">&quot;and might not be solved. Dataset may &quot;</span>
                              <span class="s2">&quot;contain too large values. You may need &quot;</span>
                              <span class="s2">&quot;to prescale your features.&quot;</span><span class="p">)</span>
                <span class="n">Xr</span> <span class="o">-=</span> <span class="n">mean_1</span>
        <span class="k">if</span> <span class="n">with_std</span><span class="p">:</span>
            <span class="n">scale_</span> <span class="o">=</span> <span class="n">_handle_zeros_in_scale</span><span class="p">(</span><span class="n">scale_</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">Xr</span> <span class="o">/=</span> <span class="n">scale_</span>
            <span class="k">if</span> <span class="n">with_mean</span><span class="p">:</span>
                <span class="n">mean_2</span> <span class="o">=</span> <span class="n">Xr</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="c1"># If mean_2 is not &#39;close to zero&#39;, it comes from the fact that</span>
                <span class="c1"># scale_ is very small so that mean_2 = mean_1/scale_ &gt; 0, even</span>
                <span class="c1"># if mean_1 was close to zero. The problem is thus essentially</span>
                <span class="c1"># due to the lack of precision of mean_. A solution is then to</span>
                <span class="c1"># subtract the mean again:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">mean_2</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Numerical issues were encountered &quot;</span>
                                  <span class="s2">&quot;when scaling the data &quot;</span>
                                  <span class="s2">&quot;and might not be solved. The standard &quot;</span>
                                  <span class="s2">&quot;deviation of the data is probably &quot;</span>
                                  <span class="s2">&quot;very close to 0. &quot;</span><span class="p">)</span>
                    <span class="n">Xr</span> <span class="o">-=</span> <span class="n">mean_2</span>
    <span class="k">return</span> <span class="n">X</span>


<span class="k">class</span> <span class="nc">MinMaxScaler</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Transforms features by scaling each feature to a given range.</span>

<span class="sd">    This estimator scales and translates each feature individually such</span>
<span class="sd">    that it is in the given range on the training set, i.e. between</span>
<span class="sd">    zero and one.</span>

<span class="sd">    The transformation is given by::</span>

<span class="sd">        X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))</span>
<span class="sd">        X_scaled = X_std * (max - min) + min</span>

<span class="sd">    where min, max = feature_range.</span>

<span class="sd">    This transformation is often used as an alternative to zero mean,</span>
<span class="sd">    unit variance scaling.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_scaler&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    feature_range : tuple (min, max), default=(0, 1)</span>
<span class="sd">        Desired range of transformed data.</span>

<span class="sd">    copy : boolean, optional, default True</span>
<span class="sd">        Set to False to perform inplace row normalization and avoid a</span>
<span class="sd">        copy (if the input is already a numpy array).</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    min_ : ndarray, shape (n_features,)</span>
<span class="sd">        Per feature adjustment for minimum.</span>

<span class="sd">    scale_ : ndarray, shape (n_features,)</span>
<span class="sd">        Per feature relative scaling of the data.</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           *scale_* attribute.</span>

<span class="sd">    data_min_ : ndarray, shape (n_features,)</span>
<span class="sd">        Per feature minimum seen in the data</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           *data_min_*</span>

<span class="sd">    data_max_ : ndarray, shape (n_features,)</span>
<span class="sd">        Per feature maximum seen in the data</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           *data_max_*</span>

<span class="sd">    data_range_ : ndarray, shape (n_features,)</span>
<span class="sd">        Per feature range ``(data_max_ - data_min_)`` seen in the data</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           *data_range_*</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]</span>
<span class="sd">    &gt;&gt;&gt; scaler = MinMaxScaler()</span>
<span class="sd">    &gt;&gt;&gt; print(scaler.fit(data))</span>
<span class="sd">    MinMaxScaler(copy=True, feature_range=(0, 1))</span>
<span class="sd">    &gt;&gt;&gt; print(scaler.data_max_)</span>
<span class="sd">    [  1.  18.]</span>
<span class="sd">    &gt;&gt;&gt; print(scaler.transform(data))</span>
<span class="sd">    [[ 0.    0.  ]</span>
<span class="sd">     [ 0.25  0.25]</span>
<span class="sd">     [ 0.5   0.5 ]</span>
<span class="sd">     [ 1.    1.  ]]</span>
<span class="sd">    &gt;&gt;&gt; print(scaler.transform([[2, 2]]))</span>
<span class="sd">    [[ 1.5  0. ]]</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    minmax_scale: Equivalent function without the estimator API.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    For a comparison of the different scalers, transformers, and normalizers,</span>
<span class="sd">    see :ref:`examples/preprocessing/plot_all_scaling.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_range</span> <span class="o">=</span> <span class="n">feature_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">copy</span> <span class="o">=</span> <span class="n">copy</span>

    <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Reset internal data-dependent state of the scaler, if necessary.</span>

<span class="sd">        __init__ parameters are not touched.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Checking one attribute is enough, becase they are all set together</span>
        <span class="c1"># in partial_fit</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scale_&#39;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_min_</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_max_</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_range_</span>

<div class="viewcode-block" id="MinMaxScaler.fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_minmaxscaler.html#ibex.sklearn.preprocessing.MinMaxScaler.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the minimum and maximum to be used for later scaling.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape [n_samples, n_features]</span>
<span class="sd">            The data used to compute the per-feature minimum and maximum</span>
<span class="sd">            used for later scaling along the features axis.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Reset internal state before fitting</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></div>

<div class="viewcode-block" id="MinMaxScaler.partial_fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_minmaxscaler.html#ibex.sklearn.preprocessing.MinMaxScaler.partial_fit">[docs]</a>    <span class="k">def</span> <span class="nf">partial_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Online computation of min and max on X for later scaling.</span>
<span class="sd">        All of X is processed as a single batch. This is intended for cases</span>
<span class="sd">        when `fit` is not feasible due to very large number of `n_samples`</span>
<span class="sd">        or because X is read from a continuous stream.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape [n_samples, n_features]</span>
<span class="sd">            The data used to compute the mean and standard deviation</span>
<span class="sd">            used for later scaling along the features axis.</span>

<span class="sd">        y : Passthrough for ``Pipeline`` compatibility.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">feature_range</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_range</span>
        <span class="k">if</span> <span class="n">feature_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">feature_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Minimum of desired feature range must be smaller&quot;</span>
                             <span class="s2">&quot; than maximum. Got </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">feature_range</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;MinMaxScaler does no support sparse input. &quot;</span>
                            <span class="s2">&quot;You may consider to use MaxAbsScaler instead.&quot;</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">,</span> <span class="n">warn_on_dtype</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">estimator</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>

        <span class="n">data_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">data_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># First pass</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;n_samples_seen_&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Next steps</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_min_</span><span class="p">,</span> <span class="n">data_min</span><span class="p">)</span>
            <span class="n">data_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_max_</span><span class="p">,</span> <span class="n">data_max</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span> <span class="o">+=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">data_range</span> <span class="o">=</span> <span class="n">data_max</span> <span class="o">-</span> <span class="n">data_min</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span> <span class="o">=</span> <span class="p">((</span><span class="n">feature_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">feature_range</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span>
                       <span class="n">_handle_zeros_in_scale</span><span class="p">(</span><span class="n">data_range</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_</span> <span class="o">=</span> <span class="n">feature_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">data_min</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_min_</span> <span class="o">=</span> <span class="n">data_min</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_max_</span> <span class="o">=</span> <span class="n">data_max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_range_</span> <span class="o">=</span> <span class="n">data_range</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="MinMaxScaler.transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_minmaxscaler.html#ibex.sklearn.preprocessing.MinMaxScaler.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Scaling features of X according to feature_range.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape [n_samples, n_features]</span>
<span class="sd">            Input data that will be transformed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scale_&#39;</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
        <span class="n">X</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_</span>
        <span class="k">return</span> <span class="n">X</span></div>

<div class="viewcode-block" id="MinMaxScaler.inverse_transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_minmaxscaler.html#ibex.sklearn.preprocessing.MinMaxScaler.inverse_transform">[docs]</a>    <span class="k">def</span> <span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Undo the scaling of X according to feature_range.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape [n_samples, n_features]</span>
<span class="sd">            Input data that will be transformed. It cannot be sparse.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scale_&#39;</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_</span>
        <span class="n">X</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
        <span class="k">return</span> <span class="n">X</span></div>


<span class="k">def</span> <span class="nf">minmax_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Transforms features by scaling each feature to a given range.</span>

<span class="sd">    This estimator scales and translates each feature individually such</span>
<span class="sd">    that it is in the given range on the training set, i.e. between</span>
<span class="sd">    zero and one.</span>

<span class="sd">    The transformation is given by::</span>

<span class="sd">        X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))</span>
<span class="sd">        X_scaled = X_std * (max - min) + min</span>

<span class="sd">    where min, max = feature_range.</span>

<span class="sd">    This transformation is often used as an alternative to zero mean,</span>
<span class="sd">    unit variance scaling.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_scaler&gt;`.</span>

<span class="sd">    .. versionadded:: 0.17</span>
<span class="sd">       *minmax_scale* function interface</span>
<span class="sd">       to :class:`sklearn.preprocessing.MinMaxScaler`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape (n_samples, n_features)</span>
<span class="sd">        The data.</span>

<span class="sd">    feature_range : tuple (min, max), default=(0, 1)</span>
<span class="sd">        Desired range of transformed data.</span>

<span class="sd">    axis : int (0 by default)</span>
<span class="sd">        axis used to scale along. If 0, independently scale each feature,</span>
<span class="sd">        otherwise (if 1) scale each sample.</span>

<span class="sd">    copy : boolean, optional, default is True</span>
<span class="sd">        Set to False to perform inplace scaling and avoid a copy (if the input</span>
<span class="sd">        is already a numpy array).</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    MinMaxScaler: Performs scaling to a given range using the``Transformer`` API</span>
<span class="sd">        (e.g. as part of a preprocessing :class:`sklearn.pipeline.Pipeline`).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    For a comparison of the different scalers, transformers, and normalizers,</span>
<span class="sd">    see :ref:`examples/preprocessing/plot_all_scaling.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>
    <span class="c1"># Unlike the scaler object, this function allows 1d input.</span>
    <span class="c1"># If copy is required, it will be done inside the scaler object.</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">warn_on_dtype</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>
    <span class="n">original_ndim</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span>

    <span class="k">if</span> <span class="n">original_ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">s</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="n">feature_range</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

    <span class="k">if</span> <span class="n">original_ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">X</span>


<span class="k">class</span> <span class="nc">StandardScaler</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Standardize features by removing the mean and scaling to unit variance</span>

<span class="sd">    Centering and scaling happen independently on each feature by computing</span>
<span class="sd">    the relevant statistics on the samples in the training set. Mean and</span>
<span class="sd">    standard deviation are then stored to be used on later data using the</span>
<span class="sd">    `transform` method.</span>

<span class="sd">    Standardization of a dataset is a common requirement for many</span>
<span class="sd">    machine learning estimators: they might behave badly if the</span>
<span class="sd">    individual feature do not more or less look like standard normally</span>
<span class="sd">    distributed data (e.g. Gaussian with 0 mean and unit variance).</span>

<span class="sd">    For instance many elements used in the objective function of</span>
<span class="sd">    a learning algorithm (such as the RBF kernel of Support Vector</span>
<span class="sd">    Machines or the L1 and L2 regularizers of linear models) assume that</span>
<span class="sd">    all features are centered around 0 and have variance in the same</span>
<span class="sd">    order. If a feature has a variance that is orders of magnitude larger</span>
<span class="sd">    that others, it might dominate the objective function and make the</span>
<span class="sd">    estimator unable to learn from other features correctly as expected.</span>

<span class="sd">    This scaler can also be applied to sparse CSR or CSC matrices by passing</span>
<span class="sd">    `with_mean=False` to avoid breaking the sparsity structure of the data.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_scaler&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    copy : boolean, optional, default True</span>
<span class="sd">        If False, try to avoid a copy and do inplace scaling instead.</span>
<span class="sd">        This is not guaranteed to always work inplace; e.g. if the data is</span>
<span class="sd">        not a NumPy array or scipy.sparse CSR matrix, a copy may still be</span>
<span class="sd">        returned.</span>

<span class="sd">    with_mean : boolean, True by default</span>
<span class="sd">        If True, center the data before scaling.</span>
<span class="sd">        This does not work (and will raise an exception) when attempted on</span>
<span class="sd">        sparse matrices, because centering them entails building a dense</span>
<span class="sd">        matrix which in common use cases is likely to be too large to fit in</span>
<span class="sd">        memory.</span>

<span class="sd">    with_std : boolean, True by default</span>
<span class="sd">        If True, scale the data to unit variance (or equivalently,</span>
<span class="sd">        unit standard deviation).</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    scale_ : ndarray, shape (n_features,)</span>
<span class="sd">        Per feature relative scaling of the data.</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           *scale_*</span>

<span class="sd">    mean_ : array of floats with shape [n_features]</span>
<span class="sd">        The mean value for each feature in the training set.</span>

<span class="sd">    var_ : array of floats with shape [n_features]</span>
<span class="sd">        The variance for each feature in the training set. Used to compute</span>
<span class="sd">        `scale_`</span>

<span class="sd">    n_samples_seen_ : int</span>
<span class="sd">        The number of samples processed by the estimator. Will be reset on</span>
<span class="sd">        new calls to fit, but increments across ``partial_fit`` calls.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.preprocessing import StandardScaler</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; data = [[0, 0], [0, 0], [1, 1], [1, 1]]</span>
<span class="sd">    &gt;&gt;&gt; scaler = StandardScaler()</span>
<span class="sd">    &gt;&gt;&gt; print(scaler.fit(data))</span>
<span class="sd">    StandardScaler(copy=True, with_mean=True, with_std=True)</span>
<span class="sd">    &gt;&gt;&gt; print(scaler.mean_)</span>
<span class="sd">    [ 0.5  0.5]</span>
<span class="sd">    &gt;&gt;&gt; print(scaler.transform(data))</span>
<span class="sd">    [[-1. -1.]</span>
<span class="sd">     [-1. -1.]</span>
<span class="sd">     [ 1.  1.]</span>
<span class="sd">     [ 1.  1.]]</span>
<span class="sd">    &gt;&gt;&gt; print(scaler.transform([[2, 2]]))</span>
<span class="sd">    [[ 3.  3.]]</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    scale: Equivalent function without the estimator API.</span>

<span class="sd">    :class:`sklearn.decomposition.PCA`</span>
<span class="sd">        Further removes the linear correlation across features with &#39;whiten=True&#39;.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    For a comparison of the different scalers, transformers, and normalizers,</span>
<span class="sd">    see :ref:`examples/preprocessing/plot_all_scaling.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_std</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">with_mean</span> <span class="o">=</span> <span class="n">with_mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">with_std</span> <span class="o">=</span> <span class="n">with_std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">copy</span> <span class="o">=</span> <span class="n">copy</span>

    <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Reset internal data-dependent state of the scaler, if necessary.</span>

<span class="sd">        __init__ parameters are not touched.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Checking one attribute is enough, becase they are all set together</span>
        <span class="c1"># in partial_fit</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scale_&#39;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_</span>

<div class="viewcode-block" id="StandardScaler.fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_standardscaler.html#ibex.sklearn.preprocessing.StandardScaler.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the mean and std to be used for later scaling.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}, shape [n_samples, n_features]</span>
<span class="sd">            The data used to compute the mean and standard deviation</span>
<span class="sd">            used for later scaling along the features axis.</span>

<span class="sd">        y : Passthrough for ``Pipeline`` compatibility.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Reset internal state before fitting</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></div>

<div class="viewcode-block" id="StandardScaler.partial_fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_standardscaler.html#ibex.sklearn.preprocessing.StandardScaler.partial_fit">[docs]</a>    <span class="k">def</span> <span class="nf">partial_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Online computation of mean and std on X for later scaling.</span>
<span class="sd">        All of X is processed as a single batch. This is intended for cases</span>
<span class="sd">        when `fit` is not feasible due to very large number of `n_samples`</span>
<span class="sd">        or because X is read from a continuous stream.</span>

<span class="sd">        The algorithm for incremental mean and std is given in Equation 1.5a,b</span>
<span class="sd">        in Chan, Tony F., Gene H. Golub, and Randall J. LeVeque. &quot;Algorithms</span>
<span class="sd">        for computing the sample variance: Analysis and recommendations.&quot;</span>
<span class="sd">        The American Statistician 37.3 (1983): 242-247:</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}, shape [n_samples, n_features]</span>
<span class="sd">            The data used to compute the mean and standard deviation</span>
<span class="sd">            used for later scaling along the features axis.</span>

<span class="sd">        y : Passthrough for ``Pipeline`` compatibility.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="s1">&#39;csc&#39;</span><span class="p">),</span> <span class="n">copy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">,</span>
                        <span class="n">warn_on_dtype</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>

        <span class="c1"># Even in the case of `with_mean=False`, we update the mean anyway</span>
        <span class="c1"># This is needed for the incremental computation of the var</span>
        <span class="c1"># See incr_mean_variance_axis and _incremental_mean_variance_axis</span>

        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_mean</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot center sparse matrices: pass `with_mean=False` &quot;</span>
                    <span class="s2">&quot;instead. See docstring for motivation and alternatives.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_std</span><span class="p">:</span>
                <span class="c1"># First pass</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;n_samples_seen_&#39;</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">mean_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_</span> <span class="o">=</span> <span class="n">mean_variance_axis</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="c1"># Next passes</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">mean_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span> <span class="o">=</span> \
                        <span class="n">incr_mean_variance_axis</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                                <span class="n">last_mean</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_</span><span class="p">,</span>
                                                <span class="n">last_var</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">var_</span><span class="p">,</span>
                                                <span class="n">last_n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">mean_</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">var_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># First pass</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;n_samples_seen_&#39;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">mean_</span> <span class="o">=</span> <span class="o">.</span><span class="mi">0</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_std</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">var_</span> <span class="o">=</span> <span class="o">.</span><span class="mi">0</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">var_</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">mean_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span> <span class="o">=</span> \
                <span class="n">_incremental_mean_and_var</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_std</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span> <span class="o">=</span> <span class="n">_handle_zeros_in_scale</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="StandardScaler.transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_standardscaler.html#ibex.sklearn.preprocessing.StandardScaler.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;deprecated&#39;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform standardization by centering and scaling</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape [n_samples, n_features]</span>
<span class="sd">            The data used to scale along the features axis.</span>
<span class="sd">        y : (ignored)</span>
<span class="sd">            .. deprecated:: 0.19</span>
<span class="sd">               This parameter will be removed in 0.21.</span>
<span class="sd">        copy : bool, optional (default: None)</span>
<span class="sd">            Copy the input X or not.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">string_types</span><span class="p">)</span> <span class="ow">or</span> <span class="n">y</span> <span class="o">!=</span> <span class="s1">&#39;deprecated&#39;</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;The parameter y on transform() is &quot;</span>
                          <span class="s2">&quot;deprecated since 0.19 and will be removed in 0.21&quot;</span><span class="p">,</span>
                          <span class="ne">DeprecationWarning</span><span class="p">)</span>

        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scale_&#39;</span><span class="p">)</span>

        <span class="n">copy</span> <span class="o">=</span> <span class="n">copy</span> <span class="k">if</span> <span class="n">copy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">,</span> <span class="n">warn_on_dtype</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">estimator</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_mean</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot center sparse matrices: pass `with_mean=False` &quot;</span>
                    <span class="s2">&quot;instead. See docstring for motivation and alternatives.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">inplace_column_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_mean</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_std</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
        <span class="k">return</span> <span class="n">X</span></div>

<div class="viewcode-block" id="StandardScaler.inverse_transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_standardscaler.html#ibex.sklearn.preprocessing.StandardScaler.inverse_transform">[docs]</a>    <span class="k">def</span> <span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Scale back the data to the original representation</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape [n_samples, n_features]</span>
<span class="sd">            The data used to scale along the features axis.</span>
<span class="sd">        copy : bool, optional (default: None)</span>
<span class="sd">            Copy the input X or not.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X_tr : array-like, shape [n_samples, n_features]</span>
<span class="sd">            Transformed array.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scale_&#39;</span><span class="p">)</span>

        <span class="n">copy</span> <span class="o">=</span> <span class="n">copy</span> <span class="k">if</span> <span class="n">copy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy</span>
        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_mean</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot uncenter sparse matrices: pass `with_mean=False` &quot;</span>
                    <span class="s2">&quot;instead See docstring for motivation and alternatives.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">sparse</span><span class="o">.</span><span class="n">isspmatrix_csr</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">tocsr</span><span class="p">()</span>
                <span class="n">copy</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="n">copy</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">inplace_column_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">copy</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_std</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_mean</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_</span>
        <span class="k">return</span> <span class="n">X</span></div>


<span class="k">class</span> <span class="nc">MaxAbsScaler</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Scale each feature by its maximum absolute value.</span>

<span class="sd">    This estimator scales and translates each feature individually such</span>
<span class="sd">    that the maximal absolute value of each feature in the</span>
<span class="sd">    training set will be 1.0. It does not shift/center the data, and</span>
<span class="sd">    thus does not destroy any sparsity.</span>

<span class="sd">    This scaler can also be applied to sparse CSR or CSC matrices.</span>

<span class="sd">    .. versionadded:: 0.17</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    copy : boolean, optional, default is True</span>
<span class="sd">        Set to False to perform inplace scaling and avoid a copy (if the input</span>
<span class="sd">        is already a numpy array).</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    scale_ : ndarray, shape (n_features,)</span>
<span class="sd">        Per feature relative scaling of the data.</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           *scale_* attribute.</span>

<span class="sd">    max_abs_ : ndarray, shape (n_features,)</span>
<span class="sd">        Per feature maximum absolute value.</span>

<span class="sd">    n_samples_seen_ : int</span>
<span class="sd">        The number of samples processed by the estimator. Will be reset on</span>
<span class="sd">        new calls to fit, but increments across ``partial_fit`` calls.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    maxabs_scale: Equivalent function without the estimator API.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    For a comparison of the different scalers, transformers, and normalizers,</span>
<span class="sd">    see :ref:`examples/preprocessing/plot_all_scaling.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">copy</span> <span class="o">=</span> <span class="n">copy</span>

    <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Reset internal data-dependent state of the scaler, if necessary.</span>

<span class="sd">        __init__ parameters are not touched.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Checking one attribute is enough, becase they are all set together</span>
        <span class="c1"># in partial_fit</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scale_&#39;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_abs_</span>

<div class="viewcode-block" id="MaxAbsScaler.fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_maxabsscaler.html#ibex.sklearn.preprocessing.MaxAbsScaler.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the maximum absolute value to be used for later scaling.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}, shape [n_samples, n_features]</span>
<span class="sd">            The data used to compute the per-feature minimum and maximum</span>
<span class="sd">            used for later scaling along the features axis.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Reset internal state before fitting</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></div>

<div class="viewcode-block" id="MaxAbsScaler.partial_fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_maxabsscaler.html#ibex.sklearn.preprocessing.MaxAbsScaler.partial_fit">[docs]</a>    <span class="k">def</span> <span class="nf">partial_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Online computation of max absolute value of X for later scaling.</span>
<span class="sd">        All of X is processed as a single batch. This is intended for cases</span>
<span class="sd">        when `fit` is not feasible due to very large number of `n_samples`</span>
<span class="sd">        or because X is read from a continuous stream.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}, shape [n_samples, n_features]</span>
<span class="sd">            The data used to compute the mean and standard deviation</span>
<span class="sd">            used for later scaling along the features axis.</span>

<span class="sd">        y : Passthrough for ``Pipeline`` compatibility.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="s1">&#39;csc&#39;</span><span class="p">),</span> <span class="n">copy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">,</span>
                        <span class="n">estimator</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">mins</span><span class="p">,</span> <span class="n">maxs</span> <span class="o">=</span> <span class="n">min_max_axis</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">max_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mins</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">maxs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">max_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># First pass</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;n_samples_seen_&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Next passes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">max_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_abs_</span><span class="p">,</span> <span class="n">max_abs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_samples_seen_</span> <span class="o">+=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_abs_</span> <span class="o">=</span> <span class="n">max_abs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span> <span class="o">=</span> <span class="n">_handle_zeros_in_scale</span><span class="p">(</span><span class="n">max_abs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="MaxAbsScaler.transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_maxabsscaler.html#ibex.sklearn.preprocessing.MaxAbsScaler.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Scale the data</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}</span>
<span class="sd">            The data that should be scaled.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scale_&#39;</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="s1">&#39;csc&#39;</span><span class="p">),</span> <span class="n">copy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">,</span>
                        <span class="n">estimator</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">inplace_column_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
        <span class="k">return</span> <span class="n">X</span></div>

<div class="viewcode-block" id="MaxAbsScaler.inverse_transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_maxabsscaler.html#ibex.sklearn.preprocessing.MaxAbsScaler.inverse_transform">[docs]</a>    <span class="k">def</span> <span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Scale back the data to the original representation</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}</span>
<span class="sd">            The data that should be transformed back.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scale_&#39;</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="s1">&#39;csc&#39;</span><span class="p">),</span> <span class="n">copy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">,</span>
                        <span class="n">estimator</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">inplace_column_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
        <span class="k">return</span> <span class="n">X</span></div>


<span class="k">def</span> <span class="nf">maxabs_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Scale each feature to the [-1, 1] range without breaking the sparsity.</span>

<span class="sd">    This estimator scales each feature individually such</span>
<span class="sd">    that the maximal absolute value of each feature in the</span>
<span class="sd">    training set will be 1.0.</span>

<span class="sd">    This scaler can also be applied to sparse CSR or CSC matrices.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape (n_samples, n_features)</span>
<span class="sd">        The data.</span>

<span class="sd">    axis : int (0 by default)</span>
<span class="sd">        axis used to scale along. If 0, independently scale each feature,</span>
<span class="sd">        otherwise (if 1) scale each sample.</span>

<span class="sd">    copy : boolean, optional, default is True</span>
<span class="sd">        Set to False to perform inplace scaling and avoid a copy (if the input</span>
<span class="sd">        is already a numpy array).</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    MaxAbsScaler: Performs scaling to the [-1, 1] range using the``Transformer`` API</span>
<span class="sd">        (e.g. as part of a preprocessing :class:`sklearn.pipeline.Pipeline`).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    For a comparison of the different scalers, transformers, and normalizers,</span>
<span class="sd">    see :ref:`examples/preprocessing/plot_all_scaling.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>
    <span class="c1"># Unlike the scaler object, this function allows 1d input.</span>

    <span class="c1"># If copy is required, it will be done inside the scaler object.</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="s1">&#39;csc&#39;</span><span class="p">),</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>
    <span class="n">original_ndim</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span>

    <span class="k">if</span> <span class="n">original_ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">s</span> <span class="o">=</span> <span class="n">MaxAbsScaler</span><span class="p">(</span><span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

    <span class="k">if</span> <span class="n">original_ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">X</span>


<span class="k">class</span> <span class="nc">RobustScaler</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Scale features using statistics that are robust to outliers.</span>

<span class="sd">    This Scaler removes the median and scales the data according to</span>
<span class="sd">    the quantile range (defaults to IQR: Interquartile Range).</span>
<span class="sd">    The IQR is the range between the 1st quartile (25th quantile)</span>
<span class="sd">    and the 3rd quartile (75th quantile).</span>

<span class="sd">    Centering and scaling happen independently on each feature (or each</span>
<span class="sd">    sample, depending on the ``axis`` argument) by computing the relevant</span>
<span class="sd">    statistics on the samples in the training set. Median and  interquartile</span>
<span class="sd">    range are then stored to be used on later data using the ``transform``</span>
<span class="sd">    method.</span>

<span class="sd">    Standardization of a dataset is a common requirement for many</span>
<span class="sd">    machine learning estimators. Typically this is done by removing the mean</span>
<span class="sd">    and scaling to unit variance. However, outliers can often influence the</span>
<span class="sd">    sample mean / variance in a negative way. In such cases, the median and</span>
<span class="sd">    the interquartile range often give better results.</span>

<span class="sd">    .. versionadded:: 0.17</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_scaler&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    with_centering : boolean, True by default</span>
<span class="sd">        If True, center the data before scaling.</span>
<span class="sd">        This will cause ``transform`` to raise an exception when attempted on</span>
<span class="sd">        sparse matrices, because centering them entails building a dense</span>
<span class="sd">        matrix which in common use cases is likely to be too large to fit in</span>
<span class="sd">        memory.</span>

<span class="sd">    with_scaling : boolean, True by default</span>
<span class="sd">        If True, scale the data to interquartile range.</span>

<span class="sd">    quantile_range : tuple (q_min, q_max), 0.0 &lt; q_min &lt; q_max &lt; 100.0</span>
<span class="sd">        Default: (25.0, 75.0) = (1st quantile, 3rd quantile) = IQR</span>
<span class="sd">        Quantile range used to calculate ``scale_``.</span>

<span class="sd">        .. versionadded:: 0.18</span>

<span class="sd">    copy : boolean, optional, default is True</span>
<span class="sd">        If False, try to avoid a copy and do inplace scaling instead.</span>
<span class="sd">        This is not guaranteed to always work inplace; e.g. if the data is</span>
<span class="sd">        not a NumPy array or scipy.sparse CSR matrix, a copy may still be</span>
<span class="sd">        returned.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    center_ : array of floats</span>
<span class="sd">        The median value for each feature in the training set.</span>

<span class="sd">    scale_ : array of floats</span>
<span class="sd">        The (scaled) interquartile range for each feature in the training set.</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           *scale_* attribute.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    robust_scale: Equivalent function without the estimator API.</span>

<span class="sd">    :class:`sklearn.decomposition.PCA`</span>
<span class="sd">        Further removes the linear correlation across features with</span>
<span class="sd">        &#39;whiten=True&#39;.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    For a comparison of the different scalers, transformers, and normalizers,</span>
<span class="sd">    see :ref:`examples/preprocessing/plot_all_scaling.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.</span>

<span class="sd">    https://en.wikipedia.org/wiki/Median_(statistics)</span>
<span class="sd">    https://en.wikipedia.org/wiki/Interquartile_range</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">with_centering</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_scaling</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">quantile_range</span><span class="o">=</span><span class="p">(</span><span class="mf">25.0</span><span class="p">,</span> <span class="mf">75.0</span><span class="p">),</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">with_centering</span> <span class="o">=</span> <span class="n">with_centering</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">with_scaling</span> <span class="o">=</span> <span class="n">with_scaling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantile_range</span> <span class="o">=</span> <span class="n">quantile_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">copy</span> <span class="o">=</span> <span class="n">copy</span>

    <span class="k">def</span> <span class="nf">_check_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">copy</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Makes sure centering is not enabled for sparse matrices.&quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="s1">&#39;csc&#39;</span><span class="p">),</span> <span class="n">copy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">,</span>
                        <span class="n">estimator</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_centering</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot center sparse matrices: use `with_centering=False`&quot;</span>
                    <span class="s2">&quot; instead. See docstring for motivation and alternatives.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span>

<div class="viewcode-block" id="RobustScaler.fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_robustscaler.html#ibex.sklearn.preprocessing.RobustScaler.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the median and quantiles to be used for scaling.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape [n_samples, n_features]</span>
<span class="sd">            The data used to compute the median and quantiles</span>
<span class="sd">            used for later scaling along the features axis.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;RobustScaler cannot be fitted on sparse inputs&quot;</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_centering</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">center_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_scaling</span><span class="p">:</span>
            <span class="n">q_min</span><span class="p">,</span> <span class="n">q_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantile_range</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">q_min</span> <span class="o">&lt;=</span> <span class="n">q_max</span> <span class="o">&lt;=</span> <span class="mi">100</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid quantile range: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span>
                                 <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantile_range</span><span class="p">))</span>

            <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantile_range</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span> <span class="o">=</span> <span class="p">(</span><span class="n">q</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span> <span class="o">=</span> <span class="n">_handle_zeros_in_scale</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale_</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="RobustScaler.transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_robustscaler.html#ibex.sklearn.preprocessing.RobustScaler.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Center and scale the data.</span>

<span class="sd">        Can be called on sparse input, provided that ``RobustScaler`` has been</span>
<span class="sd">        fitted to dense input and ``with_centering=False``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}</span>
<span class="sd">            The data used to scale along the specified axis.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_centering</span><span class="p">:</span>
            <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;center_&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_scaling</span><span class="p">:</span>
            <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scale_&#39;</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_scaling</span><span class="p">:</span>
                <span class="n">inplace_column_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_centering</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center_</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_scaling</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
        <span class="k">return</span> <span class="n">X</span></div>

<div class="viewcode-block" id="RobustScaler.inverse_transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_robustscaler.html#ibex.sklearn.preprocessing.RobustScaler.inverse_transform">[docs]</a>    <span class="k">def</span> <span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Scale back the data to the original representation</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like</span>
<span class="sd">            The data used to scale along the specified axis.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_centering</span><span class="p">:</span>
            <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;center_&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_scaling</span><span class="p">:</span>
            <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scale_&#39;</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_scaling</span><span class="p">:</span>
                <span class="n">inplace_column_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_scaling</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_centering</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center_</span>
        <span class="k">return</span> <span class="n">X</span></div>


<span class="k">def</span> <span class="nf">robust_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">with_centering</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_scaling</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">quantile_range</span><span class="o">=</span><span class="p">(</span><span class="mf">25.0</span><span class="p">,</span> <span class="mf">75.0</span><span class="p">),</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Standardize a dataset along any axis</span>

<span class="sd">    Center to the median and component wise scale</span>
<span class="sd">    according to the interquartile range.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_scaler&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like</span>
<span class="sd">        The data to center and scale.</span>

<span class="sd">    axis : int (0 by default)</span>
<span class="sd">        axis used to compute the medians and IQR along. If 0,</span>
<span class="sd">        independently scale each feature, otherwise (if 1) scale</span>
<span class="sd">        each sample.</span>

<span class="sd">    with_centering : boolean, True by default</span>
<span class="sd">        If True, center the data before scaling.</span>

<span class="sd">    with_scaling : boolean, True by default</span>
<span class="sd">        If True, scale the data to unit variance (or equivalently,</span>
<span class="sd">        unit standard deviation).</span>

<span class="sd">    quantile_range : tuple (q_min, q_max), 0.0 &lt; q_min &lt; q_max &lt; 100.0</span>
<span class="sd">        Default: (25.0, 75.0) = (1st quantile, 3rd quantile) = IQR</span>
<span class="sd">        Quantile range used to calculate ``scale_``.</span>

<span class="sd">        .. versionadded:: 0.18</span>

<span class="sd">    copy : boolean, optional, default is True</span>
<span class="sd">        set to False to perform inplace row normalization and avoid a</span>
<span class="sd">        copy (if the input is already a numpy array or a scipy.sparse</span>
<span class="sd">        CSR matrix and if axis is 1).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This implementation will refuse to center scipy.sparse matrices</span>
<span class="sd">    since it would make them non-sparse and would potentially crash the</span>
<span class="sd">    program with memory exhaustion problems.</span>

<span class="sd">    Instead the caller is expected to either set explicitly</span>
<span class="sd">    `with_centering=False` (in that case, only variance scaling will be</span>
<span class="sd">    performed on the features of the CSR matrix) or to call `X.toarray()`</span>
<span class="sd">    if he/she expects the materialized dense array to fit in memory.</span>

<span class="sd">    To avoid memory copy the caller should pass a CSR matrix.</span>

<span class="sd">    For a comparison of the different scalers, transformers, and normalizers,</span>
<span class="sd">    see :ref:`examples/preprocessing/plot_all_scaling.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    RobustScaler: Performs centering and scaling using the ``Transformer`` API</span>
<span class="sd">        (e.g. as part of a preprocessing :class:`sklearn.pipeline.Pipeline`).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">(</span><span class="n">with_centering</span><span class="o">=</span><span class="n">with_centering</span><span class="p">,</span> <span class="n">with_scaling</span><span class="o">=</span><span class="n">with_scaling</span><span class="p">,</span>
                     <span class="n">quantile_range</span><span class="o">=</span><span class="n">quantile_range</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">s</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">s</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>


<span class="k">class</span> <span class="nc">PolynomialFeatures</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate polynomial and interaction features.</span>

<span class="sd">    Generate a new feature matrix consisting of all polynomial combinations</span>
<span class="sd">    of the features with degree less than or equal to the specified degree.</span>
<span class="sd">    For example, if an input sample is two dimensional and of the form</span>
<span class="sd">    [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    degree : integer</span>
<span class="sd">        The degree of the polynomial features. Default = 2.</span>

<span class="sd">    interaction_only : boolean, default = False</span>
<span class="sd">        If true, only interaction features are produced: features that are</span>
<span class="sd">        products of at most ``degree`` *distinct* input features (so not</span>
<span class="sd">        ``x[1] ** 2``, ``x[0] * x[2] ** 3``, etc.).</span>

<span class="sd">    include_bias : boolean</span>
<span class="sd">        If True (default), then include a bias column, the feature in which</span>
<span class="sd">        all polynomial powers are zero (i.e. a column of ones - acts as an</span>
<span class="sd">        intercept term in a linear model).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; X = np.arange(6).reshape(3, 2)</span>
<span class="sd">    &gt;&gt;&gt; X</span>
<span class="sd">    array([[0, 1],</span>
<span class="sd">           [2, 3],</span>
<span class="sd">           [4, 5]])</span>
<span class="sd">    &gt;&gt;&gt; poly = PolynomialFeatures(2)</span>
<span class="sd">    &gt;&gt;&gt; poly.fit_transform(X)</span>
<span class="sd">    array([[  1.,   0.,   1.,   0.,   0.,   1.],</span>
<span class="sd">           [  1.,   2.,   3.,   4.,   6.,   9.],</span>
<span class="sd">           [  1.,   4.,   5.,  16.,  20.,  25.]])</span>
<span class="sd">    &gt;&gt;&gt; poly = PolynomialFeatures(interaction_only=True)</span>
<span class="sd">    &gt;&gt;&gt; poly.fit_transform(X)</span>
<span class="sd">    array([[  1.,   0.,   1.,   0.],</span>
<span class="sd">           [  1.,   2.,   3.,   6.],</span>
<span class="sd">           [  1.,   4.,   5.,  20.]])</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    powers_ : array, shape (n_output_features, n_input_features)</span>
<span class="sd">        powers_[i, j] is the exponent of the jth input in the ith output.</span>

<span class="sd">    n_input_features_ : int</span>
<span class="sd">        The total number of input features.</span>

<span class="sd">    n_output_features_ : int</span>
<span class="sd">        The total number of polynomial output features. The number of output</span>
<span class="sd">        features is computed by iterating over all suitably sized combinations</span>
<span class="sd">        of input features.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Be aware that the number of features in the output array scales</span>
<span class="sd">    polynomially in the number of features of the input array, and</span>
<span class="sd">    exponentially in the degree. High degrees can cause overfitting.</span>

<span class="sd">    See :ref:`examples/linear_model/plot_polynomial_interpolation.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py&gt;`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">=</span> <span class="n">degree</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interaction_only</span> <span class="o">=</span> <span class="n">interaction_only</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">include_bias</span> <span class="o">=</span> <span class="n">include_bias</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_combinations</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">degree</span><span class="p">,</span> <span class="n">interaction_only</span><span class="p">,</span> <span class="n">include_bias</span><span class="p">):</span>
        <span class="n">comb</span> <span class="o">=</span> <span class="p">(</span><span class="n">combinations</span> <span class="k">if</span> <span class="n">interaction_only</span> <span class="k">else</span> <span class="n">combinations_w_r</span><span class="p">)</span>
        <span class="n">start</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="ow">not</span> <span class="n">include_bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="n">comb</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">i</span><span class="p">)</span>
                                   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">powers_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;n_input_features_&#39;</span><span class="p">)</span>

        <span class="n">combinations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combinations</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_input_features_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">interaction_only</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">include_bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_input_features_</span><span class="p">)</span>
                         <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_feature_names</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return feature names for output features</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_features : list of string, length n_features, optional</span>
<span class="sd">            String names for input features if available. By default,</span>
<span class="sd">            &quot;x0&quot;, &quot;x1&quot;, ... &quot;xn_features&quot; is used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        output_feature_names : list of string, length n_output_features</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">powers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">powers_</span>
        <span class="k">if</span> <span class="n">input_features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;x</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">powers</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
        <span class="n">feature_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">powers</span><span class="p">:</span>
            <span class="n">inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">row</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inds</span><span class="p">):</span>
                <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">^</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">input_features</span><span class="p">[</span><span class="n">ind</span><span class="p">],</span> <span class="n">exp</span><span class="p">)</span>
                                <span class="k">if</span> <span class="n">exp</span> <span class="o">!=</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">input_features</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
                                <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">exp</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inds</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="n">inds</span><span class="p">]))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>
            <span class="n">feature_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">feature_names</span>

<div class="viewcode-block" id="PolynomialFeatures.fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_polynomialfeatures.html#ibex.sklearn.preprocessing.PolynomialFeatures.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute number of output features.</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            The data.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : instance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">combinations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combinations</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">interaction_only</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">include_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_input_features_</span> <span class="o">=</span> <span class="n">n_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_output_features_</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="PolynomialFeatures.transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_polynomialfeatures.html#ibex.sklearn.preprocessing.PolynomialFeatures.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Transform data to polynomial features</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape [n_samples, n_features]</span>
<span class="sd">            The data to transform, row by row.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        XP : np.ndarray shape [n_samples, NP]</span>
<span class="sd">            The matrix of features, where NP is the number of polynomial</span>
<span class="sd">            features generated from the combination of inputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;n_input_features_&#39;</span><span class="p">,</span> <span class="s1">&#39;n_output_features_&#39;</span><span class="p">])</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="n">n_features</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_input_features_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X shape does not match training shape&quot;</span><span class="p">)</span>

        <span class="c1"># allocate output data</span>
        <span class="n">XP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_output_features_</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">combinations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combinations</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">interaction_only</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">include_bias</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">combinations</span><span class="p">):</span>
            <span class="n">XP</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">XP</span></div>


<span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Scale input vectors individually to unit norm (vector length).</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_normalization&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {array-like, sparse matrix}, shape [n_samples, n_features]</span>
<span class="sd">        The data to normalize, element by element.</span>
<span class="sd">        scipy.sparse matrices should be in CSR format to avoid an</span>
<span class="sd">        un-necessary copy.</span>

<span class="sd">    norm : &#39;l1&#39;, &#39;l2&#39;, or &#39;max&#39;, optional (&#39;l2&#39; by default)</span>
<span class="sd">        The norm to use to normalize each non zero sample (or each non-zero</span>
<span class="sd">        feature if axis is 0).</span>

<span class="sd">    axis : 0 or 1, optional (1 by default)</span>
<span class="sd">        axis used to normalize the data along. If 1, independently normalize</span>
<span class="sd">        each sample, otherwise (if 0) normalize each feature.</span>

<span class="sd">    copy : boolean, optional, default True</span>
<span class="sd">        set to False to perform inplace row normalization and avoid a</span>
<span class="sd">        copy (if the input is already a numpy array or a scipy.sparse</span>
<span class="sd">        CSR matrix and if axis is 1).</span>

<span class="sd">    return_norm : boolean, default False</span>
<span class="sd">        whether to return the computed norms</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    X : {array-like, sparse matrix}, shape [n_samples, n_features]</span>
<span class="sd">        Normalized input X.</span>

<span class="sd">    norms : array, shape [n_samples] if axis=1 else [n_features]</span>
<span class="sd">        An array of norms along given axis for X.</span>
<span class="sd">        When X is sparse, a NotImplementedError will be raised</span>
<span class="sd">        for norm &#39;l1&#39; or &#39;l2&#39;.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    Normalizer: Performs normalization using the ``Transformer`` API</span>
<span class="sd">        (e.g. as part of a preprocessing :class:`sklearn.pipeline.Pipeline`).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    For a comparison of the different scalers, transformers, and normalizers,</span>
<span class="sd">    see :ref:`examples/preprocessing/plot_all_scaling.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">norm</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;&#39;</span><span class="si">%s</span><span class="s2">&#39; is not a supported norm&quot;</span> <span class="o">%</span> <span class="n">norm</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">sparse_format</span> <span class="o">=</span> <span class="s1">&#39;csc&#39;</span>
    <span class="k">elif</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">sparse_format</span> <span class="o">=</span> <span class="s1">&#39;csr&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;&#39;</span><span class="si">%d</span><span class="s2">&#39; is not a supported axis&quot;</span> <span class="o">%</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sparse_format</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">,</span>
                    <span class="n">estimator</span><span class="o">=</span><span class="s1">&#39;the normalize function&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span>

    <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">return_norm</span> <span class="ow">and</span> <span class="n">norm</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;return_norm=True is not implemented &quot;</span>
                                      <span class="s2">&quot;for sparse matrices with norm &#39;l1&#39; &quot;</span>
                                      <span class="s2">&quot;or norm &#39;l2&#39;&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;l1&#39;</span><span class="p">:</span>
            <span class="n">inplace_csr_row_normalize_l1</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;l2&#39;</span><span class="p">:</span>
            <span class="n">inplace_csr_row_normalize_l2</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">norms</span> <span class="o">=</span> <span class="n">min_max_axis</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">norms_elementwise</span> <span class="o">=</span> <span class="n">norms</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">indptr</span><span class="p">))</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">norms_elementwise</span> <span class="o">!=</span> <span class="mi">0</span>
            <span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">/=</span> <span class="n">norms_elementwise</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;l1&#39;</span><span class="p">:</span>
            <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;l2&#39;</span><span class="p">:</span>
            <span class="n">norms</span> <span class="o">=</span> <span class="n">row_norms</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
            <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">norms</span> <span class="o">=</span> <span class="n">_handle_zeros_in_scale</span><span class="p">(</span><span class="n">norms</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">/=</span> <span class="n">norms</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span>

    <span class="k">if</span> <span class="n">return_norm</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">norms</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">X</span>


<span class="k">class</span> <span class="nc">Normalizer</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Normalize samples individually to unit norm.</span>

<span class="sd">    Each sample (i.e. each row of the data matrix) with at least one</span>
<span class="sd">    non zero component is rescaled independently of other samples so</span>
<span class="sd">    that its norm (l1 or l2) equals one.</span>

<span class="sd">    This transformer is able to work both with dense numpy arrays and</span>
<span class="sd">    scipy.sparse matrix (use CSR format if you want to avoid the burden of</span>
<span class="sd">    a copy / conversion).</span>

<span class="sd">    Scaling inputs to unit norms is a common operation for text</span>
<span class="sd">    classification or clustering for instance. For instance the dot</span>
<span class="sd">    product of two l2-normalized TF-IDF vectors is the cosine similarity</span>
<span class="sd">    of the vectors and is the base similarity metric for the Vector</span>
<span class="sd">    Space Model commonly used by the Information Retrieval community.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_normalization&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    norm : &#39;l1&#39;, &#39;l2&#39;, or &#39;max&#39;, optional (&#39;l2&#39; by default)</span>
<span class="sd">        The norm to use to normalize each non zero sample.</span>

<span class="sd">    copy : boolean, optional, default True</span>
<span class="sd">        set to False to perform inplace row normalization and avoid a</span>
<span class="sd">        copy (if the input is already a numpy array or a scipy.sparse</span>
<span class="sd">        CSR matrix).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This estimator is stateless (besides constructor parameters), the</span>
<span class="sd">    fit method does nothing but is useful when used in a pipeline.</span>

<span class="sd">    For a comparison of the different scalers, transformers, and normalizers,</span>
<span class="sd">    see :ref:`examples/preprocessing/plot_all_scaling.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.</span>


<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    normalize: Equivalent function without the estimator API.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">copy</span> <span class="o">=</span> <span class="n">copy</span>

<div class="viewcode-block" id="Normalizer.fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_normalizer.html#ibex.sklearn.preprocessing.Normalizer.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Do nothing and return the estimator unchanged</span>

<span class="sd">        This method is just there to implement the usual API and hence</span>
<span class="sd">        work in pipelines.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="Normalizer.transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_normalizer.html#ibex.sklearn.preprocessing.Normalizer.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;deprecated&#39;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Scale each non zero row of X to unit norm</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}, shape [n_samples, n_features]</span>
<span class="sd">            The data to normalize, row by row. scipy.sparse matrices should be</span>
<span class="sd">            in CSR format to avoid an un-necessary copy.</span>
<span class="sd">        y : (ignored)</span>
<span class="sd">            .. deprecated:: 0.19</span>
<span class="sd">               This parameter will be removed in 0.21.</span>
<span class="sd">        copy : bool, optional (default: None)</span>
<span class="sd">            Copy the input X or not.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">string_types</span><span class="p">)</span> <span class="ow">or</span> <span class="n">y</span> <span class="o">!=</span> <span class="s1">&#39;deprecated&#39;</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;The parameter y on transform() is &quot;</span>
                          <span class="s2">&quot;deprecated since 0.19 and will be removed in 0.21&quot;</span><span class="p">,</span>
                          <span class="ne">DeprecationWarning</span><span class="p">)</span>

        <span class="n">copy</span> <span class="o">=</span> <span class="n">copy</span> <span class="k">if</span> <span class="n">copy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">normalize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">binarize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Boolean thresholding of array-like or scipy.sparse matrix</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_binarization&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {array-like, sparse matrix}, shape [n_samples, n_features]</span>
<span class="sd">        The data to binarize, element by element.</span>
<span class="sd">        scipy.sparse matrices should be in CSR or CSC format to avoid an</span>
<span class="sd">        un-necessary copy.</span>

<span class="sd">    threshold : float, optional (0.0 by default)</span>
<span class="sd">        Feature values below or equal to this are replaced by 0, above it by 1.</span>
<span class="sd">        Threshold may not be less than 0 for operations on sparse matrices.</span>

<span class="sd">    copy : boolean, optional, default True</span>
<span class="sd">        set to False to perform inplace binarization and avoid a copy</span>
<span class="sd">        (if the input is already a numpy array or a scipy.sparse CSR / CSC</span>
<span class="sd">        matrix and if axis is 1).</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    Binarizer: Performs binarization using the ``Transformer`` API</span>
<span class="sd">        (e.g. as part of a preprocessing :class:`sklearn.pipeline.Pipeline`).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="s1">&#39;csc&#39;</span><span class="p">],</span> <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">threshold</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot binarize a sparse matrix with threshold &#39;</span>
                             <span class="s1">&#39;&lt; 0&#39;</span><span class="p">)</span>
        <span class="n">cond</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span> <span class="o">&gt;</span> <span class="n">threshold</span>
        <span class="n">not_cond</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">cond</span><span class="p">)</span>
        <span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">cond</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">not_cond</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">X</span><span class="o">.</span><span class="n">eliminate_zeros</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cond</span> <span class="o">=</span> <span class="n">X</span> <span class="o">&gt;</span> <span class="n">threshold</span>
        <span class="n">not_cond</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">cond</span><span class="p">)</span>
        <span class="n">X</span><span class="p">[</span><span class="n">cond</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">X</span><span class="p">[</span><span class="n">not_cond</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">X</span>


<span class="k">class</span> <span class="nc">Binarizer</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Binarize data (set feature values to 0 or 1) according to a threshold</span>

<span class="sd">    Values greater than the threshold map to 1, while values less than</span>
<span class="sd">    or equal to the threshold map to 0. With the default threshold of 0,</span>
<span class="sd">    only positive values map to 1.</span>

<span class="sd">    Binarization is a common operation on text count data where the</span>
<span class="sd">    analyst can decide to only consider the presence or absence of a</span>
<span class="sd">    feature rather than a quantified number of occurrences for instance.</span>

<span class="sd">    It can also be used as a pre-processing step for estimators that</span>
<span class="sd">    consider boolean random variables (e.g. modelled using the Bernoulli</span>
<span class="sd">    distribution in a Bayesian setting).</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_binarization&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    threshold : float, optional (0.0 by default)</span>
<span class="sd">        Feature values below or equal to this are replaced by 0, above it by 1.</span>
<span class="sd">        Threshold may not be less than 0 for operations on sparse matrices.</span>

<span class="sd">    copy : boolean, optional, default True</span>
<span class="sd">        set to False to perform inplace binarization and avoid a copy (if</span>
<span class="sd">        the input is already a numpy array or a scipy.sparse CSR matrix).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If the input is a sparse matrix, only the non-zero values are subject</span>
<span class="sd">    to update by the Binarizer class.</span>

<span class="sd">    This estimator is stateless (besides constructor parameters), the</span>
<span class="sd">    fit method does nothing but is useful when used in a pipeline.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    binarize: Equivalent function without the estimator API.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">copy</span> <span class="o">=</span> <span class="n">copy</span>

<div class="viewcode-block" id="Binarizer.fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_binarizer.html#ibex.sklearn.preprocessing.Binarizer.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Do nothing and return the estimator unchanged</span>

<span class="sd">        This method is just there to implement the usual API and hence</span>
<span class="sd">        work in pipelines.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="Binarizer.transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_binarizer.html#ibex.sklearn.preprocessing.Binarizer.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;deprecated&#39;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Binarize each element of X</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}, shape [n_samples, n_features]</span>
<span class="sd">            The data to binarize, element by element.</span>
<span class="sd">            scipy.sparse matrices should be in CSR format to avoid an</span>
<span class="sd">            un-necessary copy.</span>
<span class="sd">        y : (ignored)</span>
<span class="sd">            .. deprecated:: 0.19</span>
<span class="sd">               This parameter will be removed in 0.21.</span>
<span class="sd">        copy : bool</span>
<span class="sd">            Copy the input X or not.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">string_types</span><span class="p">)</span> <span class="ow">or</span> <span class="n">y</span> <span class="o">!=</span> <span class="s1">&#39;deprecated&#39;</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;The parameter y on transform() is &quot;</span>
                          <span class="s2">&quot;deprecated since 0.19 and will be removed in 0.21&quot;</span><span class="p">,</span>
                          <span class="ne">DeprecationWarning</span><span class="p">)</span>

        <span class="n">copy</span> <span class="o">=</span> <span class="n">copy</span> <span class="k">if</span> <span class="n">copy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy</span>
        <span class="k">return</span> <span class="n">binarize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">KernelCenterer</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Center a kernel matrix</span>

<span class="sd">    Let K(x, z) be a kernel defined by phi(x)^T phi(z), where phi is a</span>
<span class="sd">    function mapping x to a Hilbert space. KernelCenterer centers (i.e.,</span>
<span class="sd">    normalize to have zero mean) the data without explicitly computing phi(x).</span>
<span class="sd">    It is equivalent to centering phi(x) with</span>
<span class="sd">    sklearn.preprocessing.StandardScaler(with_std=False).</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;kernel_centering&gt;`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="KernelCenterer.fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_kernelcenterer.html#ibex.sklearn.preprocessing.KernelCenterer.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit KernelCenterer</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        K : numpy array of shape [n_samples, n_samples]</span>
<span class="sd">            Kernel matrix.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : returns an instance of self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K_fit_rows_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K_fit_all_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K_fit_rows_</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">n_samples</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="KernelCenterer.transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_kernelcenterer.html#ibex.sklearn.preprocessing.KernelCenterer.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;deprecated&#39;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Center kernel matrix.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        K : numpy array of shape [n_samples1, n_samples2]</span>
<span class="sd">            Kernel matrix.</span>
<span class="sd">        y : (ignored)</span>
<span class="sd">            .. deprecated:: 0.19</span>
<span class="sd">               This parameter will be removed in 0.21.</span>
<span class="sd">        copy : boolean, optional, default True</span>
<span class="sd">            Set to False to perform inplace computation.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K_new : numpy array of shape [n_samples1, n_samples2]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">string_types</span><span class="p">)</span> <span class="ow">or</span> <span class="n">y</span> <span class="o">!=</span> <span class="s1">&#39;deprecated&#39;</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;The parameter y on transform() is &quot;</span>
                          <span class="s2">&quot;deprecated since 0.19 and will be removed in 0.21&quot;</span><span class="p">,</span>
                          <span class="ne">DeprecationWarning</span><span class="p">)</span>

        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;K_fit_all_&#39;</span><span class="p">)</span>

        <span class="n">K</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>

        <span class="n">K_pred_cols</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span>
                       <span class="bp">self</span><span class="o">.</span><span class="n">K_fit_rows_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

        <span class="n">K</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K_fit_rows_</span>
        <span class="n">K</span> <span class="o">-=</span> <span class="n">K_pred_cols</span>
        <span class="n">K</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K_fit_all_</span>

        <span class="k">return</span> <span class="n">K</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pairwise</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">True</span>


<span class="k">def</span> <span class="nf">add_dummy_feature</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Augment dataset with an additional dummy feature.</span>

<span class="sd">    This is useful for fitting an intercept term with implementations which</span>
<span class="sd">    cannot otherwise fit it directly.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {array-like, sparse matrix}, shape [n_samples, n_features]</span>
<span class="sd">        Data.</span>

<span class="sd">    value : float</span>
<span class="sd">        Value to use for the dummy feature.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    X : {array, sparse matrix}, shape [n_samples, n_features + 1]</span>
<span class="sd">        Same data with dummy feature added as first column.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; from sklearn.preprocessing import add_dummy_feature</span>
<span class="sd">    &gt;&gt;&gt; add_dummy_feature([[0, 1], [1, 0]])</span>
<span class="sd">    array([[ 1.,  0.,  1.],</span>
<span class="sd">           [ 1.,  1.,  0.]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;csc&#39;</span><span class="p">,</span> <span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="s1">&#39;coo&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">isspmatrix_coo</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="c1"># Shift columns to the right.</span>
            <span class="n">col</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">col</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="c1"># Column indices of dummy feature are 0 everywhere.</span>
            <span class="n">col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">col</span><span class="p">))</span>
            <span class="c1"># Row indices of dummy feature are 0, ..., n_samples-1.</span>
            <span class="n">row</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">X</span><span class="o">.</span><span class="n">row</span><span class="p">))</span>
            <span class="c1"># Prepend the dummy feature n_samples times.</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="n">value</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">sparse</span><span class="o">.</span><span class="n">coo_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">)),</span> <span class="n">shape</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">sparse</span><span class="o">.</span><span class="n">isspmatrix_csc</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="c1"># Shift index pointers since we need to add n_samples elements.</span>
            <span class="n">indptr</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">indptr</span> <span class="o">+</span> <span class="n">n_samples</span>
            <span class="c1"># indptr[0] must be 0.</span>
            <span class="n">indptr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span> <span class="n">indptr</span><span class="p">))</span>
            <span class="c1"># Row indices of dummy feature are 0, ..., n_samples-1.</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">X</span><span class="o">.</span><span class="n">indices</span><span class="p">))</span>
            <span class="c1"># Prepend the dummy feature n_samples times.</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="n">value</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csc_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">indptr</span><span class="p">),</span> <span class="n">shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">klass</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="vm">__class__</span>
            <span class="k">return</span> <span class="n">klass</span><span class="p">(</span><span class="n">add_dummy_feature</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">tocoo</span><span class="p">(),</span> <span class="n">value</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">value</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_transform_selected</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">transform</span><span class="p">,</span> <span class="n">selected</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply a transform function to portion of selected features</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {array-like, sparse matrix}, shape [n_samples, n_features]</span>
<span class="sd">        Dense array or sparse matrix.</span>

<span class="sd">    transform : callable</span>
<span class="sd">        A callable transform(X) -&gt; X_transformed</span>

<span class="sd">    copy : boolean, optional</span>
<span class="sd">        Copy X even if it could be avoided.</span>

<span class="sd">    selected: &quot;all&quot; or array of indices or mask</span>
<span class="sd">        Specify which features to apply the transform to.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    X : array or sparse matrix, shape=(n_samples, n_features_new)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s1">&#39;csc&#39;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_DTYPES</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">selected</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">)</span> <span class="ow">and</span> <span class="n">selected</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">selected</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">X</span>

    <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span>
    <span class="n">sel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="n">sel</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">selected</span><span class="p">)]</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">not_sel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">sel</span><span class="p">)</span>
    <span class="n">n_selected</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sel</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n_selected</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># No features selected.</span>
        <span class="k">return</span> <span class="n">X</span>
    <span class="k">elif</span> <span class="n">n_selected</span> <span class="o">==</span> <span class="n">n_features</span><span class="p">:</span>
        <span class="c1"># All features selected.</span>
        <span class="k">return</span> <span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X_sel</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">ind</span><span class="p">[</span><span class="n">sel</span><span class="p">]])</span>
        <span class="n">X_not_sel</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">ind</span><span class="p">[</span><span class="n">not_sel</span><span class="p">]]</span>

        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X_sel</span><span class="p">)</span> <span class="ow">or</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X_not_sel</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_sel</span><span class="p">,</span> <span class="n">X_not_sel</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_sel</span><span class="p">,</span> <span class="n">X_not_sel</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Encode categorical integer features using a one-hot aka one-of-K scheme.</span>

<span class="sd">    The input to this transformer should be a matrix of integers, denoting</span>
<span class="sd">    the values taken on by categorical (discrete) features. The output will be</span>
<span class="sd">    a sparse matrix where each column corresponds to one possible value of one</span>
<span class="sd">    feature. It is assumed that input features take on values in the range</span>
<span class="sd">    [0, n_values).</span>

<span class="sd">    This encoding is needed for feeding categorical data to many scikit-learn</span>
<span class="sd">    estimators, notably linear models and SVMs with the standard kernels.</span>

<span class="sd">    Note: a one-hot encoding of y labels should use a LabelBinarizer</span>
<span class="sd">    instead.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_categorical_features&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_values : &#39;auto&#39;, int or array of ints</span>
<span class="sd">        Number of values per feature.</span>

<span class="sd">        - &#39;auto&#39; : determine value range from training data.</span>
<span class="sd">        - int : number of categorical values per feature.</span>
<span class="sd">                Each feature value should be in ``range(n_values)``</span>
<span class="sd">        - array : ``n_values[i]`` is the number of categorical values in</span>
<span class="sd">                  ``X[:, i]``. Each feature value should be</span>
<span class="sd">                  in ``range(n_values[i])``</span>

<span class="sd">    categorical_features : &quot;all&quot; or array of indices or mask</span>
<span class="sd">        Specify what features are treated as categorical.</span>

<span class="sd">        - &#39;all&#39; (default): All features are treated as categorical.</span>
<span class="sd">        - array of indices: Array of categorical feature indices.</span>
<span class="sd">        - mask: Array of length n_features and with dtype=bool.</span>

<span class="sd">        Non-categorical features are always stacked to the right of the matrix.</span>

<span class="sd">    dtype : number type, default=np.float</span>
<span class="sd">        Desired dtype of output.</span>

<span class="sd">    sparse : boolean, default=True</span>
<span class="sd">        Will return sparse matrix if set True else will return an array.</span>

<span class="sd">    handle_unknown : str, &#39;error&#39; or &#39;ignore&#39;</span>
<span class="sd">        Whether to raise an error or ignore if a unknown categorical feature is</span>
<span class="sd">        present during transform.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    active_features_ : array</span>
<span class="sd">        Indices for active features, meaning values that actually occur</span>
<span class="sd">        in the training set. Only available when n_values is ``&#39;auto&#39;``.</span>

<span class="sd">    feature_indices_ : array of shape (n_features,)</span>
<span class="sd">        Indices to feature ranges.</span>
<span class="sd">        Feature ``i`` in the original data is mapped to features</span>
<span class="sd">        from ``feature_indices_[i]`` to ``feature_indices_[i+1]``</span>
<span class="sd">        (and then potentially masked by `active_features_` afterwards)</span>

<span class="sd">    n_values_ : array of shape (n_features,)</span>
<span class="sd">        Maximum number of values per feature.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Given a dataset with three features and four samples, we let the encoder</span>
<span class="sd">    find the maximum value per feature and transform the data to a binary</span>
<span class="sd">    one-hot encoding.</span>

<span class="sd">    &gt;&gt;&gt; from sklearn.preprocessing import OneHotEncoder</span>
<span class="sd">    &gt;&gt;&gt; enc = OneHotEncoder()</span>
<span class="sd">    &gt;&gt;&gt; enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], \</span>
<span class="sd">[1, 0, 2]])  # doctest: +ELLIPSIS</span>
<span class="sd">    OneHotEncoder(categorical_features=&#39;all&#39;, dtype=&lt;... &#39;numpy.float64&#39;&gt;,</span>
<span class="sd">           handle_unknown=&#39;error&#39;, n_values=&#39;auto&#39;, sparse=True)</span>
<span class="sd">    &gt;&gt;&gt; enc.n_values_</span>
<span class="sd">    array([2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; enc.feature_indices_</span>
<span class="sd">    array([0, 2, 5, 9])</span>
<span class="sd">    &gt;&gt;&gt; enc.transform([[0, 1, 1]]).toarray()</span>
<span class="sd">    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.]])</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of</span>
<span class="sd">      dictionary items (also handles string-valued features).</span>
<span class="sd">    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot</span>
<span class="sd">      encoding of dictionary items or strings.</span>
<span class="sd">    sklearn.preprocessing.LabelBinarizer : binarizes labels in a one-vs-all</span>
<span class="sd">      fashion.</span>
<span class="sd">    sklearn.preprocessing.MultiLabelBinarizer : transforms between iterable of</span>
<span class="sd">      iterables and a multilabel format, e.g. a (samples x classes) binary</span>
<span class="sd">      matrix indicating the presence of a class label.</span>
<span class="sd">    sklearn.preprocessing.LabelEncoder : encodes labels with values between 0</span>
<span class="sd">      and n_classes-1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_values</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">categorical_features</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
                 <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;error&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_values</span> <span class="o">=</span> <span class="n">n_values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">categorical_features</span> <span class="o">=</span> <span class="n">categorical_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="o">=</span> <span class="n">sparse</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">handle_unknown</span> <span class="o">=</span> <span class="n">handle_unknown</span>

<div class="viewcode-block" id="OneHotEncoder.fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_onehotencoder.html#ibex.sklearn.preprocessing.OneHotEncoder.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit OneHotEncoder to X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape [n_samples, n_feature]</span>
<span class="sd">            Input array of type int.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="k">def</span> <span class="nf">_fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Assumes X contains only categorical features.&quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">X</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X needs to contain only non-negative integers.&quot;</span><span class="p">)</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_values</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">)</span> <span class="ow">and</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_values</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span><span class="p">):</span>
            <span class="n">n_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_values</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_values</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Feature out of bounds for n_values=</span><span class="si">%d</span><span class="s2">&quot;</span>
                                 <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_values</span><span class="p">)</span>
            <span class="n">n_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
            <span class="n">n_values</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_values</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">n_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Wrong type for parameter `n_values`. Expected&quot;</span>
                                <span class="s2">&quot; &#39;auto&#39;, int or array of ints, got </span><span class="si">%r</span><span class="s2">&quot;</span>
                                <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">n_values</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">n_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Shape mismatch: if n_values is an array,&quot;</span>
                                 <span class="s2">&quot; it has to be of shape (n_features,).&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_values_</span> <span class="o">=</span> <span class="n">n_values</span>
        <span class="n">n_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n_values</span><span class="p">])</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">n_values</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_indices_</span> <span class="o">=</span> <span class="n">indices</span>

        <span class="n">column_indices</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">+</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="n">row_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
                                <span class="n">n_features</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">*</span> <span class="n">n_features</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">coo_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">row_indices</span><span class="p">,</span> <span class="n">column_indices</span><span class="p">)),</span>
                                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">indices</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">tocsr</span><span class="p">()</span>

        <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_values</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">)</span> <span class="ow">and</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_values</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span><span class="p">):</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span>
            <span class="n">active_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:,</span> <span class="n">active_features</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">active_features_</span> <span class="o">=</span> <span class="n">active_features</span>

        <span class="k">return</span> <span class="n">out</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="k">else</span> <span class="n">out</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

<div class="viewcode-block" id="OneHotEncoder.fit_transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_onehotencoder.html#ibex.sklearn.preprocessing.OneHotEncoder.fit_transform">[docs]</a>    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit OneHotEncoder to X, then transform X.</span>

<span class="sd">        Equivalent to self.fit(X).transform(X), but more convenient and more</span>
<span class="sd">        efficient. See fit for the parameters, transform for the return value.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape [n_samples, n_feature]</span>
<span class="sd">            Input array of type int.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_transform_selected</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_transform</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">categorical_features</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Assumes X contains only categorical features.&quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">X</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X needs to contain only non-negative integers.&quot;</span><span class="p">)</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_indices_</span>
        <span class="k">if</span> <span class="n">n_features</span> <span class="o">!=</span> <span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X has different shape than during fitting.&quot;</span>
                             <span class="s2">&quot; Expected </span><span class="si">%d</span><span class="s2">, got </span><span class="si">%d</span><span class="s2">.&quot;</span>
                             <span class="o">%</span> <span class="p">(</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>

        <span class="c1"># We use only those categorical features of X that are known using fit.</span>
        <span class="c1"># i.e lesser than n_values_ using mask.</span>
        <span class="c1"># This means, if self.handle_unknown is &quot;ignore&quot;, the row_indices and</span>
        <span class="c1"># col_indices corresponding to the unknown categorical feature are</span>
        <span class="c1"># ignored.</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_values_</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">handle_unknown</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">,</span> <span class="s1">&#39;ignore&#39;</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;handle_unknown should be either error or &quot;</span>
                                 <span class="s2">&quot;unknown got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">handle_unknown</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">handle_unknown</span> <span class="o">==</span> <span class="s1">&#39;error&#39;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;unknown categorical feature present </span><span class="si">%s</span><span class="s2"> &quot;</span>
                                 <span class="s2">&quot;during transform.&quot;</span> <span class="o">%</span> <span class="n">X</span><span class="o">.</span><span class="n">ravel</span><span class="p">()[</span><span class="o">~</span><span class="n">mask</span><span class="p">])</span>

        <span class="n">column_indices</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">+</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">ravel</span><span class="p">()[</span><span class="n">mask</span><span class="p">]</span>
        <span class="n">row_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
                                <span class="n">n_features</span><span class="p">)[</span><span class="n">mask</span><span class="p">]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">coo_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">row_indices</span><span class="p">,</span> <span class="n">column_indices</span><span class="p">)),</span>
                                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">indices</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">tocsr</span><span class="p">()</span>
        <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_values</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">)</span> <span class="ow">and</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_values</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_features_</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">out</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="k">else</span> <span class="n">out</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

<div class="viewcode-block" id="OneHotEncoder.transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_onehotencoder.html#ibex.sklearn.preprocessing.OneHotEncoder.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Transform X using one-hot encoding.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape [n_samples, n_features]</span>
<span class="sd">            Input array of type int.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X_out : sparse matrix if sparse=True else a 2-d array, dtype=int</span>
<span class="sd">            Transformed input.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_transform_selected</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">categorical_features</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">QuantileTransformer</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Transform features using quantiles information.</span>

<span class="sd">    This method transforms the features to follow a uniform or a normal</span>
<span class="sd">    distribution. Therefore, for a given feature, this transformation tends</span>
<span class="sd">    to spread out the most frequent values. It also reduces the impact of</span>
<span class="sd">    (marginal) outliers: this is therefore a robust preprocessing scheme.</span>

<span class="sd">    The transformation is applied on each feature independently.</span>
<span class="sd">    The cumulative density function of a feature is used to project the</span>
<span class="sd">    original values. Features values of new/unseen data that fall below</span>
<span class="sd">    or above the fitted range will be mapped to the bounds of the output</span>
<span class="sd">    distribution. Note that this transform is non-linear. It may distort linear</span>
<span class="sd">    correlations between variables measured at the same scale but renders</span>
<span class="sd">    variables measured at different scales more directly comparable.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_transformer&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_quantiles : int, optional (default=1000)</span>
<span class="sd">        Number of quantiles to be computed. It corresponds to the number</span>
<span class="sd">        of landmarks used to discretize the cumulative density function.</span>

<span class="sd">    output_distribution : str, optional (default=&#39;uniform&#39;)</span>
<span class="sd">        Marginal distribution for the transformed data. The choices are</span>
<span class="sd">        &#39;uniform&#39; (default) or &#39;normal&#39;.</span>

<span class="sd">    ignore_implicit_zeros : bool, optional (default=False)</span>
<span class="sd">        Only applies to sparse matrices. If True, the sparse entries of the</span>
<span class="sd">        matrix are discarded to compute the quantile statistics. If False,</span>
<span class="sd">        these entries are treated as zeros.</span>

<span class="sd">    subsample : int, optional (default=1e5)</span>
<span class="sd">        Maximum number of samples used to estimate the quantiles for</span>
<span class="sd">        computational efficiency. Note that the subsampling procedure may</span>
<span class="sd">        differ for value-identical sparse and dense matrices.</span>

<span class="sd">    random_state : int, RandomState instance or None, optional (default=None)</span>
<span class="sd">        If int, random_state is the seed used by the random number generator;</span>
<span class="sd">        If RandomState instance, random_state is the random number generator;</span>
<span class="sd">        If None, the random number generator is the RandomState instance used</span>
<span class="sd">        by np.random. Note that this is used by subsampling and smoothing</span>
<span class="sd">        noise.</span>

<span class="sd">    copy : boolean, optional, (default=True)</span>
<span class="sd">        Set to False to perform inplace transformation and avoid a copy (if the</span>
<span class="sd">        input is already a numpy array).</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    quantiles_ : ndarray, shape (n_quantiles, n_features)</span>
<span class="sd">        The values corresponding the quantiles of reference.</span>

<span class="sd">    references_ : ndarray, shape(n_quantiles, )</span>
<span class="sd">        Quantiles of references.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.preprocessing import QuantileTransformer</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.RandomState(0)</span>
<span class="sd">    &gt;&gt;&gt; X = np.sort(rng.normal(loc=0.5, scale=0.25, size=(25, 1)), axis=0)</span>
<span class="sd">    &gt;&gt;&gt; qt = QuantileTransformer(n_quantiles=10, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; qt.fit_transform(X) # doctest: +ELLIPSIS</span>
<span class="sd">    array([...])</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    quantile_transform : Equivalent function without the estimator API.</span>
<span class="sd">    StandardScaler : perform standardization that is faster, but less robust</span>
<span class="sd">        to outliers.</span>
<span class="sd">    RobustScaler : perform robust standardization that removes the influence</span>
<span class="sd">        of outliers but does not put outliers and inliers on the same scale.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    For a comparison of the different scalers, transformers, and normalizers,</span>
<span class="sd">    see :ref:`examples/preprocessing/plot_all_scaling.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_quantiles</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">output_distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span>
                 <span class="n">ignore_implicit_zeros</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">),</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_quantiles</span> <span class="o">=</span> <span class="n">n_quantiles</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_distribution</span> <span class="o">=</span> <span class="n">output_distribution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_implicit_zeros</span> <span class="o">=</span> <span class="n">ignore_implicit_zeros</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">=</span> <span class="n">subsample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">copy</span> <span class="o">=</span> <span class="n">copy</span>

    <span class="k">def</span> <span class="nf">_dense_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute percentiles for dense matrices.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray, shape (n_samples, n_features)</span>
<span class="sd">            The data used to scale along the features axis.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_implicit_zeros</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;&#39;ignore_implicit_zeros&#39; takes effect only with&quot;</span>
                          <span class="s2">&quot; sparse matrix. This parameter has no effect.&quot;</span><span class="p">)</span>

        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># for compatibility issue with numpy&lt;=1.8.X, references</span>
        <span class="c1"># need to be a list scaled between 0 and 100</span>
        <span class="n">references</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">references_</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
                <span class="n">subsample_idx</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span>
                                                    <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">subsample</span><span class="p">,</span>
                                                    <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">col</span> <span class="o">=</span> <span class="n">col</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">subsample_idx</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;clip&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">references</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sparse_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute percentiles for sparse matrices.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : sparse matrix CSC, shape (n_samples, n_features)</span>
<span class="sd">            The data used to scale along the features axis. The sparse matrix</span>
<span class="sd">            needs to be nonnegative.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># for compatibility issue with numpy&lt;=1.8.X, references</span>
        <span class="c1"># need to be a list scaled between 0 and 100</span>
        <span class="n">references</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">references_</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">feature_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">):</span>
            <span class="n">column_nnz_data</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">indptr</span><span class="p">[</span><span class="n">feature_idx</span><span class="p">]:</span>
                                     <span class="n">X</span><span class="o">.</span><span class="n">indptr</span><span class="p">[</span><span class="n">feature_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">column_nnz_data</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span><span class="p">:</span>
                <span class="n">column_subsample</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">column_nnz_data</span><span class="p">)</span> <span class="o">//</span>
                                    <span class="n">n_samples</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_implicit_zeros</span><span class="p">:</span>
                    <span class="n">column_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">column_subsample</span><span class="p">,</span>
                                           <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">column_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">subsample</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="n">column_data</span><span class="p">[:</span><span class="n">column_subsample</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                    <span class="n">column_nnz_data</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">column_subsample</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_implicit_zeros</span><span class="p">:</span>
                    <span class="n">column_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">column_nnz_data</span><span class="p">),</span>
                                           <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">column_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="n">column_data</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">column_nnz_data</span><span class="p">)]</span> <span class="o">=</span> <span class="n">column_nnz_data</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">column_data</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
                <span class="c1"># if no nnz, an error will be raised for computing the</span>
                <span class="c1"># quantiles. Force the quantiles to be zeros.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">references</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">column_data</span><span class="p">,</span> <span class="n">references</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span><span class="p">)</span>

<div class="viewcode-block" id="QuantileTransformer.fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_quantiletransformer.html#ibex.sklearn.preprocessing.QuantileTransformer.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the quantiles used for transforming.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray or sparse matrix, shape (n_samples, n_features)</span>
<span class="sd">            The data used to scale along the features axis. If a sparse</span>
<span class="sd">            matrix is provided, it will be converted into a sparse</span>
<span class="sd">            ``csc_matrix``. Additionally, the sparse matrix needs to be</span>
<span class="sd">            nonnegative if `ignore_implicit_zeros` is False.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_quantiles</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid value for &#39;n_quantiles&#39;: </span><span class="si">%d</span><span class="s2">. &quot;</span>
                             <span class="s2">&quot;The number of quantiles must be at least one.&quot;</span>
                             <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_quantiles</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid value for &#39;subsample&#39;: </span><span class="si">%d</span><span class="s2">. &quot;</span>
                             <span class="s2">&quot;The number of subsamples must be at least one.&quot;</span>
                             <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_quantiles</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The number of quantiles cannot be greater than&quot;</span>
                             <span class="s2">&quot; the number of samples used. Got </span><span class="si">{}</span><span class="s2"> quantiles&quot;</span>
                             <span class="s2">&quot; and </span><span class="si">{}</span><span class="s2"> samples.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_quantiles</span><span class="p">,</span>
                                                       <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span><span class="p">))</span>

        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>

        <span class="c1"># Create the quantiles of reference</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">references_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_quantiles</span><span class="p">,</span>
                                       <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sparse_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dense_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="k">def</span> <span class="nf">_transform_col</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_col</span><span class="p">,</span> <span class="n">quantiles</span><span class="p">,</span> <span class="n">inverse</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Private function to transform a single feature&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_distribution</span> <span class="o">==</span> <span class="s1">&#39;normal&#39;</span><span class="p">:</span>
            <span class="n">output_distribution</span> <span class="o">=</span> <span class="s1">&#39;norm&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_distribution</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_distribution</span>
        <span class="n">output_distribution</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">stats</span><span class="p">,</span> <span class="n">output_distribution</span><span class="p">)</span>

        <span class="c1"># older version of scipy do not handle tuple as fill_value</span>
        <span class="c1"># clipping the value before transform solve the issue</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">inverse</span><span class="p">:</span>
            <span class="n">lower_bound_x</span> <span class="o">=</span> <span class="n">quantiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">upper_bound_x</span> <span class="o">=</span> <span class="n">quantiles</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">lower_bound_y</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">upper_bound_y</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lower_bound_x</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">upper_bound_x</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">lower_bound_y</span> <span class="o">=</span> <span class="n">quantiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">upper_bound_y</span> <span class="o">=</span> <span class="n">quantiles</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="c1">#  for inverse transform, match a uniform PDF</span>
            <span class="n">X_col</span> <span class="o">=</span> <span class="n">output_distribution</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">X_col</span><span class="p">)</span>
        <span class="c1"># find index for lower and higher bounds</span>
        <span class="n">lower_bounds_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_col</span> <span class="o">-</span> <span class="n">BOUNDS_THRESHOLD</span> <span class="o">&lt;</span>
                            <span class="n">lower_bound_x</span><span class="p">)</span>
        <span class="n">upper_bounds_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_col</span> <span class="o">+</span> <span class="n">BOUNDS_THRESHOLD</span> <span class="o">&gt;</span>
                            <span class="n">upper_bound_x</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">inverse</span><span class="p">:</span>
            <span class="c1"># Interpolate in one direction and in the other and take the</span>
            <span class="c1"># mean. This is in case of repeated values in the features</span>
            <span class="c1"># and hence repeated quantiles</span>
            <span class="c1">#</span>
            <span class="c1"># If we don&#39;t do this, only one extreme of the duplicated is</span>
            <span class="c1"># used (the upper when we do assending, and the</span>
            <span class="c1"># lower for descending). We take the mean of these two</span>
            <span class="n">X_col</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">X_col</span><span class="p">,</span> <span class="n">quantiles</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">references_</span><span class="p">)</span>
                          <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="o">-</span><span class="n">X_col</span><span class="p">,</span> <span class="o">-</span><span class="n">quantiles</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                      <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">references_</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">X_col</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">references_</span><span class="p">,</span> <span class="n">quantiles</span><span class="p">)</span>

        <span class="n">X_col</span><span class="p">[</span><span class="n">upper_bounds_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">upper_bound_y</span>
        <span class="n">X_col</span><span class="p">[</span><span class="n">lower_bounds_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">lower_bound_y</span>
        <span class="c1"># for forward transform, match the output PDF</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">inverse</span><span class="p">:</span>
            <span class="n">X_col</span> <span class="o">=</span> <span class="n">output_distribution</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">X_col</span><span class="p">)</span>
            <span class="c1"># find the value to clip the data to avoid mapping to</span>
            <span class="c1"># infinity. Clip such that the inverse transform will be</span>
            <span class="c1"># consistent</span>
            <span class="n">clip_min</span> <span class="o">=</span> <span class="n">output_distribution</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">BOUNDS_THRESHOLD</span> <span class="o">-</span>
                                               <span class="n">np</span><span class="o">.</span><span class="n">spacing</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">clip_max</span> <span class="o">=</span> <span class="n">output_distribution</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">BOUNDS_THRESHOLD</span> <span class="o">-</span>
                                                    <span class="n">np</span><span class="o">.</span><span class="n">spacing</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
            <span class="n">X_col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">X_col</span><span class="p">,</span> <span class="n">clip_min</span><span class="p">,</span> <span class="n">clip_max</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X_col</span>

    <span class="k">def</span> <span class="nf">_check_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse_negative</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Check inputs before fit and transform&quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s1">&#39;csc&#39;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">])</span>
        <span class="c1"># we only accept positive sparse matrix when ignore_implicit_zeros is</span>
        <span class="c1"># false and that we call fit or transform.</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">accept_sparse_negative</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_implicit_zeros</span> <span class="ow">and</span>
                <span class="p">(</span><span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">data</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">))):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;QuantileTransformer only accepts non-negative&#39;</span>
                             <span class="s1">&#39; sparse matrices.&#39;</span><span class="p">)</span>

        <span class="c1"># check the output PDF</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_distribution</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="s1">&#39;uniform&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;&#39;output_distribution&#39; has to be either &#39;normal&#39;&quot;</span>
                             <span class="s2">&quot; or &#39;uniform&#39;. Got &#39;</span><span class="si">{}</span><span class="s2">&#39; instead.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                 <span class="bp">self</span><span class="o">.</span><span class="n">output_distribution</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">X</span>

    <span class="k">def</span> <span class="nf">_check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Check the inputs before transforming&quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;quantiles_&#39;</span><span class="p">)</span>
        <span class="c1"># check that the dimension of X are adequate with the fitted data</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;X does not have the same number of features as&#39;</span>
                             <span class="s1">&#39; the previously fitted data. Got </span><span class="si">{}</span><span class="s1"> instead of&#39;</span>
                             <span class="s1">&#39; </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                           <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

    <span class="k">def</span> <span class="nf">_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Forward and inverse transform.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray, shape (n_samples, n_features)</span>
<span class="sd">            The data used to scale along the features axis.</span>

<span class="sd">        inverse : bool, optional (default=False)</span>
<span class="sd">            If False, apply forward transform. If True, apply</span>
<span class="sd">            inverse transform.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X : ndarray, shape (n_samples, n_features)</span>
<span class="sd">            Projected data</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">feature_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">column_slice</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">indptr</span><span class="p">[</span><span class="n">feature_idx</span><span class="p">],</span>
                                     <span class="n">X</span><span class="o">.</span><span class="n">indptr</span><span class="p">[</span><span class="n">feature_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
                <span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">column_slice</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_col</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">column_slice</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span><span class="p">[:,</span> <span class="n">feature_idx</span><span class="p">],</span>
                    <span class="n">inverse</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">feature_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">X</span><span class="p">[:,</span> <span class="n">feature_idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_col</span><span class="p">(</span>
                    <span class="n">X</span><span class="p">[:,</span> <span class="n">feature_idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles_</span><span class="p">[:,</span> <span class="n">feature_idx</span><span class="p">],</span>
                    <span class="n">inverse</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X</span>

<div class="viewcode-block" id="QuantileTransformer.transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_quantiletransformer.html#ibex.sklearn.preprocessing.QuantileTransformer.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Feature-wise transformation of the data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray or sparse matrix, shape (n_samples, n_features)</span>
<span class="sd">            The data used to scale along the features axis. If a sparse</span>
<span class="sd">            matrix is provided, it will be converted into a sparse</span>
<span class="sd">            ``csc_matrix``. Additionally, the sparse matrix needs to be</span>
<span class="sd">            nonnegative if `ignore_implicit_zeros` is False.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Xt : ndarray or sparse matrix, shape (n_samples, n_features)</span>
<span class="sd">            The projected data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>

<div class="viewcode-block" id="QuantileTransformer.inverse_transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_preprocessing_quantiletransformer.html#ibex.sklearn.preprocessing.QuantileTransformer.inverse_transform">[docs]</a>    <span class="k">def</span> <span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Back-projection to the original space.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray or sparse matrix, shape (n_samples, n_features)</span>
<span class="sd">            The data used to scale along the features axis. If a sparse</span>
<span class="sd">            matrix is provided, it will be converted into a sparse</span>
<span class="sd">            ``csc_matrix``. Additionally, the sparse matrix needs to be</span>
<span class="sd">            nonnegative if `ignore_implicit_zeros` is False.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Xt : ndarray or sparse matrix, shape (n_samples, n_features)</span>
<span class="sd">            The projected data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse_negative</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">quantile_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_quantiles</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                       <span class="n">output_distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span>
                       <span class="n">ignore_implicit_zeros</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                       <span class="n">subsample</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">),</span>
                       <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                       <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Transform features using quantiles information.</span>

<span class="sd">    This method transforms the features to follow a uniform or a normal</span>
<span class="sd">    distribution. Therefore, for a given feature, this transformation tends</span>
<span class="sd">    to spread out the most frequent values. It also reduces the impact of</span>
<span class="sd">    (marginal) outliers: this is therefore a robust preprocessing scheme.</span>

<span class="sd">    The transformation is applied on each feature independently.</span>
<span class="sd">    The cumulative density function of a feature is used to project the</span>
<span class="sd">    original values. Features values of new/unseen data that fall below</span>
<span class="sd">    or above the fitted range will be mapped to the bounds of the output</span>
<span class="sd">    distribution. Note that this transform is non-linear. It may distort linear</span>
<span class="sd">    correlations between variables measured at the same scale but renders</span>
<span class="sd">    variables measured at different scales more directly comparable.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;preprocessing_transformer&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, sparse matrix</span>
<span class="sd">        The data to transform.</span>

<span class="sd">    axis : int, (default=0)</span>
<span class="sd">        Axis used to compute the means and standard deviations along. If 0,</span>
<span class="sd">        transform each feature, otherwise (if 1) transform each sample.</span>

<span class="sd">    n_quantiles : int, optional (default=1000)</span>
<span class="sd">        Number of quantiles to be computed. It corresponds to the number</span>
<span class="sd">        of landmarks used to discretize the cumulative density function.</span>

<span class="sd">    output_distribution : str, optional (default=&#39;uniform&#39;)</span>
<span class="sd">        Marginal distribution for the transformed data. The choices are</span>
<span class="sd">        &#39;uniform&#39; (default) or &#39;normal&#39;.</span>

<span class="sd">    ignore_implicit_zeros : bool, optional (default=False)</span>
<span class="sd">        Only applies to sparse matrices. If True, the sparse entries of the</span>
<span class="sd">        matrix are discarded to compute the quantile statistics. If False,</span>
<span class="sd">        these entries are treated as zeros.</span>

<span class="sd">    subsample : int, optional (default=1e5)</span>
<span class="sd">        Maximum number of samples used to estimate the quantiles for</span>
<span class="sd">        computational efficiency. Note that the subsampling procedure may</span>
<span class="sd">        differ for value-identical sparse and dense matrices.</span>

<span class="sd">    random_state : int, RandomState instance or None, optional (default=None)</span>
<span class="sd">        If int, random_state is the seed used by the random number generator;</span>
<span class="sd">        If RandomState instance, random_state is the random number generator;</span>
<span class="sd">        If None, the random number generator is the RandomState instance used</span>
<span class="sd">        by np.random. Note that this is used by subsampling and smoothing</span>
<span class="sd">        noise.</span>

<span class="sd">    copy : boolean, optional, (default=True)</span>
<span class="sd">        Set to False to perform inplace transformation and avoid a copy (if the</span>
<span class="sd">        input is already a numpy array).</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    quantiles_ : ndarray, shape (n_quantiles, n_features)</span>
<span class="sd">        The values corresponding the quantiles of reference.</span>

<span class="sd">    references_ : ndarray, shape(n_quantiles, )</span>
<span class="sd">        Quantiles of references.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.preprocessing import quantile_transform</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.RandomState(0)</span>
<span class="sd">    &gt;&gt;&gt; X = np.sort(rng.normal(loc=0.5, scale=0.25, size=(25, 1)), axis=0)</span>
<span class="sd">    &gt;&gt;&gt; quantile_transform(X, n_quantiles=10, random_state=0)</span>
<span class="sd">    ... # doctest: +ELLIPSIS</span>
<span class="sd">    array([...])</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    QuantileTransformer : Performs quantile-based scaling using the</span>
<span class="sd">        ``Transformer`` API (e.g. as part of a preprocessing</span>
<span class="sd">        :class:`sklearn.pipeline.Pipeline`).</span>
<span class="sd">    scale : perform standardization that is faster, but less robust</span>
<span class="sd">        to outliers.</span>
<span class="sd">    robust_scale : perform robust standardization that removes the influence</span>
<span class="sd">        of outliers but does not put outliers and inliers on the same scale.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    For a comparison of the different scalers, transformers, and normalizers,</span>
<span class="sd">    see :ref:`examples/preprocessing/plot_all_scaling.py</span>
<span class="sd">    &lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">QuantileTransformer</span><span class="p">(</span><span class="n">n_quantiles</span><span class="o">=</span><span class="n">n_quantiles</span><span class="p">,</span>
                            <span class="n">output_distribution</span><span class="o">=</span><span class="n">output_distribution</span><span class="p">,</span>
                            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
                            <span class="n">ignore_implicit_zeros</span><span class="o">=</span><span class="n">ignore_implicit_zeros</span><span class="p">,</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                            <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;axis should be either equal to 0 or 1. Got&quot;</span>
                         <span class="s2">&quot; axis=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">axis</span><span class="p">))</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../index.html">
              <img class="logo" src="../../../_static/logo.jpeg" alt="Logo"/>
            </a></p><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Ami Tavory, Shahar Azulay, Tali Raveh-Sadka.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.5</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
    </div>

    
    <a href="https://github.com/atavory/ibex" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>