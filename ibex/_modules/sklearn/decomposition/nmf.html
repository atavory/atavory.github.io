
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>sklearn.decomposition.nmf &#8212; ibex latest documentation</title>
    <link rel="stylesheet" href="../../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     'latest',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for sklearn.decomposition.nmf</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot; Non-negative matrix factorization</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Author: Vlad Niculae</span>
<span class="c1">#         Lars Buitinck</span>
<span class="c1">#         Mathieu Blondel &lt;mathieu@mblondel.org&gt;</span>
<span class="c1">#         Tom Dupre la Tour</span>
<span class="c1"># License: BSD 3 clause</span>


<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span>

<span class="kn">from</span> <span class="nn">math</span> <span class="k">import</span> <span class="n">sqrt</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sp</span>

<span class="kn">from</span> <span class="nn">..base</span> <span class="k">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="k">import</span> <span class="n">check_random_state</span><span class="p">,</span> <span class="n">check_array</span>
<span class="kn">from</span> <span class="nn">..utils.extmath</span> <span class="k">import</span> <span class="n">randomized_svd</span><span class="p">,</span> <span class="n">safe_sparse_dot</span><span class="p">,</span> <span class="n">squared_norm</span>
<span class="kn">from</span> <span class="nn">..utils.extmath</span> <span class="k">import</span> <span class="n">safe_min</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="k">import</span> <span class="n">check_is_fitted</span><span class="p">,</span> <span class="n">check_non_negative</span>
<span class="kn">from</span> <span class="nn">..exceptions</span> <span class="k">import</span> <span class="n">ConvergenceWarning</span>
<span class="kn">from</span> <span class="nn">.cdnmf_fast</span> <span class="k">import</span> <span class="n">_update_cdnmf_fast</span>

<span class="n">EPSILON</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>

<span class="n">INTEGER_TYPES</span> <span class="o">=</span> <span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">norm</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Dot product-based Euclidean norm implementation</span>

<span class="sd">    See: http://fseoane.net/blog/2011/computing-the-vector-norm/</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">squared_norm</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">trace_dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trace of np.dot(X, Y.T).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">Y</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>


<span class="k">def</span> <span class="nf">_check_init</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">whom</span><span class="p">):</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">!=</span> <span class="n">shape</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Array with wrong shape passed to </span><span class="si">%s</span><span class="s1">. Expected </span><span class="si">%s</span><span class="s1">, &#39;</span>
                         <span class="s1">&#39;but got </span><span class="si">%s</span><span class="s1"> &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">whom</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A</span><span class="p">)))</span>
    <span class="n">check_non_negative</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">whom</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Array passed to </span><span class="si">%s</span><span class="s1"> is full of zeros.&#39;</span> <span class="o">%</span> <span class="n">whom</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_beta_divergence</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">square_root</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the beta-divergence of X and dot(W, H).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : float or array-like, shape (n_samples, n_features)</span>

<span class="sd">    W : float or dense array-like, shape (n_samples, n_components)</span>

<span class="sd">    H : float or dense array-like, shape (n_components, n_features)</span>

<span class="sd">    beta : float, string in {&#39;frobenius&#39;, &#39;kullback-leibler&#39;, &#39;itakura-saito&#39;}</span>
<span class="sd">        Parameter of the beta-divergence.</span>
<span class="sd">        If beta == 2, this is half the Frobenius *squared* norm.</span>
<span class="sd">        If beta == 1, this is the generalized Kullback-Leibler divergence.</span>
<span class="sd">        If beta == 0, this is the Itakura-Saito divergence.</span>
<span class="sd">        Else, this is the general beta-divergence.</span>

<span class="sd">    square_root : boolean, default False</span>
<span class="sd">        If True, return np.sqrt(2 * res)</span>
<span class="sd">        For beta == 2, it corresponds to the Frobenius norm.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">        res : float</span>
<span class="sd">            Beta divergence of X and np.dot(X, H)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">_beta_loss_to_float</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>

    <span class="c1"># The method can be called with scalars</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>

    <span class="c1"># Frobenius norm</span>
    <span class="k">if</span> <span class="n">beta</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># Avoid the creation of the dense np.dot(W, H) if X is sparse.</span>
        <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">norm_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="n">norm_WH</span> <span class="o">=</span> <span class="n">trace_dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> <span class="n">H</span><span class="p">),</span> <span class="n">H</span><span class="p">)</span>
            <span class="n">cross_prod</span> <span class="o">=</span> <span class="n">trace_dot</span><span class="p">((</span><span class="n">X</span> <span class="o">*</span> <span class="n">H</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">W</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="n">norm_X</span> <span class="o">+</span> <span class="n">norm_WH</span> <span class="o">-</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">cross_prod</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">squared_norm</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">))</span> <span class="o">/</span> <span class="mf">2.</span>

        <span class="k">if</span> <span class="n">square_root</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">res</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">res</span>

    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="c1"># compute np.dot(W, H) only where X is nonzero</span>
        <span class="n">WH_data</span> <span class="o">=</span> <span class="n">_special_sparse_dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
        <span class="n">X_data</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">WH</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
        <span class="n">WH_data</span> <span class="o">=</span> <span class="n">WH</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="n">X_data</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="c1"># do not affect the zeros: here 0 ** (-1) = 0 and not infinity</span>
    <span class="n">WH_data</span> <span class="o">=</span> <span class="n">WH_data</span><span class="p">[</span><span class="n">X_data</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">X_data</span> <span class="o">=</span> <span class="n">X_data</span><span class="p">[</span><span class="n">X_data</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>

    <span class="c1"># used to avoid division by zero</span>
    <span class="n">WH_data</span><span class="p">[</span><span class="n">WH_data</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">EPSILON</span>

    <span class="c1"># generalized Kullback-Leibler divergence</span>
    <span class="k">if</span> <span class="n">beta</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># fast and memory efficient computation of np.sum(np.dot(W, H))</span>
        <span class="n">sum_WH</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="c1"># computes np.sum(X * log(X / WH)) only where X is nonzero</span>
        <span class="n">div</span> <span class="o">=</span> <span class="n">X_data</span> <span class="o">/</span> <span class="n">WH_data</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">div</span><span class="p">))</span>
        <span class="c1"># add full np.sum(np.dot(W, H)) - np.sum(X)</span>
        <span class="n">res</span> <span class="o">+=</span> <span class="n">sum_WH</span> <span class="o">-</span> <span class="n">X_data</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># Itakura-Saito divergence</span>
    <span class="k">elif</span> <span class="n">beta</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">div</span> <span class="o">=</span> <span class="n">X_data</span> <span class="o">/</span> <span class="n">WH_data</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">div</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">div</span><span class="p">))</span>

    <span class="c1"># beta-divergence, beta not in (0, 1, 2)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="c1"># slow loop, but memory efficient computation of :</span>
            <span class="c1"># np.sum(np.dot(W, H) ** beta)</span>
            <span class="n">sum_WH_beta</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">sum_WH_beta</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span> <span class="o">**</span> <span class="n">beta</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">sum_WH_beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">WH</span> <span class="o">**</span> <span class="n">beta</span><span class="p">)</span>

        <span class="n">sum_X_WH</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">WH_data</span> <span class="o">**</span> <span class="p">(</span><span class="n">beta</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_data</span> <span class="o">**</span> <span class="n">beta</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">sum_X_WH</span>
        <span class="n">res</span> <span class="o">+=</span> <span class="n">sum_WH_beta</span> <span class="o">*</span> <span class="p">(</span><span class="n">beta</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">/=</span> <span class="n">beta</span> <span class="o">*</span> <span class="p">(</span><span class="n">beta</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">square_root</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">res</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">res</span>


<span class="k">def</span> <span class="nf">_special_sparse_dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes np.dot(W, H), only where X is non zero.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">ii</span><span class="p">,</span> <span class="n">jj</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span>
        <span class="n">dot_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:],</span> <span class="n">H</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="n">jj</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">WH</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">coo_matrix</span><span class="p">((</span><span class="n">dot_vals</span><span class="p">,</span> <span class="p">(</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">)),</span> <span class="n">shape</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">WH</span><span class="o">.</span><span class="n">tocsr</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_compute_regularization</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="p">,</span> <span class="n">regularization</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute L1 and L2 regularization coefficients for W and H&quot;&quot;&quot;</span>
    <span class="n">alpha_H</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="n">alpha_W</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">if</span> <span class="n">regularization</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="s1">&#39;components&#39;</span><span class="p">):</span>
        <span class="n">alpha_H</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">regularization</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="s1">&#39;transformation&#39;</span><span class="p">):</span>
        <span class="n">alpha_W</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>

    <span class="n">l1_reg_W</span> <span class="o">=</span> <span class="n">alpha_W</span> <span class="o">*</span> <span class="n">l1_ratio</span>
    <span class="n">l1_reg_H</span> <span class="o">=</span> <span class="n">alpha_H</span> <span class="o">*</span> <span class="n">l1_ratio</span>
    <span class="n">l2_reg_W</span> <span class="o">=</span> <span class="n">alpha_W</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">l1_ratio</span><span class="p">)</span>
    <span class="n">l2_reg_H</span> <span class="o">=</span> <span class="n">alpha_H</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">l1_ratio</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">l1_reg_W</span><span class="p">,</span> <span class="n">l1_reg_H</span><span class="p">,</span> <span class="n">l2_reg_W</span><span class="p">,</span> <span class="n">l2_reg_H</span>


<span class="k">def</span> <span class="nf">_check_string_param</span><span class="p">(</span><span class="n">solver</span><span class="p">,</span> <span class="n">regularization</span><span class="p">,</span> <span class="n">beta_loss</span><span class="p">,</span> <span class="n">init</span><span class="p">):</span>
    <span class="n">allowed_solver</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;cd&#39;</span><span class="p">,</span> <span class="s1">&#39;mu&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">solver</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">allowed_solver</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;Invalid solver parameter: got </span><span class="si">%r</span><span class="s1"> instead of one of </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span>
            <span class="p">(</span><span class="n">solver</span><span class="p">,</span> <span class="n">allowed_solver</span><span class="p">))</span>

    <span class="n">allowed_regularization</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="s1">&#39;components&#39;</span><span class="p">,</span> <span class="s1">&#39;transformation&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">regularization</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">allowed_regularization</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;Invalid regularization parameter: got </span><span class="si">%r</span><span class="s1"> instead of one of </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span>
            <span class="p">(</span><span class="n">regularization</span><span class="p">,</span> <span class="n">allowed_regularization</span><span class="p">))</span>

    <span class="c1"># &#39;mu&#39; is the only solver that handles other beta losses than &#39;frobenius&#39;</span>
    <span class="k">if</span> <span class="n">solver</span> <span class="o">!=</span> <span class="s1">&#39;mu&#39;</span> <span class="ow">and</span> <span class="n">beta_loss</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;frobenius&#39;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;Invalid beta_loss parameter: solver </span><span class="si">%r</span><span class="s1"> does not handle beta_loss&#39;</span>
            <span class="s1">&#39; = </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">solver</span><span class="p">,</span> <span class="n">beta_loss</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">solver</span> <span class="o">==</span> <span class="s1">&#39;mu&#39;</span> <span class="ow">and</span> <span class="n">init</span> <span class="o">==</span> <span class="s1">&#39;nndsvd&#39;</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;The multiplicative update (&#39;mu&#39;) solver cannot update &quot;</span>
                      <span class="s2">&quot;zeros present in the initialization, and so leads to &quot;</span>
                      <span class="s2">&quot;poorer results when used jointly with init=&#39;nndsvd&#39;. &quot;</span>
                      <span class="s2">&quot;You may try init=&#39;nndsvda&#39; or init=&#39;nndsvdar&#39; instead.&quot;</span><span class="p">,</span>
                      <span class="ne">UserWarning</span><span class="p">)</span>

    <span class="n">beta_loss</span> <span class="o">=</span> <span class="n">_beta_loss_to_float</span><span class="p">(</span><span class="n">beta_loss</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">beta_loss</span>


<span class="k">def</span> <span class="nf">_beta_loss_to_float</span><span class="p">(</span><span class="n">beta_loss</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Convert string beta_loss to float&quot;&quot;&quot;</span>
    <span class="n">allowed_beta_loss</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;frobenius&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
                         <span class="s1">&#39;kullback-leibler&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                         <span class="s1">&#39;itakura-saito&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">beta_loss</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">beta_loss</span> <span class="ow">in</span> <span class="n">allowed_beta_loss</span><span class="p">:</span>
        <span class="n">beta_loss</span> <span class="o">=</span> <span class="n">allowed_beta_loss</span><span class="p">[</span><span class="n">beta_loss</span><span class="p">]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">beta_loss</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid beta_loss parameter: got </span><span class="si">%r</span><span class="s1"> instead &#39;</span>
                         <span class="s1">&#39;of one of </span><span class="si">%r</span><span class="s1">, or a float.&#39;</span> <span class="o">%</span>
                         <span class="p">(</span><span class="n">beta_loss</span><span class="p">,</span> <span class="n">allowed_beta_loss</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    <span class="k">return</span> <span class="n">beta_loss</span>


<span class="k">def</span> <span class="nf">_initialize_nmf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_components</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Algorithms for NMF initialization.</span>

<span class="sd">    Computes an initial guess for the non-negative</span>
<span class="sd">    rank k matrix approximation for X: X = WH</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape (n_samples, n_features)</span>
<span class="sd">        The data matrix to be decomposed.</span>

<span class="sd">    n_components : integer</span>
<span class="sd">        The number of components desired in the approximation.</span>

<span class="sd">    init :  None | &#39;random&#39; | &#39;nndsvd&#39; | &#39;nndsvda&#39; | &#39;nndsvdar&#39;</span>
<span class="sd">        Method used to initialize the procedure.</span>
<span class="sd">        Default: &#39;nndsvd&#39; if n_components &lt; n_features, otherwise &#39;random&#39;.</span>
<span class="sd">        Valid options:</span>

<span class="sd">        - &#39;random&#39;: non-negative random matrices, scaled with:</span>
<span class="sd">            sqrt(X.mean() / n_components)</span>

<span class="sd">        - &#39;nndsvd&#39;: Nonnegative Double Singular Value Decomposition (NNDSVD)</span>
<span class="sd">            initialization (better for sparseness)</span>

<span class="sd">        - &#39;nndsvda&#39;: NNDSVD with zeros filled with the average of X</span>
<span class="sd">            (better when sparsity is not desired)</span>

<span class="sd">        - &#39;nndsvdar&#39;: NNDSVD with zeros filled with small random values</span>
<span class="sd">            (generally faster, less accurate alternative to NNDSVDa</span>
<span class="sd">            for when sparsity is not desired)</span>

<span class="sd">        - &#39;custom&#39;: use custom matrices W and H</span>

<span class="sd">    eps : float</span>
<span class="sd">        Truncate all values less then this in output to zero.</span>

<span class="sd">    random_state : int, RandomState instance or None, optional, default: None</span>
<span class="sd">        If int, random_state is the seed used by the random number generator;</span>
<span class="sd">        If RandomState instance, random_state is the random number generator;</span>
<span class="sd">        If None, the random number generator is the RandomState instance used</span>
<span class="sd">        by `np.random`. Used when ``random`` == &#39;nndsvdar&#39; or &#39;random&#39;.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    W : array-like, shape (n_samples, n_components)</span>
<span class="sd">        Initial guesses for solving X ~= WH</span>

<span class="sd">    H : array-like, shape (n_components, n_features)</span>
<span class="sd">        Initial guesses for solving X ~= WH</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    C. Boutsidis, E. Gallopoulos: SVD based initialization: A head start for</span>
<span class="sd">    nonnegative matrix factorization - Pattern Recognition, 2008</span>
<span class="sd">    http://tinyurl.com/nndsvd</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_non_negative</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s2">&quot;NMF initialization&quot;</span><span class="p">)</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">n_components</span> <span class="o">&lt;</span> <span class="n">n_features</span><span class="p">:</span>
            <span class="n">init</span> <span class="o">=</span> <span class="s1">&#39;nndsvd&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">init</span> <span class="o">=</span> <span class="s1">&#39;random&#39;</span>

    <span class="c1"># Random initialization</span>
    <span class="k">if</span> <span class="n">init</span> <span class="o">==</span> <span class="s1">&#39;random&#39;</span><span class="p">:</span>
        <span class="n">avg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">/</span> <span class="n">n_components</span><span class="p">)</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">avg</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">avg</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_components</span><span class="p">)</span>
        <span class="c1"># we do not write np.abs(H, out=H) to stay compatible with</span>
        <span class="c1"># numpy 1.5 and earlier where the &#39;out&#39; keyword is not</span>
        <span class="c1"># supported as a kwarg on ufuncs</span>
        <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span>

    <span class="c1"># NNDSVD initialization</span>
    <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">randomized_svd</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_components</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
    <span class="n">W</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">V</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># The leading singular triplet is non-negative</span>
    <span class="c1"># so it can be used as is for initialization.</span>
    <span class="n">W</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">U</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">H</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">V</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>

    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_components</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="n">j</span><span class="p">],</span> <span class="n">V</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># extract positive and negative parts of column vectors</span>
        <span class="n">x_p</span><span class="p">,</span> <span class="n">y_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">x_n</span><span class="p">,</span> <span class="n">y_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

        <span class="c1"># and their norms</span>
        <span class="n">x_p_nrm</span><span class="p">,</span> <span class="n">y_p_nrm</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">x_p</span><span class="p">),</span> <span class="n">norm</span><span class="p">(</span><span class="n">y_p</span><span class="p">)</span>
        <span class="n">x_n_nrm</span><span class="p">,</span> <span class="n">y_n_nrm</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">x_n</span><span class="p">),</span> <span class="n">norm</span><span class="p">(</span><span class="n">y_n</span><span class="p">)</span>

        <span class="n">m_p</span><span class="p">,</span> <span class="n">m_n</span> <span class="o">=</span> <span class="n">x_p_nrm</span> <span class="o">*</span> <span class="n">y_p_nrm</span><span class="p">,</span> <span class="n">x_n_nrm</span> <span class="o">*</span> <span class="n">y_n_nrm</span>

        <span class="c1"># choose update</span>
        <span class="k">if</span> <span class="n">m_p</span> <span class="o">&gt;</span> <span class="n">m_n</span><span class="p">:</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">x_p</span> <span class="o">/</span> <span class="n">x_p_nrm</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">y_p</span> <span class="o">/</span> <span class="n">y_p_nrm</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">m_p</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">x_n</span> <span class="o">/</span> <span class="n">x_n_nrm</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">y_n</span> <span class="o">/</span> <span class="n">y_n_nrm</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">m_n</span>

        <span class="n">lbd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="n">W</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">lbd</span> <span class="o">*</span> <span class="n">u</span>
        <span class="n">H</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lbd</span> <span class="o">*</span> <span class="n">v</span>

    <span class="n">W</span><span class="p">[</span><span class="n">W</span> <span class="o">&lt;</span> <span class="n">eps</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">H</span><span class="p">[</span><span class="n">H</span> <span class="o">&lt;</span> <span class="n">eps</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">init</span> <span class="o">==</span> <span class="s2">&quot;nndsvd&quot;</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="k">elif</span> <span class="n">init</span> <span class="o">==</span> <span class="s2">&quot;nndsvda&quot;</span><span class="p">:</span>
        <span class="n">avg</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">W</span><span class="p">[</span><span class="n">W</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">avg</span>
        <span class="n">H</span><span class="p">[</span><span class="n">H</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">avg</span>
    <span class="k">elif</span> <span class="n">init</span> <span class="o">==</span> <span class="s2">&quot;nndsvdar&quot;</span><span class="p">:</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">avg</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">W</span><span class="p">[</span><span class="n">W</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">avg</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">W</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]))</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
        <span class="n">H</span><span class="p">[</span><span class="n">H</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">avg</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">H</span><span class="p">[</span><span class="n">H</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]))</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;Invalid init parameter: got </span><span class="si">%r</span><span class="s1"> instead of one of </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span>
            <span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="s1">&#39;nndsvd&#39;</span><span class="p">,</span> <span class="s1">&#39;nndsvda&#39;</span><span class="p">,</span> <span class="s1">&#39;nndsvdar&#39;</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span>


<span class="k">def</span> <span class="nf">_update_coordinate_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">Ht</span><span class="p">,</span> <span class="n">l1_reg</span><span class="p">,</span> <span class="n">l2_reg</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">,</span>
                               <span class="n">random_state</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for _fit_coordinate_descent</span>

<span class="sd">    Update W to minimize the objective function, iterating once over all</span>
<span class="sd">    coordinates. By symmetry, to update H, one can call</span>
<span class="sd">    _update_coordinate_descent(X.T, Ht, W, ...)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_components</span> <span class="o">=</span> <span class="n">Ht</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">HHt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ht</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Ht</span><span class="p">)</span>
    <span class="n">XHt</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Ht</span><span class="p">)</span>

    <span class="c1"># L2 regularization corresponds to increase of the diagonal of HHt</span>
    <span class="k">if</span> <span class="n">l2_reg</span> <span class="o">!=</span> <span class="mf">0.</span><span class="p">:</span>
        <span class="c1"># adds l2_reg only on the diagonal</span>
        <span class="n">HHt</span><span class="o">.</span><span class="n">flat</span><span class="p">[::</span><span class="n">n_components</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">l2_reg</span>
    <span class="c1"># L1 regularization corresponds to decrease of each element of XHt</span>
    <span class="k">if</span> <span class="n">l1_reg</span> <span class="o">!=</span> <span class="mf">0.</span><span class="p">:</span>
        <span class="n">XHt</span> <span class="o">-=</span> <span class="n">l1_reg</span>

    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">permutation</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n_components</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">permutation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_components</span><span class="p">)</span>
    <span class="c1"># The following seems to be required on 64-bit Windows w/ Python 3.5.</span>
    <span class="n">permutation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">permutation</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_update_cdnmf_fast</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">HHt</span><span class="p">,</span> <span class="n">XHt</span><span class="p">,</span> <span class="n">permutation</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_fit_coordinate_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">l1_reg_W</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                            <span class="n">l1_reg_H</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">l2_reg_W</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">l2_reg_H</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">update_H</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute Non-negative Matrix Factorization (NMF) with Coordinate Descent</span>

<span class="sd">    The objective function is minimized with an alternating minimization of W</span>
<span class="sd">    and H. Each minimization is done with a cyclic (up to a permutation of the</span>
<span class="sd">    features) Coordinate Descent.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape (n_samples, n_features)</span>
<span class="sd">        Constant matrix.</span>

<span class="sd">    W : array-like, shape (n_samples, n_components)</span>
<span class="sd">        Initial guess for the solution.</span>

<span class="sd">    H : array-like, shape (n_components, n_features)</span>
<span class="sd">        Initial guess for the solution.</span>

<span class="sd">    tol : float, default: 1e-4</span>
<span class="sd">        Tolerance of the stopping condition.</span>

<span class="sd">    max_iter : integer, default: 200</span>
<span class="sd">        Maximum number of iterations before timing out.</span>

<span class="sd">    l1_reg_W : double, default: 0.</span>
<span class="sd">        L1 regularization parameter for W.</span>

<span class="sd">    l1_reg_H : double, default: 0.</span>
<span class="sd">        L1 regularization parameter for H.</span>

<span class="sd">    l2_reg_W : double, default: 0.</span>
<span class="sd">        L2 regularization parameter for W.</span>

<span class="sd">    l2_reg_H : double, default: 0.</span>
<span class="sd">        L2 regularization parameter for H.</span>

<span class="sd">    update_H : boolean, default: True</span>
<span class="sd">        Set to True, both W and H will be estimated from initial guesses.</span>
<span class="sd">        Set to False, only W will be estimated.</span>

<span class="sd">    verbose : integer, default: 0</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    shuffle : boolean, default: False</span>
<span class="sd">        If true, randomize the order of coordinates in the CD solver.</span>

<span class="sd">    random_state : int, RandomState instance or None, optional, default: None</span>
<span class="sd">        If int, random_state is the seed used by the random number generator;</span>
<span class="sd">        If RandomState instance, random_state is the random number generator;</span>
<span class="sd">        If None, the random number generator is the RandomState instance used</span>
<span class="sd">        by `np.random`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    W : array-like, shape (n_samples, n_components)</span>
<span class="sd">        Solution to the non-negative least squares problem.</span>

<span class="sd">    H : array-like, shape (n_components, n_features)</span>
<span class="sd">        Solution to the non-negative least squares problem.</span>

<span class="sd">    n_iter : int</span>
<span class="sd">        The number of iterations done by the algorithm.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Cichocki, Andrzej, and P. H. A. N. Anh-Huy. &quot;Fast local algorithms for</span>
<span class="sd">    large scale nonnegative matrix and tensor factorizations.&quot;</span>
<span class="sd">    IEICE transactions on fundamentals of electronics, communications and</span>
<span class="sd">    computer sciences 92.3: 708-721, 2009.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># so W and Ht are both in C order in memory</span>
    <span class="n">Ht</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">H</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">)</span>

    <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">n_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="n">violation</span> <span class="o">=</span> <span class="mf">0.</span>

        <span class="c1"># Update W</span>
        <span class="n">violation</span> <span class="o">+=</span> <span class="n">_update_coordinate_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">Ht</span><span class="p">,</span> <span class="n">l1_reg_W</span><span class="p">,</span>
                                                <span class="n">l2_reg_W</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>
        <span class="c1"># Update H</span>
        <span class="k">if</span> <span class="n">update_H</span><span class="p">:</span>
            <span class="n">violation</span> <span class="o">+=</span> <span class="n">_update_coordinate_descent</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Ht</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">l1_reg_H</span><span class="p">,</span>
                                                    <span class="n">l2_reg_H</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_iter</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">violation_init</span> <span class="o">=</span> <span class="n">violation</span>

        <span class="k">if</span> <span class="n">violation_init</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;violation:&quot;</span><span class="p">,</span> <span class="n">violation</span> <span class="o">/</span> <span class="n">violation_init</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">violation</span> <span class="o">/</span> <span class="n">violation_init</span> <span class="o">&lt;=</span> <span class="n">tol</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Converged at iteration&quot;</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">Ht</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">n_iter</span>


<span class="k">def</span> <span class="nf">_multiplicative_update_w</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">beta_loss</span><span class="p">,</span> <span class="n">l1_reg_W</span><span class="p">,</span> <span class="n">l2_reg_W</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span>
                             <span class="n">H_sum</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">HHt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">XHt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">update_H</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;update W in Multiplicative Update NMF&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># Numerator</span>
        <span class="k">if</span> <span class="n">XHt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">XHt</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">H</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">update_H</span><span class="p">:</span>
            <span class="c1"># avoid a copy of XHt, which will be re-computed (update_H=True)</span>
            <span class="n">numerator</span> <span class="o">=</span> <span class="n">XHt</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># preserve the XHt, which is not re-computed (update_H=False)</span>
            <span class="n">numerator</span> <span class="o">=</span> <span class="n">XHt</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># Denominator</span>
        <span class="k">if</span> <span class="n">HHt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">HHt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">H</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">HHt</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Numerator</span>
        <span class="c1"># if X is sparse, compute WH only where X is non zero</span>
        <span class="n">WH_safe_X</span> <span class="o">=</span> <span class="n">_special_sparse_dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">WH_safe_X_data</span> <span class="o">=</span> <span class="n">WH_safe_X</span><span class="o">.</span><span class="n">data</span>
            <span class="n">X_data</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">WH_safe_X_data</span> <span class="o">=</span> <span class="n">WH_safe_X</span>
            <span class="n">X_data</span> <span class="o">=</span> <span class="n">X</span>
            <span class="c1"># copy used in the Denominator</span>
            <span class="n">WH</span> <span class="o">=</span> <span class="n">WH_safe_X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">-</span> <span class="mf">1.</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">WH</span><span class="p">[</span><span class="n">WH</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">EPSILON</span>

        <span class="c1"># to avoid taking a negative power of zero</span>
        <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">-</span> <span class="mf">2.</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">WH_safe_X_data</span><span class="p">[</span><span class="n">WH_safe_X_data</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">EPSILON</span>

        <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">WH_safe_X_data</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">WH_safe_X_data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">beta_loss</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># speeds up computation time</span>
            <span class="c1"># refer to /numpy/numpy/issues/9363</span>
            <span class="n">WH_safe_X_data</span> <span class="o">**=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="n">WH_safe_X_data</span> <span class="o">**=</span> <span class="mi">2</span>
            <span class="c1"># element-wise multiplication</span>
            <span class="n">WH_safe_X_data</span> <span class="o">*=</span> <span class="n">X_data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">WH_safe_X_data</span> <span class="o">**=</span> <span class="n">beta_loss</span> <span class="o">-</span> <span class="mi">2</span>
            <span class="c1"># element-wise multiplication</span>
            <span class="n">WH_safe_X_data</span> <span class="o">*=</span> <span class="n">X_data</span>

        <span class="c1"># here numerator = dot(X * (dot(W, H) ** (beta_loss - 2)), H.T)</span>
        <span class="n">numerator</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">WH_safe_X</span><span class="p">,</span> <span class="n">H</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="c1"># Denominator</span>
        <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">H_sum</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">H_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># shape(n_components, )</span>
            <span class="n">denominator</span> <span class="o">=</span> <span class="n">H_sum</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># computation of WHHt = dot(dot(W, H) ** beta_loss - 1, H.T)</span>
            <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
                <span class="c1"># memory efficient computation</span>
                <span class="c1"># (compute row by row, avoiding the dense matrix WH)</span>
                <span class="n">WHHt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="n">WHi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">H</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">WHi</span><span class="p">[</span><span class="n">WHi</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">EPSILON</span>
                    <span class="n">WHi</span> <span class="o">**=</span> <span class="n">beta_loss</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="n">WHHt</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">WHi</span><span class="p">,</span> <span class="n">H</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">WH</span> <span class="o">**=</span> <span class="n">beta_loss</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">WHHt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">WH</span><span class="p">,</span> <span class="n">H</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="n">denominator</span> <span class="o">=</span> <span class="n">WHHt</span>

    <span class="c1"># Add L1 and L2 regularization</span>
    <span class="k">if</span> <span class="n">l1_reg_W</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">denominator</span> <span class="o">+=</span> <span class="n">l1_reg_W</span>
    <span class="k">if</span> <span class="n">l2_reg_W</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">denominator</span> <span class="o">+</span> <span class="n">l2_reg_W</span> <span class="o">*</span> <span class="n">W</span>
    <span class="n">denominator</span><span class="p">[</span><span class="n">denominator</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">EPSILON</span>

    <span class="n">numerator</span> <span class="o">/=</span> <span class="n">denominator</span>
    <span class="n">delta_W</span> <span class="o">=</span> <span class="n">numerator</span>

    <span class="c1"># gamma is in ]0, 1]</span>
    <span class="k">if</span> <span class="n">gamma</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">delta_W</span> <span class="o">**=</span> <span class="n">gamma</span>

    <span class="k">return</span> <span class="n">delta_W</span><span class="p">,</span> <span class="n">H_sum</span><span class="p">,</span> <span class="n">HHt</span><span class="p">,</span> <span class="n">XHt</span>


<span class="k">def</span> <span class="nf">_multiplicative_update_h</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">beta_loss</span><span class="p">,</span> <span class="n">l1_reg_H</span><span class="p">,</span> <span class="n">l2_reg_H</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;update H in Multiplicative Update NMF&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">numerator</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> <span class="n">H</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Numerator</span>
        <span class="n">WH_safe_X</span> <span class="o">=</span> <span class="n">_special_sparse_dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">WH_safe_X_data</span> <span class="o">=</span> <span class="n">WH_safe_X</span><span class="o">.</span><span class="n">data</span>
            <span class="n">X_data</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">WH_safe_X_data</span> <span class="o">=</span> <span class="n">WH_safe_X</span>
            <span class="n">X_data</span> <span class="o">=</span> <span class="n">X</span>
            <span class="c1"># copy used in the Denominator</span>
            <span class="n">WH</span> <span class="o">=</span> <span class="n">WH_safe_X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">-</span> <span class="mf">1.</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">WH</span><span class="p">[</span><span class="n">WH</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">EPSILON</span>

        <span class="c1"># to avoid division by zero</span>
        <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">-</span> <span class="mf">2.</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">WH_safe_X_data</span><span class="p">[</span><span class="n">WH_safe_X_data</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">EPSILON</span>

        <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">WH_safe_X_data</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">WH_safe_X_data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">beta_loss</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># speeds up computation time</span>
            <span class="c1"># refer to /numpy/numpy/issues/9363</span>
            <span class="n">WH_safe_X_data</span> <span class="o">**=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="n">WH_safe_X_data</span> <span class="o">**=</span> <span class="mi">2</span>
            <span class="c1"># element-wise multiplication</span>
            <span class="n">WH_safe_X_data</span> <span class="o">*=</span> <span class="n">X_data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">WH_safe_X_data</span> <span class="o">**=</span> <span class="n">beta_loss</span> <span class="o">-</span> <span class="mi">2</span>
            <span class="c1"># element-wise multiplication</span>
            <span class="n">WH_safe_X_data</span> <span class="o">*=</span> <span class="n">X_data</span>

        <span class="c1"># here numerator = dot(W.T, (dot(W, H) ** (beta_loss - 2)) * X)</span>
        <span class="n">numerator</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">WH_safe_X</span><span class="p">)</span>

        <span class="c1"># Denominator</span>
        <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">W_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># shape(n_components, )</span>
            <span class="n">W_sum</span><span class="p">[</span><span class="n">W_sum</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
            <span class="n">denominator</span> <span class="o">=</span> <span class="n">W_sum</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

        <span class="c1"># beta_loss not in (1, 2)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># computation of WtWH = dot(W.T, dot(W, H) ** beta_loss - 1)</span>
            <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
                <span class="c1"># memory efficient computation</span>
                <span class="c1"># (compute column by column, avoiding the dense matrix WH)</span>
                <span class="n">WtWH</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">H</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                    <span class="n">WHi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
                    <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">WHi</span><span class="p">[</span><span class="n">WHi</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">EPSILON</span>
                    <span class="n">WHi</span> <span class="o">**=</span> <span class="n">beta_loss</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="n">WtWH</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">WHi</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">WH</span> <span class="o">**=</span> <span class="n">beta_loss</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">WtWH</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">WH</span><span class="p">)</span>
            <span class="n">denominator</span> <span class="o">=</span> <span class="n">WtWH</span>

    <span class="c1"># Add L1 and L2 regularization</span>
    <span class="k">if</span> <span class="n">l1_reg_H</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">denominator</span> <span class="o">+=</span> <span class="n">l1_reg_H</span>
    <span class="k">if</span> <span class="n">l2_reg_H</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">denominator</span> <span class="o">+</span> <span class="n">l2_reg_H</span> <span class="o">*</span> <span class="n">H</span>
    <span class="n">denominator</span><span class="p">[</span><span class="n">denominator</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">EPSILON</span>

    <span class="n">numerator</span> <span class="o">/=</span> <span class="n">denominator</span>
    <span class="n">delta_H</span> <span class="o">=</span> <span class="n">numerator</span>

    <span class="c1"># gamma is in ]0, 1]</span>
    <span class="k">if</span> <span class="n">gamma</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">delta_H</span> <span class="o">**=</span> <span class="n">gamma</span>

    <span class="k">return</span> <span class="n">delta_H</span>


<span class="k">def</span> <span class="nf">_fit_multiplicative_update</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">beta_loss</span><span class="o">=</span><span class="s1">&#39;frobenius&#39;</span><span class="p">,</span>
                               <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
                               <span class="n">l1_reg_W</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">l1_reg_H</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">l2_reg_W</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">l2_reg_H</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                               <span class="n">update_H</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute Non-negative Matrix Factorization with Multiplicative Update</span>

<span class="sd">    The objective function is _beta_divergence(X, WH) and is minimized with an</span>
<span class="sd">    alternating minimization of W and H. Each minimization is done with a</span>
<span class="sd">    Multiplicative Update.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape (n_samples, n_features)</span>
<span class="sd">        Constant input matrix.</span>

<span class="sd">    W : array-like, shape (n_samples, n_components)</span>
<span class="sd">        Initial guess for the solution.</span>

<span class="sd">    H : array-like, shape (n_components, n_features)</span>
<span class="sd">        Initial guess for the solution.</span>

<span class="sd">    beta_loss : float or string, default &#39;frobenius&#39;</span>
<span class="sd">        String must be in {&#39;frobenius&#39;, &#39;kullback-leibler&#39;, &#39;itakura-saito&#39;}.</span>
<span class="sd">        Beta divergence to be minimized, measuring the distance between X</span>
<span class="sd">        and the dot product WH. Note that values different from &#39;frobenius&#39;</span>
<span class="sd">        (or 2) and &#39;kullback-leibler&#39; (or 1) lead to significantly slower</span>
<span class="sd">        fits. Note that for beta_loss &lt;= 0 (or &#39;itakura-saito&#39;), the input</span>
<span class="sd">        matrix X cannot contain zeros.</span>

<span class="sd">    max_iter : integer, default: 200</span>
<span class="sd">        Number of iterations.</span>

<span class="sd">    tol : float, default: 1e-4</span>
<span class="sd">        Tolerance of the stopping condition.</span>

<span class="sd">    l1_reg_W : double, default: 0.</span>
<span class="sd">        L1 regularization parameter for W.</span>

<span class="sd">    l1_reg_H : double, default: 0.</span>
<span class="sd">        L1 regularization parameter for H.</span>

<span class="sd">    l2_reg_W : double, default: 0.</span>
<span class="sd">        L2 regularization parameter for W.</span>

<span class="sd">    l2_reg_H : double, default: 0.</span>
<span class="sd">        L2 regularization parameter for H.</span>

<span class="sd">    update_H : boolean, default: True</span>
<span class="sd">        Set to True, both W and H will be estimated from initial guesses.</span>
<span class="sd">        Set to False, only W will be estimated.</span>

<span class="sd">    verbose : integer, default: 0</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    W : array, shape (n_samples, n_components)</span>
<span class="sd">        Solution to the non-negative least squares problem.</span>

<span class="sd">    H : array, shape (n_components, n_features)</span>
<span class="sd">        Solution to the non-negative least squares problem.</span>

<span class="sd">    n_iter : int</span>
<span class="sd">        The number of iterations done by the algorithm.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Fevotte, C., &amp; Idier, J. (2011). Algorithms for nonnegative matrix</span>
<span class="sd">    factorization with the beta-divergence. Neural Computation, 23(9).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">beta_loss</span> <span class="o">=</span> <span class="n">_beta_loss_to_float</span><span class="p">(</span><span class="n">beta_loss</span><span class="p">)</span>

    <span class="c1"># gamma for Maximization-Minimization (MM) algorithm [Fevotte 2011]</span>
    <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">-</span> <span class="n">beta_loss</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">beta_loss</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="n">beta_loss</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="c1"># used for the convergence criterion</span>
    <span class="n">error_at_init</span> <span class="o">=</span> <span class="n">_beta_divergence</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">beta_loss</span><span class="p">,</span> <span class="n">square_root</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">previous_error</span> <span class="o">=</span> <span class="n">error_at_init</span>

    <span class="n">H_sum</span><span class="p">,</span> <span class="n">HHt</span><span class="p">,</span> <span class="n">XHt</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">n_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># update W</span>
        <span class="c1"># H_sum, HHt and XHt are saved and reused if not update_H</span>
        <span class="n">delta_W</span><span class="p">,</span> <span class="n">H_sum</span><span class="p">,</span> <span class="n">HHt</span><span class="p">,</span> <span class="n">XHt</span> <span class="o">=</span> <span class="n">_multiplicative_update_w</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">beta_loss</span><span class="p">,</span> <span class="n">l1_reg_W</span><span class="p">,</span> <span class="n">l2_reg_W</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span>
            <span class="n">H_sum</span><span class="p">,</span> <span class="n">HHt</span><span class="p">,</span> <span class="n">XHt</span><span class="p">,</span> <span class="n">update_H</span><span class="p">)</span>
        <span class="n">W</span> <span class="o">*=</span> <span class="n">delta_W</span>

        <span class="c1"># necessary for stability with beta_loss &lt; 1</span>
        <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">W</span><span class="p">[</span><span class="n">W</span> <span class="o">&lt;</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>

        <span class="c1"># update H</span>
        <span class="k">if</span> <span class="n">update_H</span><span class="p">:</span>
            <span class="n">delta_H</span> <span class="o">=</span> <span class="n">_multiplicative_update_h</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">beta_loss</span><span class="p">,</span> <span class="n">l1_reg_H</span><span class="p">,</span>
                                               <span class="n">l2_reg_H</span><span class="p">,</span> <span class="n">gamma</span><span class="p">)</span>
            <span class="n">H</span> <span class="o">*=</span> <span class="n">delta_H</span>

            <span class="c1"># These values will be recomputed since H changed</span>
            <span class="n">H_sum</span><span class="p">,</span> <span class="n">HHt</span><span class="p">,</span> <span class="n">XHt</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

            <span class="c1"># necessary for stability with beta_loss &lt; 1</span>
            <span class="k">if</span> <span class="n">beta_loss</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">H</span><span class="p">[</span><span class="n">H</span> <span class="o">&lt;</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>

        <span class="c1"># test convergence criterion every 10 iterations</span>
        <span class="k">if</span> <span class="n">tol</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">n_iter</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">error</span> <span class="o">=</span> <span class="n">_beta_divergence</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">beta_loss</span><span class="p">,</span> <span class="n">square_root</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">iter_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">%02d</span><span class="s2"> reached after </span><span class="si">%.3f</span><span class="s2"> seconds, error: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span>
                      <span class="p">(</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">iter_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="n">error</span><span class="p">))</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">previous_error</span> <span class="o">-</span> <span class="n">error</span><span class="p">)</span> <span class="o">/</span> <span class="n">error_at_init</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">previous_error</span> <span class="o">=</span> <span class="n">error</span>

    <span class="c1"># do not print if we have already printed in the convergence test</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="p">(</span><span class="n">tol</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">n_iter</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">%02d</span><span class="s2"> reached after </span><span class="si">%.3f</span><span class="s2"> seconds.&quot;</span> <span class="o">%</span>
              <span class="p">(</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">n_iter</span>


<span class="k">def</span> <span class="nf">non_negative_factorization</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">H</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                               <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">update_H</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;cd&#39;</span><span class="p">,</span>
                               <span class="n">beta_loss</span><span class="o">=</span><span class="s1">&#39;frobenius&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
                               <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
                               <span class="n">regularization</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                               <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute Non-negative Matrix Factorization (NMF)</span>

<span class="sd">    Find two non-negative matrices (W, H) whose product approximates the non-</span>
<span class="sd">    negative matrix X. This factorization can be used for example for</span>
<span class="sd">    dimensionality reduction, source separation or topic extraction.</span>

<span class="sd">    The objective function is::</span>

<span class="sd">        0.5 * ||X - WH||_Fro^2</span>
<span class="sd">        + alpha * l1_ratio * ||vec(W)||_1</span>
<span class="sd">        + alpha * l1_ratio * ||vec(H)||_1</span>
<span class="sd">        + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2</span>
<span class="sd">        + 0.5 * alpha * (1 - l1_ratio) * ||H||_Fro^2</span>

<span class="sd">    Where::</span>

<span class="sd">        ||A||_Fro^2 = \sum_{i,j} A_{ij}^2 (Frobenius norm)</span>
<span class="sd">        ||vec(A)||_1 = \sum_{i,j} abs(A_{ij}) (Elementwise L1 norm)</span>

<span class="sd">    For multiplicative-update (&#39;mu&#39;) solver, the Frobenius norm</span>
<span class="sd">    (0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss,</span>
<span class="sd">    by changing the beta_loss parameter.</span>

<span class="sd">    The objective function is minimized with an alternating minimization of W</span>
<span class="sd">    and H. If H is given and update_H=False, it solves for W only.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape (n_samples, n_features)</span>
<span class="sd">        Constant matrix.</span>

<span class="sd">    W : array-like, shape (n_samples, n_components)</span>
<span class="sd">        If init=&#39;custom&#39;, it is used as initial guess for the solution.</span>

<span class="sd">    H : array-like, shape (n_components, n_features)</span>
<span class="sd">        If init=&#39;custom&#39;, it is used as initial guess for the solution.</span>
<span class="sd">        If update_H=False, it is used as a constant, to solve for W only.</span>

<span class="sd">    n_components : integer</span>
<span class="sd">        Number of components, if n_components is not set all features</span>
<span class="sd">        are kept.</span>

<span class="sd">    init :  None | &#39;random&#39; | &#39;nndsvd&#39; | &#39;nndsvda&#39; | &#39;nndsvdar&#39; | &#39;custom&#39;</span>
<span class="sd">        Method used to initialize the procedure.</span>
<span class="sd">        Default: &#39;nndsvd&#39; if n_components &lt; n_features, otherwise random.</span>
<span class="sd">        Valid options:</span>

<span class="sd">        - &#39;random&#39;: non-negative random matrices, scaled with:</span>
<span class="sd">            sqrt(X.mean() / n_components)</span>

<span class="sd">        - &#39;nndsvd&#39;: Nonnegative Double Singular Value Decomposition (NNDSVD)</span>
<span class="sd">            initialization (better for sparseness)</span>

<span class="sd">        - &#39;nndsvda&#39;: NNDSVD with zeros filled with the average of X</span>
<span class="sd">            (better when sparsity is not desired)</span>

<span class="sd">        - &#39;nndsvdar&#39;: NNDSVD with zeros filled with small random values</span>
<span class="sd">            (generally faster, less accurate alternative to NNDSVDa</span>
<span class="sd">            for when sparsity is not desired)</span>

<span class="sd">        - &#39;custom&#39;: use custom matrices W and H</span>

<span class="sd">    update_H : boolean, default: True</span>
<span class="sd">        Set to True, both W and H will be estimated from initial guesses.</span>
<span class="sd">        Set to False, only W will be estimated.</span>

<span class="sd">    solver : &#39;cd&#39; | &#39;mu&#39;</span>
<span class="sd">        Numerical solver to use:</span>
<span class="sd">        &#39;cd&#39; is a Coordinate Descent solver.</span>
<span class="sd">        &#39;mu&#39; is a Multiplicative Update solver.</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           Coordinate Descent solver.</span>

<span class="sd">        .. versionadded:: 0.19</span>
<span class="sd">           Multiplicative Update solver.</span>

<span class="sd">    beta_loss : float or string, default &#39;frobenius&#39;</span>
<span class="sd">        String must be in {&#39;frobenius&#39;, &#39;kullback-leibler&#39;, &#39;itakura-saito&#39;}.</span>
<span class="sd">        Beta divergence to be minimized, measuring the distance between X</span>
<span class="sd">        and the dot product WH. Note that values different from &#39;frobenius&#39;</span>
<span class="sd">        (or 2) and &#39;kullback-leibler&#39; (or 1) lead to significantly slower</span>
<span class="sd">        fits. Note that for beta_loss &lt;= 0 (or &#39;itakura-saito&#39;), the input</span>
<span class="sd">        matrix X cannot contain zeros. Used only in &#39;mu&#39; solver.</span>

<span class="sd">        .. versionadded:: 0.19</span>

<span class="sd">    tol : float, default: 1e-4</span>
<span class="sd">        Tolerance of the stopping condition.</span>

<span class="sd">    max_iter : integer, default: 200</span>
<span class="sd">        Maximum number of iterations before timing out.</span>

<span class="sd">    alpha : double, default: 0.</span>
<span class="sd">        Constant that multiplies the regularization terms.</span>

<span class="sd">    l1_ratio : double, default: 0.</span>
<span class="sd">        The regularization mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.</span>
<span class="sd">        For l1_ratio = 0 the penalty is an elementwise L2 penalty</span>
<span class="sd">        (aka Frobenius Norm).</span>
<span class="sd">        For l1_ratio = 1 it is an elementwise L1 penalty.</span>
<span class="sd">        For 0 &lt; l1_ratio &lt; 1, the penalty is a combination of L1 and L2.</span>

<span class="sd">    regularization : &#39;both&#39; | &#39;components&#39; | &#39;transformation&#39; | None</span>
<span class="sd">        Select whether the regularization affects the components (H), the</span>
<span class="sd">        transformation (W), both or none of them.</span>

<span class="sd">    random_state : int, RandomState instance or None, optional, default: None</span>
<span class="sd">        If int, random_state is the seed used by the random number generator;</span>
<span class="sd">        If RandomState instance, random_state is the random number generator;</span>
<span class="sd">        If None, the random number generator is the RandomState instance used</span>
<span class="sd">        by `np.random`.</span>

<span class="sd">    verbose : integer, default: 0</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    shuffle : boolean, default: False</span>
<span class="sd">        If true, randomize the order of coordinates in the CD solver.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    W : array-like, shape (n_samples, n_components)</span>
<span class="sd">        Solution to the non-negative least squares problem.</span>

<span class="sd">    H : array-like, shape (n_components, n_features)</span>
<span class="sd">        Solution to the non-negative least squares problem.</span>

<span class="sd">    n_iter : int</span>
<span class="sd">        Actual number of iterations.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1,1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.decomposition import non_negative_factorization</span>
<span class="sd">    &gt;&gt;&gt; W, H, n_iter = non_negative_factorization(X, n_components=2, \</span>
<span class="sd">        init=&#39;random&#39;, random_state=0)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Cichocki, Andrzej, and P. H. A. N. Anh-Huy. &quot;Fast local algorithms for</span>
<span class="sd">    large scale nonnegative matrix and tensor factorizations.&quot;</span>
<span class="sd">    IEICE transactions on fundamentals of electronics, communications and</span>
<span class="sd">    computer sciences 92.3: 708-721, 2009.</span>

<span class="sd">    Fevotte, C., &amp; Idier, J. (2011). Algorithms for nonnegative matrix</span>
<span class="sd">    factorization with the beta-divergence. Neural Computation, 23(9).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="s1">&#39;csc&#39;</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">check_non_negative</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s2">&quot;NMF (input X)&quot;</span><span class="p">)</span>
    <span class="n">beta_loss</span> <span class="o">=</span> <span class="n">_check_string_param</span><span class="p">(</span><span class="n">solver</span><span class="p">,</span> <span class="n">regularization</span><span class="p">,</span> <span class="n">beta_loss</span><span class="p">,</span> <span class="n">init</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">safe_min</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">beta_loss</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;When beta_loss &lt;= 0 and X contains zeros, &quot;</span>
                         <span class="s2">&quot;the solver may diverge. Please add small values to &quot;</span>
                         <span class="s2">&quot;X, or use a positive beta_loss.&quot;</span><span class="p">)</span>

    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">n_components</span> <span class="o">=</span> <span class="n">n_features</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">INTEGER_TYPES</span><span class="p">)</span> <span class="ow">or</span> <span class="n">n_components</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Number of components must be a positive integer;&quot;</span>
                         <span class="s2">&quot; got (n_components=</span><span class="si">%r</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">n_components</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">INTEGER_TYPES</span><span class="p">)</span> <span class="ow">or</span> <span class="n">max_iter</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations must be a positive &quot;</span>
                         <span class="s2">&quot;integer; got (max_iter=</span><span class="si">%r</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">max_iter</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tol</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">)</span> <span class="ow">or</span> <span class="n">tol</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Tolerance for stopping criteria must be &quot;</span>
                         <span class="s2">&quot;positive; got (tol=</span><span class="si">%r</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">tol</span><span class="p">)</span>

    <span class="c1"># check W and H, or initialize them</span>
    <span class="k">if</span> <span class="n">init</span> <span class="o">==</span> <span class="s1">&#39;custom&#39;</span> <span class="ow">and</span> <span class="n">update_H</span><span class="p">:</span>
        <span class="n">_check_init</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="s2">&quot;NMF (input H)&quot;</span><span class="p">)</span>
        <span class="n">_check_init</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_components</span><span class="p">),</span> <span class="s2">&quot;NMF (input W)&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="n">update_H</span><span class="p">:</span>
        <span class="n">_check_init</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="s2">&quot;NMF (input H)&quot;</span><span class="p">)</span>
        <span class="c1"># &#39;mu&#39; solver should not be initialized by zeros</span>
        <span class="k">if</span> <span class="n">solver</span> <span class="o">==</span> <span class="s1">&#39;mu&#39;</span><span class="p">:</span>
            <span class="n">avg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">/</span> <span class="n">n_components</span><span class="p">)</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">avg</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_components</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_components</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">W</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="n">_initialize_nmf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_components</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span>
                               <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

    <span class="n">l1_reg_W</span><span class="p">,</span> <span class="n">l1_reg_H</span><span class="p">,</span> <span class="n">l2_reg_W</span><span class="p">,</span> <span class="n">l2_reg_H</span> <span class="o">=</span> <span class="n">_compute_regularization</span><span class="p">(</span>
        <span class="n">alpha</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="p">,</span> <span class="n">regularization</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">solver</span> <span class="o">==</span> <span class="s1">&#39;cd&#39;</span><span class="p">:</span>
        <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="n">_fit_coordinate_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span>
                                               <span class="n">l1_reg_W</span><span class="p">,</span> <span class="n">l1_reg_H</span><span class="p">,</span>
                                               <span class="n">l2_reg_W</span><span class="p">,</span> <span class="n">l2_reg_H</span><span class="p">,</span>
                                               <span class="n">update_H</span><span class="o">=</span><span class="n">update_H</span><span class="p">,</span>
                                               <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                                               <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
                                               <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">solver</span> <span class="o">==</span> <span class="s1">&#39;mu&#39;</span><span class="p">:</span>
        <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="n">_fit_multiplicative_update</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">beta_loss</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span>
                                                  <span class="n">tol</span><span class="p">,</span> <span class="n">l1_reg_W</span><span class="p">,</span> <span class="n">l1_reg_H</span><span class="p">,</span>
                                                  <span class="n">l2_reg_W</span><span class="p">,</span> <span class="n">l2_reg_H</span><span class="p">,</span> <span class="n">update_H</span><span class="p">,</span>
                                                  <span class="n">verbose</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid solver parameter &#39;</span><span class="si">%s</span><span class="s2">&#39;.&quot;</span> <span class="o">%</span> <span class="n">solver</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n_iter</span> <span class="o">==</span> <span class="n">max_iter</span> <span class="ow">and</span> <span class="n">tol</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Maximum number of iteration </span><span class="si">%d</span><span class="s2"> reached. Increase it to&quot;</span>
                      <span class="s2">&quot; improve convergence.&quot;</span> <span class="o">%</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">ConvergenceWarning</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">n_iter</span>


<span class="k">class</span> <span class="nc">NMF</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Non-Negative Matrix Factorization (NMF)</span>

<span class="sd">    Find two non-negative matrices (W, H) whose product approximates the non-</span>
<span class="sd">    negative matrix X. This factorization can be used for example for</span>
<span class="sd">    dimensionality reduction, source separation or topic extraction.</span>

<span class="sd">    The objective function is::</span>

<span class="sd">        0.5 * ||X - WH||_Fro^2</span>
<span class="sd">        + alpha * l1_ratio * ||vec(W)||_1</span>
<span class="sd">        + alpha * l1_ratio * ||vec(H)||_1</span>
<span class="sd">        + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2</span>
<span class="sd">        + 0.5 * alpha * (1 - l1_ratio) * ||H||_Fro^2</span>

<span class="sd">    Where::</span>

<span class="sd">        ||A||_Fro^2 = \sum_{i,j} A_{ij}^2 (Frobenius norm)</span>
<span class="sd">        ||vec(A)||_1 = \sum_{i,j} abs(A_{ij}) (Elementwise L1 norm)</span>

<span class="sd">    For multiplicative-update (&#39;mu&#39;) solver, the Frobenius norm</span>
<span class="sd">    (0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss,</span>
<span class="sd">    by changing the beta_loss parameter.</span>

<span class="sd">    The objective function is minimized with an alternating minimization of W</span>
<span class="sd">    and H.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;NMF&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_components : int or None</span>
<span class="sd">        Number of components, if n_components is not set all features</span>
<span class="sd">        are kept.</span>

<span class="sd">    init :  &#39;random&#39; | &#39;nndsvd&#39; |  &#39;nndsvda&#39; | &#39;nndsvdar&#39; | &#39;custom&#39;</span>
<span class="sd">        Method used to initialize the procedure.</span>
<span class="sd">        Default: &#39;nndsvd&#39; if n_components &lt; n_features, otherwise random.</span>
<span class="sd">        Valid options:</span>

<span class="sd">        - &#39;random&#39;: non-negative random matrices, scaled with:</span>
<span class="sd">            sqrt(X.mean() / n_components)</span>

<span class="sd">        - &#39;nndsvd&#39;: Nonnegative Double Singular Value Decomposition (NNDSVD)</span>
<span class="sd">            initialization (better for sparseness)</span>

<span class="sd">        - &#39;nndsvda&#39;: NNDSVD with zeros filled with the average of X</span>
<span class="sd">            (better when sparsity is not desired)</span>

<span class="sd">        - &#39;nndsvdar&#39;: NNDSVD with zeros filled with small random values</span>
<span class="sd">            (generally faster, less accurate alternative to NNDSVDa</span>
<span class="sd">            for when sparsity is not desired)</span>

<span class="sd">        - &#39;custom&#39;: use custom matrices W and H</span>

<span class="sd">    solver : &#39;cd&#39; | &#39;mu&#39;</span>
<span class="sd">        Numerical solver to use:</span>
<span class="sd">        &#39;cd&#39; is a Coordinate Descent solver.</span>
<span class="sd">        &#39;mu&#39; is a Multiplicative Update solver.</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           Coordinate Descent solver.</span>

<span class="sd">        .. versionadded:: 0.19</span>
<span class="sd">           Multiplicative Update solver.</span>

<span class="sd">    beta_loss : float or string, default &#39;frobenius&#39;</span>
<span class="sd">        String must be in {&#39;frobenius&#39;, &#39;kullback-leibler&#39;, &#39;itakura-saito&#39;}.</span>
<span class="sd">        Beta divergence to be minimized, measuring the distance between X</span>
<span class="sd">        and the dot product WH. Note that values different from &#39;frobenius&#39;</span>
<span class="sd">        (or 2) and &#39;kullback-leibler&#39; (or 1) lead to significantly slower</span>
<span class="sd">        fits. Note that for beta_loss &lt;= 0 (or &#39;itakura-saito&#39;), the input</span>
<span class="sd">        matrix X cannot contain zeros. Used only in &#39;mu&#39; solver.</span>

<span class="sd">        .. versionadded:: 0.19</span>

<span class="sd">    tol : float, default: 1e-4</span>
<span class="sd">        Tolerance of the stopping condition.</span>

<span class="sd">    max_iter : integer, default: 200</span>
<span class="sd">        Maximum number of iterations before timing out.</span>

<span class="sd">    random_state : int, RandomState instance or None, optional, default: None</span>
<span class="sd">        If int, random_state is the seed used by the random number generator;</span>
<span class="sd">        If RandomState instance, random_state is the random number generator;</span>
<span class="sd">        If None, the random number generator is the RandomState instance used</span>
<span class="sd">        by `np.random`.</span>

<span class="sd">    alpha : double, default: 0.</span>
<span class="sd">        Constant that multiplies the regularization terms. Set it to zero to</span>
<span class="sd">        have no regularization.</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           *alpha* used in the Coordinate Descent solver.</span>

<span class="sd">    l1_ratio : double, default: 0.</span>
<span class="sd">        The regularization mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.</span>
<span class="sd">        For l1_ratio = 0 the penalty is an elementwise L2 penalty</span>
<span class="sd">        (aka Frobenius Norm).</span>
<span class="sd">        For l1_ratio = 1 it is an elementwise L1 penalty.</span>
<span class="sd">        For 0 &lt; l1_ratio &lt; 1, the penalty is a combination of L1 and L2.</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           Regularization parameter *l1_ratio* used in the Coordinate Descent</span>
<span class="sd">           solver.</span>

<span class="sd">    verbose : bool, default=False</span>
<span class="sd">        Whether to be verbose.</span>

<span class="sd">    shuffle : boolean, default: False</span>
<span class="sd">        If true, randomize the order of coordinates in the CD solver.</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           *shuffle* parameter used in the Coordinate Descent solver.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    components_ : array, [n_components, n_features]</span>
<span class="sd">        Factorization matrix, sometimes called &#39;dictionary&#39;.</span>

<span class="sd">    reconstruction_err_ : number</span>
<span class="sd">        Frobenius norm of the matrix difference, or beta-divergence, between</span>
<span class="sd">        the training data ``X`` and the reconstructed data ``WH`` from</span>
<span class="sd">        the fitted model.</span>

<span class="sd">    n_iter_ : int</span>
<span class="sd">        Actual number of iterations.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.decomposition import NMF</span>
<span class="sd">    &gt;&gt;&gt; model = NMF(n_components=2, init=&#39;random&#39;, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; W = model.fit_transform(X)</span>
<span class="sd">    &gt;&gt;&gt; H = model.components_</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Cichocki, Andrzej, and P. H. A. N. Anh-Huy. &quot;Fast local algorithms for</span>
<span class="sd">    large scale nonnegative matrix and tensor factorizations.&quot;</span>
<span class="sd">    IEICE transactions on fundamentals of electronics, communications and</span>
<span class="sd">    computer sciences 92.3: 708-721, 2009.</span>

<span class="sd">    Fevotte, C., &amp; Idier, J. (2011). Algorithms for nonnegative matrix</span>
<span class="sd">    factorization with the beta-divergence. Neural Computation, 23(9).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;cd&#39;</span><span class="p">,</span>
                 <span class="n">beta_loss</span><span class="o">=</span><span class="s1">&#39;frobenius&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">=</span> <span class="n">init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta_loss</span> <span class="o">=</span> <span class="n">beta_loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1_ratio</span> <span class="o">=</span> <span class="n">l1_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>

<div class="viewcode-block" id="NMF.fit_transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_decomposition_nmf.html#ibex.sklearn.decomposition.NMF.fit_transform">[docs]</a>    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">H</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Learn a NMF model for the data X and returns the transformed data.</span>

<span class="sd">        This is more efficient than calling fit followed by transform.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}, shape (n_samples, n_features)</span>
<span class="sd">            Data matrix to be decomposed</span>

<span class="sd">        W : array-like, shape (n_samples, n_components)</span>
<span class="sd">            If init=&#39;custom&#39;, it is used as initial guess for the solution.</span>

<span class="sd">        H : array-like, shape (n_components, n_features)</span>
<span class="sd">            If init=&#39;custom&#39;, it is used as initial guess for the solution.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        W : array, shape (n_samples, n_components)</span>
<span class="sd">            Transformed data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="s1">&#39;csc&#39;</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

        <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">n_iter_</span> <span class="o">=</span> <span class="n">non_negative_factorization</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="o">=</span><span class="n">H</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">,</span>
            <span class="n">update_H</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span> <span class="n">beta_loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">beta_loss</span><span class="p">,</span>
            <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
            <span class="n">l1_ratio</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">l1_ratio</span><span class="p">,</span> <span class="n">regularization</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reconstruction_err_</span> <span class="o">=</span> <span class="n">_beta_divergence</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_loss</span><span class="p">,</span>
                                                    <span class="n">square_root</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_components_</span> <span class="o">=</span> <span class="n">H</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="n">H</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="n">n_iter_</span>

        <span class="k">return</span> <span class="n">W</span></div>

<div class="viewcode-block" id="NMF.fit"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_decomposition_nmf.html#ibex.sklearn.decomposition.NMF.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Learn a NMF model for the data X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}, shape (n_samples, n_features)</span>
<span class="sd">            Data matrix to be decomposed</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="NMF.transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_decomposition_nmf.html#ibex.sklearn.decomposition.NMF.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Transform the data X according to the fitted NMF model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}, shape (n_samples, n_features)</span>
<span class="sd">            Data matrix to be transformed by the model</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        W : array, shape (n_samples, n_components)</span>
<span class="sd">            Transformed data</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;n_components_&#39;</span><span class="p">)</span>

        <span class="n">W</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">n_iter_</span> <span class="o">=</span> <span class="n">non_negative_factorization</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">H</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components_</span><span class="p">,</span>
            <span class="n">init</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">,</span> <span class="n">update_H</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
            <span class="n">beta_loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">beta_loss</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">l1_ratio</span><span class="p">,</span> <span class="n">regularization</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">W</span></div>

<div class="viewcode-block" id="NMF.inverse_transform"><a class="viewcode-back" href="../../../tmp/api_ibex_sklearn_decomposition_nmf.html#ibex.sklearn.decomposition.NMF.inverse_transform">[docs]</a>    <span class="k">def</span> <span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Transform data back to its original space.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        W : {array-like, sparse matrix}, shape (n_samples, n_components)</span>
<span class="sd">            Transformed data matrix</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X : {array-like, sparse matrix}, shape (n_samples, n_features)</span>
<span class="sd">            Data matrix of original shape</span>

<span class="sd">        .. versionadded:: 0.18</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;n_components_&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="p">)</span></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../index.html">
              <img class="logo" src="../../../_static/logo.jpeg" alt="Logo"/>
            </a></p><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Ami Tavory, Shahar Azulay, Tali Raveh-Sadka.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.5</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
    </div>

    
    <a href="https://github.com/atavory/ibex" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>