
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>sklearn.decomposition.dict_learning &#8212; ibex latest documentation</title>
    <link rel="stylesheet" href="../../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     'latest',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for sklearn.decomposition.dict_learning</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot; Dictionary learning</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>
<span class="c1"># Author: Vlad Niculae, Gael Varoquaux, Alexandre Gramfort</span>
<span class="c1"># License: BSD 3 clause</span>

<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">itertools</span>

<span class="kn">from</span> <span class="nn">math</span> <span class="k">import</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">ceil</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">linalg</span>
<span class="kn">from</span> <span class="nn">numpy.lib.stride_tricks</span> <span class="k">import</span> <span class="n">as_strided</span>

<span class="kn">from</span> <span class="nn">..base</span> <span class="k">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">..externals.joblib</span> <span class="k">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span><span class="p">,</span> <span class="n">cpu_count</span>
<span class="kn">from</span> <span class="nn">..externals.six.moves</span> <span class="k">import</span> <span class="nb">zip</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="k">import</span> <span class="p">(</span><span class="n">check_array</span><span class="p">,</span> <span class="n">check_random_state</span><span class="p">,</span> <span class="n">gen_even_slices</span><span class="p">,</span>
                     <span class="n">gen_batches</span><span class="p">,</span> <span class="n">_get_n_jobs</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">..utils.extmath</span> <span class="k">import</span> <span class="n">randomized_svd</span><span class="p">,</span> <span class="n">row_norms</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="k">import</span> <span class="n">check_is_fitted</span>
<span class="kn">from</span> <span class="nn">..linear_model</span> <span class="k">import</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">orthogonal_mp_gram</span><span class="p">,</span> <span class="n">LassoLars</span><span class="p">,</span> <span class="n">Lars</span>


<span class="k">def</span> <span class="nf">_sparse_encode</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">gram</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;lasso_lars&#39;</span><span class="p">,</span>
                   <span class="n">regularization</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copy_cov</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">check_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generic sparse coding</span>

<span class="sd">    Each column of the result is the solution to a Lasso problem.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array of shape (n_samples, n_features)</span>
<span class="sd">        Data matrix.</span>

<span class="sd">    dictionary : array of shape (n_components, n_features)</span>
<span class="sd">        The dictionary matrix against which to solve the sparse coding of</span>
<span class="sd">        the data. Some of the algorithms assume normalized rows.</span>

<span class="sd">    gram : None | array, shape=(n_components, n_components)</span>
<span class="sd">        Precomputed Gram matrix, dictionary * dictionary&#39;</span>
<span class="sd">        gram can be None if method is &#39;threshold&#39;.</span>

<span class="sd">    cov : array, shape=(n_components, n_samples)</span>
<span class="sd">        Precomputed covariance, dictionary * X&#39;</span>

<span class="sd">    algorithm : {&#39;lasso_lars&#39;, &#39;lasso_cd&#39;, &#39;lars&#39;, &#39;omp&#39;, &#39;threshold&#39;}</span>
<span class="sd">        lars: uses the least angle regression method (linear_model.lars_path)</span>
<span class="sd">        lasso_lars: uses Lars to compute the Lasso solution</span>
<span class="sd">        lasso_cd: uses the coordinate descent method to compute the</span>
<span class="sd">        Lasso solution (linear_model.Lasso). lasso_lars will be faster if</span>
<span class="sd">        the estimated components are sparse.</span>
<span class="sd">        omp: uses orthogonal matching pursuit to estimate the sparse solution</span>
<span class="sd">        threshold: squashes to zero all coefficients less than regularization</span>
<span class="sd">        from the projection dictionary * data&#39;</span>

<span class="sd">    regularization : int | float</span>
<span class="sd">        The regularization parameter. It corresponds to alpha when</span>
<span class="sd">        algorithm is &#39;lasso_lars&#39;, &#39;lasso_cd&#39; or &#39;threshold&#39;.</span>
<span class="sd">        Otherwise it corresponds to n_nonzero_coefs.</span>

<span class="sd">    init : array of shape (n_samples, n_components)</span>
<span class="sd">        Initialization value of the sparse code. Only used if</span>
<span class="sd">        `algorithm=&#39;lasso_cd&#39;`.</span>

<span class="sd">    max_iter : int, 1000 by default</span>
<span class="sd">        Maximum number of iterations to perform if `algorithm=&#39;lasso_cd&#39;`.</span>

<span class="sd">    copy_cov : boolean, optional</span>
<span class="sd">        Whether to copy the precomputed covariance matrix; if False, it may be</span>
<span class="sd">        overwritten.</span>

<span class="sd">    check_input : boolean, optional</span>
<span class="sd">        If False, the input arrays X and dictionary will not be checked.</span>

<span class="sd">    verbose : int</span>
<span class="sd">        Controls the verbosity; the higher, the more messages. Defaults to 0.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    code : array of shape (n_components, n_features)</span>
<span class="sd">        The sparse codes</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    sklearn.linear_model.lars_path</span>
<span class="sd">    sklearn.linear_model.orthogonal_mp</span>
<span class="sd">    sklearn.linear_model.Lasso</span>
<span class="sd">    SparseCoder</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">n_components</span> <span class="o">=</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Dictionary and X have different numbers of features:&quot;</span>
                         <span class="s2">&quot;dictionary.shape: </span><span class="si">{}</span><span class="s2"> X.shape</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                             <span class="n">dictionary</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">cov</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">algorithm</span> <span class="o">!=</span> <span class="s1">&#39;lasso_cd&#39;</span><span class="p">:</span>
        <span class="c1"># overwriting cov is safe</span>
        <span class="n">copy_cov</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;lasso_lars&#39;</span><span class="p">:</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">regularization</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_features</span>  <span class="c1"># account for scaling</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">err_mgt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="nb">all</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

            <span class="c1"># Not passing in verbose=max(0, verbose-1) because Lars.fit already</span>
            <span class="c1"># corrects the verbosity level.</span>
            <span class="n">lasso_lars</span> <span class="o">=</span> <span class="n">LassoLars</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                   <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                   <span class="n">precompute</span><span class="o">=</span><span class="n">gram</span><span class="p">,</span> <span class="n">fit_path</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">lasso_lars</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dictionary</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Xy</span><span class="o">=</span><span class="n">cov</span><span class="p">)</span>
            <span class="n">new_code</span> <span class="o">=</span> <span class="n">lasso_lars</span><span class="o">.</span><span class="n">coef_</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="o">**</span><span class="n">err_mgt</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;lasso_cd&#39;</span><span class="p">:</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">regularization</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_features</span>  <span class="c1"># account for scaling</span>

        <span class="c1"># TODO: Make verbosity argument for Lasso?</span>
        <span class="c1"># sklearn.linear_model.coordinate_descent.enet_path has a verbosity</span>
        <span class="c1"># argument that we could pass in from Lasso.</span>
        <span class="n">clf</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">precompute</span><span class="o">=</span><span class="n">gram</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">init</span>

        <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dictionary</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">check_input</span><span class="o">=</span><span class="n">check_input</span><span class="p">)</span>
        <span class="n">new_code</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">coef_</span>

    <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;lars&#39;</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">err_mgt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="nb">all</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

            <span class="c1"># Not passing in verbose=max(0, verbose-1) because Lars.fit already</span>
            <span class="c1"># corrects the verbosity level.</span>
            <span class="n">lars</span> <span class="o">=</span> <span class="n">Lars</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">precompute</span><span class="o">=</span><span class="n">gram</span><span class="p">,</span> <span class="n">n_nonzero_coefs</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">regularization</span><span class="p">),</span>
                        <span class="n">fit_path</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">lars</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dictionary</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Xy</span><span class="o">=</span><span class="n">cov</span><span class="p">)</span>
            <span class="n">new_code</span> <span class="o">=</span> <span class="n">lars</span><span class="o">.</span><span class="n">coef_</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="o">**</span><span class="n">err_mgt</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;threshold&#39;</span><span class="p">:</span>
        <span class="n">new_code</span> <span class="o">=</span> <span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span> <span class="o">*</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span> <span class="o">-</span> <span class="n">regularization</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;omp&#39;</span><span class="p">:</span>
        <span class="c1"># TODO: Should verbose argument be passed to this?</span>
        <span class="n">new_code</span> <span class="o">=</span> <span class="n">orthogonal_mp_gram</span><span class="p">(</span>
            <span class="n">Gram</span><span class="o">=</span><span class="n">gram</span><span class="p">,</span> <span class="n">Xy</span><span class="o">=</span><span class="n">cov</span><span class="p">,</span> <span class="n">n_nonzero_coefs</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">regularization</span><span class="p">),</span>
            <span class="n">tol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norms_squared</span><span class="o">=</span><span class="n">row_norms</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">copy_Xy</span><span class="o">=</span><span class="n">copy_cov</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Sparse coding method must be &quot;lasso_lars&quot; &#39;</span>
                         <span class="s1">&#39;&quot;lasso_cd&quot;,  &quot;lasso&quot;, &quot;threshold&quot; or &quot;omp&quot;, got </span><span class="si">%s</span><span class="s1">.&#39;</span>
                         <span class="o">%</span> <span class="n">algorithm</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">new_code</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">new_code</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_components</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_code</span>


<span class="c1"># XXX : could be moved to the linear_model module</span>
<span class="k">def</span> <span class="nf">sparse_encode</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">gram</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;lasso_lars&#39;</span><span class="p">,</span>
                  <span class="n">n_nonzero_coefs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copy_cov</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">check_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sparse coding</span>

<span class="sd">    Each row of the result is the solution to a sparse coding problem.</span>
<span class="sd">    The goal is to find a sparse array `code` such that::</span>

<span class="sd">        X ~= code * dictionary</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;SparseCoder&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array of shape (n_samples, n_features)</span>
<span class="sd">        Data matrix</span>

<span class="sd">    dictionary : array of shape (n_components, n_features)</span>
<span class="sd">        The dictionary matrix against which to solve the sparse coding of</span>
<span class="sd">        the data. Some of the algorithms assume normalized rows for meaningful</span>
<span class="sd">        output.</span>

<span class="sd">    gram : array, shape=(n_components, n_components)</span>
<span class="sd">        Precomputed Gram matrix, dictionary * dictionary&#39;</span>

<span class="sd">    cov : array, shape=(n_components, n_samples)</span>
<span class="sd">        Precomputed covariance, dictionary&#39; * X</span>

<span class="sd">    algorithm : {&#39;lasso_lars&#39;, &#39;lasso_cd&#39;, &#39;lars&#39;, &#39;omp&#39;, &#39;threshold&#39;}</span>
<span class="sd">        lars: uses the least angle regression method (linear_model.lars_path)</span>
<span class="sd">        lasso_lars: uses Lars to compute the Lasso solution</span>
<span class="sd">        lasso_cd: uses the coordinate descent method to compute the</span>
<span class="sd">        Lasso solution (linear_model.Lasso). lasso_lars will be faster if</span>
<span class="sd">        the estimated components are sparse.</span>
<span class="sd">        omp: uses orthogonal matching pursuit to estimate the sparse solution</span>
<span class="sd">        threshold: squashes to zero all coefficients less than alpha from</span>
<span class="sd">        the projection dictionary * X&#39;</span>

<span class="sd">    n_nonzero_coefs : int, 0.1 * n_features by default</span>
<span class="sd">        Number of nonzero coefficients to target in each column of the</span>
<span class="sd">        solution. This is only used by `algorithm=&#39;lars&#39;` and `algorithm=&#39;omp&#39;`</span>
<span class="sd">        and is overridden by `alpha` in the `omp` case.</span>

<span class="sd">    alpha : float, 1. by default</span>
<span class="sd">        If `algorithm=&#39;lasso_lars&#39;` or `algorithm=&#39;lasso_cd&#39;`, `alpha` is the</span>
<span class="sd">        penalty applied to the L1 norm.</span>
<span class="sd">        If `algorithm=&#39;threshold&#39;`, `alpha` is the absolute value of the</span>
<span class="sd">        threshold below which coefficients will be squashed to zero.</span>
<span class="sd">        If `algorithm=&#39;omp&#39;`, `alpha` is the tolerance parameter: the value of</span>
<span class="sd">        the reconstruction error targeted. In this case, it overrides</span>
<span class="sd">        `n_nonzero_coefs`.</span>

<span class="sd">    copy_cov : boolean, optional</span>
<span class="sd">        Whether to copy the precomputed covariance matrix; if False, it may be</span>
<span class="sd">        overwritten.</span>

<span class="sd">    init : array of shape (n_samples, n_components)</span>
<span class="sd">        Initialization value of the sparse codes. Only used if</span>
<span class="sd">        `algorithm=&#39;lasso_cd&#39;`.</span>

<span class="sd">    max_iter : int, 1000 by default</span>
<span class="sd">        Maximum number of iterations to perform if `algorithm=&#39;lasso_cd&#39;`.</span>

<span class="sd">    n_jobs : int, optional</span>
<span class="sd">        Number of parallel jobs to run.</span>

<span class="sd">    check_input : boolean, optional</span>
<span class="sd">        If False, the input arrays X and dictionary will not be checked.</span>

<span class="sd">    verbose : int, optional</span>
<span class="sd">        Controls the verbosity; the higher, the more messages. Defaults to 0.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    code : array of shape (n_samples, n_components)</span>
<span class="sd">        The sparse codes</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    sklearn.linear_model.lars_path</span>
<span class="sd">    sklearn.linear_model.orthogonal_mp</span>
<span class="sd">    sklearn.linear_model.Lasso</span>
<span class="sd">    SparseCoder</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">check_input</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;lasso_cd&#39;</span><span class="p">:</span>
            <span class="n">dictionary</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dictionary</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">dictionary</span><span class="p">)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">n_components</span> <span class="o">=</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">gram</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">algorithm</span> <span class="o">!=</span> <span class="s1">&#39;threshold&#39;</span><span class="p">:</span>
        <span class="n">gram</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cov</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">algorithm</span> <span class="o">!=</span> <span class="s1">&#39;lasso_cd&#39;</span><span class="p">:</span>
        <span class="n">copy_cov</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;lars&#39;</span><span class="p">,</span> <span class="s1">&#39;omp&#39;</span><span class="p">):</span>
        <span class="n">regularization</span> <span class="o">=</span> <span class="n">n_nonzero_coefs</span>
        <span class="k">if</span> <span class="n">regularization</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">regularization</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">n_features</span> <span class="o">/</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">n_components</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">regularization</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="k">if</span> <span class="n">regularization</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">regularization</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="k">if</span> <span class="n">n_jobs</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;threshold&#39;</span><span class="p">:</span>
        <span class="n">code</span> <span class="o">=</span> <span class="n">_sparse_encode</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                              <span class="n">dictionary</span><span class="p">,</span> <span class="n">gram</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">,</span>
                              <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span>
                              <span class="n">regularization</span><span class="o">=</span><span class="n">regularization</span><span class="p">,</span> <span class="n">copy_cov</span><span class="o">=</span><span class="n">copy_cov</span><span class="p">,</span>
                              <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span>
                              <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
                              <span class="n">check_input</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                              <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">code</span>

    <span class="c1"># Enter parallel code block</span>
    <span class="n">code</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_components</span><span class="p">))</span>
    <span class="n">slices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">gen_even_slices</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">_get_n_jobs</span><span class="p">(</span><span class="n">n_jobs</span><span class="p">)))</span>

    <span class="n">code_views</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)(</span>
        <span class="n">delayed</span><span class="p">(</span><span class="n">_sparse_encode</span><span class="p">)(</span>
            <span class="n">X</span><span class="p">[</span><span class="n">this_slice</span><span class="p">],</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">gram</span><span class="p">,</span>
            <span class="n">cov</span><span class="p">[:,</span> <span class="n">this_slice</span><span class="p">]</span> <span class="k">if</span> <span class="n">cov</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">algorithm</span><span class="p">,</span>
            <span class="n">regularization</span><span class="o">=</span><span class="n">regularization</span><span class="p">,</span> <span class="n">copy_cov</span><span class="o">=</span><span class="n">copy_cov</span><span class="p">,</span>
            <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">[</span><span class="n">this_slice</span><span class="p">]</span> <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">check_input</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">this_slice</span> <span class="ow">in</span> <span class="n">slices</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">this_slice</span><span class="p">,</span> <span class="n">this_view</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">slices</span><span class="p">,</span> <span class="n">code_views</span><span class="p">):</span>
        <span class="n">code</span><span class="p">[</span><span class="n">this_slice</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_view</span>
    <span class="k">return</span> <span class="n">code</span>


<span class="k">def</span> <span class="nf">_update_dict</span><span class="p">(</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">code</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_r2</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update the dense dictionary factor in place.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    dictionary : array of shape (n_features, n_components)</span>
<span class="sd">        Value of the dictionary at the previous iteration.</span>

<span class="sd">    Y : array of shape (n_features, n_samples)</span>
<span class="sd">        Data matrix.</span>

<span class="sd">    code : array of shape (n_components, n_samples)</span>
<span class="sd">        Sparse coding of the data against which to optimize the dictionary.</span>

<span class="sd">    verbose:</span>
<span class="sd">        Degree of output the procedure will print.</span>

<span class="sd">    return_r2 : bool</span>
<span class="sd">        Whether to compute and return the residual sum of squares corresponding</span>
<span class="sd">        to the computed solution.</span>

<span class="sd">    random_state : int, RandomState instance or None, optional (default=None)</span>
<span class="sd">        If int, random_state is the seed used by the random number generator;</span>
<span class="sd">        If RandomState instance, random_state is the random number generator;</span>
<span class="sd">        If None, the random number generator is the RandomState instance used</span>
<span class="sd">        by `np.random`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dictionary : array of shape (n_features, n_components)</span>
<span class="sd">        Updated dictionary.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_components</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">code</span><span class="p">)</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
    <span class="c1"># Residuals, computed &#39;in-place&#39; for efficiency</span>
    <span class="n">R</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">code</span><span class="p">)</span>
    <span class="n">R</span> <span class="o">+=</span> <span class="n">Y</span>
    <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asfortranarray</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
    <span class="n">ger</span><span class="p">,</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">get_blas_funcs</span><span class="p">((</span><span class="s1">&#39;ger&#39;</span><span class="p">,),</span> <span class="p">(</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">code</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_components</span><span class="p">):</span>
        <span class="c1"># R &lt;- 1.0 * U_k * V_k^T + R</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">ger</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">[:,</span> <span class="n">k</span><span class="p">],</span> <span class="n">code</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:],</span> <span class="n">a</span><span class="o">=</span><span class="n">R</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">dictionary</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">code</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="c1"># Scale k&#39;th atom</span>
        <span class="n">atom_norm_square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dictionary</span><span class="p">[:,</span> <span class="n">k</span><span class="p">],</span> <span class="n">dictionary</span><span class="p">[:,</span> <span class="n">k</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">atom_norm_square</span> <span class="o">&lt;</span> <span class="mf">1e-20</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">)</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Adding new random atom&quot;</span><span class="p">)</span>
            <span class="n">dictionary</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
            <span class="c1"># Setting corresponding coefs to 0</span>
            <span class="n">code</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">dictionary</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">/=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dictionary</span><span class="p">[:,</span> <span class="n">k</span><span class="p">],</span>
                                            <span class="n">dictionary</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dictionary</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">/=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">atom_norm_square</span><span class="p">)</span>
            <span class="c1"># R &lt;- -1.0 * U_k * V_k^T + R</span>
            <span class="n">R</span> <span class="o">=</span> <span class="n">ger</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">[:,</span> <span class="n">k</span><span class="p">],</span> <span class="n">code</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:],</span> <span class="n">a</span><span class="o">=</span><span class="n">R</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">return_r2</span><span class="p">:</span>
        <span class="n">R</span> <span class="o">**=</span> <span class="mi">2</span>
        <span class="c1"># R is fortran-ordered. For numpy version &lt; 1.6, sum does not</span>
        <span class="c1"># follow the quick striding first, and is thus inefficient on</span>
        <span class="c1"># fortran ordered data. We take a flat view of the data with no</span>
        <span class="c1"># striding</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">as_strided</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">R</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="n">R</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">itemsize</span><span class="p">,))</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">R</span>
    <span class="k">return</span> <span class="n">dictionary</span>


<span class="k">def</span> <span class="nf">dict_learning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_components</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                  <span class="n">method</span><span class="o">=</span><span class="s1">&#39;lars&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dict_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">code_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">return_n_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Solves a dictionary learning matrix factorization problem.</span>

<span class="sd">    Finds the best dictionary and the corresponding sparse code for</span>
<span class="sd">    approximating the data matrix X by solving::</span>

<span class="sd">        (U^*, V^*) = argmin 0.5 || X - U V ||_2^2 + alpha * || U ||_1</span>
<span class="sd">                     (U,V)</span>
<span class="sd">                    with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components</span>

<span class="sd">    where V is the dictionary and U is the sparse code.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;DictionaryLearning&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array of shape (n_samples, n_features)</span>
<span class="sd">        Data matrix.</span>

<span class="sd">    n_components : int,</span>
<span class="sd">        Number of dictionary atoms to extract.</span>

<span class="sd">    alpha : int,</span>
<span class="sd">        Sparsity controlling parameter.</span>

<span class="sd">    max_iter : int,</span>
<span class="sd">        Maximum number of iterations to perform.</span>

<span class="sd">    tol : float,</span>
<span class="sd">        Tolerance for the stopping condition.</span>

<span class="sd">    method : {&#39;lars&#39;, &#39;cd&#39;}</span>
<span class="sd">        lars: uses the least angle regression method to solve the lasso problem</span>
<span class="sd">        (linear_model.lars_path)</span>
<span class="sd">        cd: uses the coordinate descent method to compute the</span>
<span class="sd">        Lasso solution (linear_model.Lasso). Lars will be faster if</span>
<span class="sd">        the estimated components are sparse.</span>

<span class="sd">    n_jobs : int,</span>
<span class="sd">        Number of parallel jobs to run, or -1 to autodetect.</span>

<span class="sd">    dict_init : array of shape (n_components, n_features),</span>
<span class="sd">        Initial value for the dictionary for warm restart scenarios.</span>

<span class="sd">    code_init : array of shape (n_samples, n_components),</span>
<span class="sd">        Initial value for the sparse code for warm restart scenarios.</span>

<span class="sd">    callback : callable or None, optional (default: None)</span>
<span class="sd">        Callable that gets invoked every five iterations</span>

<span class="sd">    verbose : bool, optional (default: False)</span>
<span class="sd">        To control the verbosity of the procedure.</span>

<span class="sd">    random_state : int, RandomState instance or None, optional (default=None)</span>
<span class="sd">        If int, random_state is the seed used by the random number generator;</span>
<span class="sd">        If RandomState instance, random_state is the random number generator;</span>
<span class="sd">        If None, the random number generator is the RandomState instance used</span>
<span class="sd">        by `np.random`.</span>

<span class="sd">    return_n_iter : bool</span>
<span class="sd">        Whether or not to return the number of iterations.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    code : array of shape (n_samples, n_components)</span>
<span class="sd">        The sparse code factor in the matrix factorization.</span>

<span class="sd">    dictionary : array of shape (n_components, n_features),</span>
<span class="sd">        The dictionary factor in the matrix factorization.</span>

<span class="sd">    errors : array</span>
<span class="sd">        Vector of errors at each iteration.</span>

<span class="sd">    n_iter : int</span>
<span class="sd">        Number of iterations run. Returned only if `return_n_iter` is</span>
<span class="sd">        set to True.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    dict_learning_online</span>
<span class="sd">    DictionaryLearning</span>
<span class="sd">    MiniBatchDictionaryLearning</span>
<span class="sd">    SparsePCA</span>
<span class="sd">    MiniBatchSparsePCA</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;lars&#39;</span><span class="p">,</span> <span class="s1">&#39;cd&#39;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Coding method </span><span class="si">%r</span><span class="s1"> not supported as a fit algorithm.&#39;</span>
                         <span class="o">%</span> <span class="n">method</span><span class="p">)</span>
    <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;lasso_&#39;</span> <span class="o">+</span> <span class="n">method</span>

    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="c1"># Avoid integer division problems</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n_jobs</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">cpu_count</span><span class="p">()</span>

    <span class="c1"># Init the code and the dictionary with SVD of Y</span>
    <span class="k">if</span> <span class="n">code_init</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">dict_init</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">code</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">code_init</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)</span>
        <span class="c1"># Don&#39;t copy V, it will happen below</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="n">dict_init</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">code</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">dictionary</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="n">S</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">dictionary</span>
    <span class="n">r</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dictionary</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_components</span> <span class="o">&lt;=</span> <span class="n">r</span><span class="p">:</span>  <span class="c1"># True even if n_components=None</span>
        <span class="n">code</span> <span class="o">=</span> <span class="n">code</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_components</span><span class="p">]</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="n">dictionary</span><span class="p">[:</span><span class="n">n_components</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">code</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">code</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">code</span><span class="p">),</span> <span class="n">n_components</span> <span class="o">-</span> <span class="n">r</span><span class="p">))]</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">dictionary</span><span class="p">,</span>
                           <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_components</span> <span class="o">-</span> <span class="n">r</span><span class="p">,</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))]</span>

    <span class="c1"># Fortran-order dict, as we are going to access its row vectors</span>
    <span class="n">dictionary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)</span>

    <span class="n">residuals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">current_cost</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="k">if</span> <span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[dict_learning]&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">)</span>

    <span class="c1"># If max_iter is 0, number of iterations returned should be zero</span>
    <span class="n">ii</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="n">dt</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration </span><span class="si">% 3i</span><span class="s2"> &quot;</span>
                  <span class="s2">&quot;(elapsed time: </span><span class="si">% 3i</span><span class="s2">s, </span><span class="si">% 4.1f</span><span class="s2">mn, current cost </span><span class="si">% 7.3f</span><span class="s2">)&quot;</span>
                  <span class="o">%</span> <span class="p">(</span><span class="n">ii</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">dt</span> <span class="o">/</span> <span class="mi">60</span><span class="p">,</span> <span class="n">current_cost</span><span class="p">))</span>

        <span class="c1"># Update code</span>
        <span class="n">code</span> <span class="o">=</span> <span class="n">sparse_encode</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
                             <span class="n">init</span><span class="o">=</span><span class="n">code</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)</span>
        <span class="c1"># Update dictionary</span>
        <span class="n">dictionary</span><span class="p">,</span> <span class="n">residuals</span> <span class="o">=</span> <span class="n">_update_dict</span><span class="p">(</span><span class="n">dictionary</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">code</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                                             <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">return_r2</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                             <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">T</span>

        <span class="c1"># Cost function</span>
        <span class="n">current_cost</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">residuals</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">code</span><span class="p">))</span>
        <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_cost</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ii</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dE</span> <span class="o">=</span> <span class="n">errors</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">errors</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="c1"># assert(dE &gt;= -tol * errors[-1])</span>
            <span class="k">if</span> <span class="n">dE</span> <span class="o">&lt;</span> <span class="n">tol</span> <span class="o">*</span> <span class="n">errors</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># A line return</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Convergence reached after </span><span class="si">%d</span><span class="s2"> iterations&quot;</span> <span class="o">%</span> <span class="n">ii</span><span class="p">)</span>
                <span class="k">break</span>
        <span class="k">if</span> <span class="n">ii</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">callback</span><span class="p">(</span><span class="nb">locals</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">return_n_iter</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">code</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">errors</span><span class="p">,</span> <span class="n">ii</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">code</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">errors</span>


<span class="k">def</span> <span class="nf">dict_learning_online</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                         <span class="n">return_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dict_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                         <span class="n">method</span><span class="o">=</span><span class="s1">&#39;lars&#39;</span><span class="p">,</span> <span class="n">iter_offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">return_inner_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_stats</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">return_n_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Solves a dictionary learning matrix factorization problem online.</span>

<span class="sd">    Finds the best dictionary and the corresponding sparse code for</span>
<span class="sd">    approximating the data matrix X by solving::</span>

<span class="sd">        (U^*, V^*) = argmin 0.5 || X - U V ||_2^2 + alpha * || U ||_1</span>
<span class="sd">                     (U,V)</span>
<span class="sd">                     with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components</span>

<span class="sd">    where V is the dictionary and U is the sparse code. This is</span>
<span class="sd">    accomplished by repeatedly iterating over mini-batches by slicing</span>
<span class="sd">    the input data.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;DictionaryLearning&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array of shape (n_samples, n_features)</span>
<span class="sd">        Data matrix.</span>

<span class="sd">    n_components : int,</span>
<span class="sd">        Number of dictionary atoms to extract.</span>

<span class="sd">    alpha : float,</span>
<span class="sd">        Sparsity controlling parameter.</span>

<span class="sd">    n_iter : int,</span>
<span class="sd">        Number of iterations to perform.</span>

<span class="sd">    return_code : boolean,</span>
<span class="sd">        Whether to also return the code U or just the dictionary V.</span>

<span class="sd">    dict_init : array of shape (n_components, n_features),</span>
<span class="sd">        Initial value for the dictionary for warm restart scenarios.</span>

<span class="sd">    callback : callable or None, optional (default: None)</span>
<span class="sd">        callable that gets invoked every five iterations</span>

<span class="sd">    batch_size : int,</span>
<span class="sd">        The number of samples to take in each batch.</span>

<span class="sd">    verbose : bool, optional (default: False)</span>
<span class="sd">        To control the verbosity of the procedure.</span>

<span class="sd">    shuffle : boolean,</span>
<span class="sd">        Whether to shuffle the data before splitting it in batches.</span>

<span class="sd">    n_jobs : int,</span>
<span class="sd">        Number of parallel jobs to run, or -1 to autodetect.</span>

<span class="sd">    method : {&#39;lars&#39;, &#39;cd&#39;}</span>
<span class="sd">        lars: uses the least angle regression method to solve the lasso problem</span>
<span class="sd">        (linear_model.lars_path)</span>
<span class="sd">        cd: uses the coordinate descent method to compute the</span>
<span class="sd">        Lasso solution (linear_model.Lasso). Lars will be faster if</span>
<span class="sd">        the estimated components are sparse.</span>

<span class="sd">    iter_offset : int, default 0</span>
<span class="sd">        Number of previous iterations completed on the dictionary used for</span>
<span class="sd">        initialization.</span>

<span class="sd">    random_state : int, RandomState instance or None, optional (default=None)</span>
<span class="sd">        If int, random_state is the seed used by the random number generator;</span>
<span class="sd">        If RandomState instance, random_state is the random number generator;</span>
<span class="sd">        If None, the random number generator is the RandomState instance used</span>
<span class="sd">        by `np.random`.</span>

<span class="sd">    return_inner_stats : boolean, optional</span>
<span class="sd">        Return the inner statistics A (dictionary covariance) and B</span>
<span class="sd">        (data approximation). Useful to restart the algorithm in an</span>
<span class="sd">        online setting. If return_inner_stats is True, return_code is</span>
<span class="sd">        ignored</span>

<span class="sd">    inner_stats : tuple of (A, B) ndarrays</span>
<span class="sd">        Inner sufficient statistics that are kept by the algorithm.</span>
<span class="sd">        Passing them at initialization is useful in online settings, to</span>
<span class="sd">        avoid loosing the history of the evolution.</span>
<span class="sd">        A (n_components, n_components) is the dictionary covariance matrix.</span>
<span class="sd">        B (n_features, n_components) is the data approximation matrix</span>

<span class="sd">    return_n_iter : bool</span>
<span class="sd">        Whether or not to return the number of iterations.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    code : array of shape (n_samples, n_components),</span>
<span class="sd">        the sparse code (only returned if `return_code=True`)</span>

<span class="sd">    dictionary : array of shape (n_components, n_features),</span>
<span class="sd">        the solutions to the dictionary learning problem</span>

<span class="sd">    n_iter : int</span>
<span class="sd">        Number of iterations run. Returned only if `return_n_iter` is</span>
<span class="sd">        set to `True`.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    dict_learning</span>
<span class="sd">    DictionaryLearning</span>
<span class="sd">    MiniBatchDictionaryLearning</span>
<span class="sd">    SparsePCA</span>
<span class="sd">    MiniBatchSparsePCA</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">n_components</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;lars&#39;</span><span class="p">,</span> <span class="s1">&#39;cd&#39;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Coding method not supported as a fit algorithm.&#39;</span><span class="p">)</span>
    <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;lasso_&#39;</span> <span class="o">+</span> <span class="n">method</span>

    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="c1"># Avoid integer division problems</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n_jobs</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">cpu_count</span><span class="p">()</span>

    <span class="c1"># Init V with SVD of X</span>
    <span class="k">if</span> <span class="n">dict_init</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="n">dict_init</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">dictionary</span> <span class="o">=</span> <span class="n">randomized_svd</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_components</span><span class="p">,</span>
                                          <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="n">S</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">dictionary</span>
    <span class="n">r</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dictionary</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_components</span> <span class="o">&lt;=</span> <span class="n">r</span><span class="p">:</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="n">dictionary</span><span class="p">[:</span><span class="n">n_components</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">dictionary</span><span class="p">,</span>
                           <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_components</span> <span class="o">-</span> <span class="n">r</span><span class="p">,</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))]</span>

    <span class="k">if</span> <span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[dict_learning]&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">random_state</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span>

    <span class="n">dictionary</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">dictionary</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
                             <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">batches</span> <span class="o">=</span> <span class="n">gen_batches</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">batches</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">cycle</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>

    <span class="c1"># The covariance of the dictionary</span>
    <span class="k">if</span> <span class="n">inner_stats</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_components</span><span class="p">,</span> <span class="n">n_components</span><span class="p">))</span>
        <span class="c1"># The data approximation</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_components</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">inner_stats</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">inner_stats</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="c1"># If n_iter is zero, we need to return zero.</span>
    <span class="n">ii</span> <span class="o">=</span> <span class="n">iter_offset</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">iter_offset</span><span class="p">,</span> <span class="n">iter_offset</span> <span class="o">+</span> <span class="n">n_iter</span><span class="p">),</span> <span class="n">batches</span><span class="p">):</span>
        <span class="n">this_X</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">batch</span><span class="p">]</span>
        <span class="n">dt</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">10</span> <span class="ow">or</span> <span class="n">ii</span> <span class="o">%</span> <span class="n">ceil</span><span class="p">(</span><span class="mf">100.</span> <span class="o">/</span> <span class="n">verbose</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration </span><span class="si">% 3i</span><span class="s2"> (elapsed time: </span><span class="si">% 3i</span><span class="s2">s, </span><span class="si">% 4.1f</span><span class="s2">mn)&quot;</span>
                      <span class="o">%</span> <span class="p">(</span><span class="n">ii</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">dt</span> <span class="o">/</span> <span class="mi">60</span><span class="p">))</span>

        <span class="n">this_code</span> <span class="o">=</span> <span class="n">sparse_encode</span><span class="p">(</span><span class="n">this_X</span><span class="p">,</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
                                  <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

        <span class="c1"># Update the auxiliary variables</span>
        <span class="k">if</span> <span class="n">ii</span> <span class="o">&lt;</span> <span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="nb">float</span><span class="p">((</span><span class="n">ii</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">ii</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="p">(</span><span class="n">theta</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">batch_size</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">theta</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">A</span> <span class="o">*=</span> <span class="n">beta</span>
        <span class="n">A</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">this_code</span><span class="p">,</span> <span class="n">this_code</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">B</span> <span class="o">*=</span> <span class="n">beta</span>
        <span class="n">B</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">this_X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">this_code</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="c1"># Update dictionary</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="n">_update_dict</span><span class="p">(</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                                  <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
        <span class="c1"># XXX: Can the residuals be of any use?</span>

        <span class="c1"># Maybe we need a stopping criteria based on the amount of</span>
        <span class="c1"># modification in the dictionary</span>
        <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">callback</span><span class="p">(</span><span class="nb">locals</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">return_inner_stats</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">return_n_iter</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">),</span> <span class="n">ii</span> <span class="o">-</span> <span class="n">iter_offset</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">return_code</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Learning code...&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
        <span class="n">code</span> <span class="o">=</span> <span class="n">sparse_encode</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
                             <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">check_input</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">dt</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;done (total time: </span><span class="si">% 3i</span><span class="s1">s, </span><span class="si">% 4.1f</span><span class="s1">mn)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">dt</span> <span class="o">/</span> <span class="mi">60</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">return_n_iter</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">code</span><span class="p">,</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">ii</span> <span class="o">-</span> <span class="n">iter_offset</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">code</span><span class="p">,</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">T</span>

    <span class="k">if</span> <span class="n">return_n_iter</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">ii</span> <span class="o">-</span> <span class="n">iter_offset</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">T</span>


<span class="k">class</span> <span class="nc">SparseCodingMixin</span><span class="p">(</span><span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sparse coding mixin&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_set_sparse_coding_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_components</span><span class="p">,</span>
                                  <span class="n">transform_algorithm</span><span class="o">=</span><span class="s1">&#39;omp&#39;</span><span class="p">,</span>
                                  <span class="n">transform_n_nonzero_coefs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                  <span class="n">transform_alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">split_sign</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                  <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform_algorithm</span> <span class="o">=</span> <span class="n">transform_algorithm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform_n_nonzero_coefs</span> <span class="o">=</span> <span class="n">transform_n_nonzero_coefs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform_alpha</span> <span class="o">=</span> <span class="n">transform_alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split_sign</span> <span class="o">=</span> <span class="n">split_sign</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Encode the data as a sparse combination of the dictionary atoms.</span>

<span class="sd">        Coding method is determined by the object parameter</span>
<span class="sd">        `transform_algorithm`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array of shape (n_samples, n_features)</span>
<span class="sd">            Test data to be transformed, must have the same number of</span>
<span class="sd">            features as the data used to train the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X_new : array, shape (n_samples, n_components)</span>
<span class="sd">            Transformed data</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;components_&#39;</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">code</span> <span class="o">=</span> <span class="n">sparse_encode</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform_algorithm</span><span class="p">,</span>
            <span class="n">n_nonzero_coefs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform_n_nonzero_coefs</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform_alpha</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_sign</span><span class="p">:</span>
            <span class="c1"># feature vector is split into a positive and negative side</span>
            <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">code</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">split_code</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">n_features</span><span class="p">))</span>
            <span class="n">split_code</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">code</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">split_code</span><span class="p">[:,</span> <span class="n">n_features</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">code</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">code</span> <span class="o">=</span> <span class="n">split_code</span>

        <span class="k">return</span> <span class="n">code</span>


<span class="k">class</span> <span class="nc">SparseCoder</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">SparseCodingMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sparse coding</span>

<span class="sd">    Finds a sparse representation of data against a fixed, precomputed</span>
<span class="sd">    dictionary.</span>

<span class="sd">    Each row of the result is the solution to a sparse coding problem.</span>
<span class="sd">    The goal is to find a sparse array `code` such that::</span>

<span class="sd">        X ~= code * dictionary</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;SparseCoder&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    dictionary : array, [n_components, n_features]</span>
<span class="sd">        The dictionary atoms used for sparse coding. Lines are assumed to be</span>
<span class="sd">        normalized to unit norm.</span>

<span class="sd">    transform_algorithm : {&#39;lasso_lars&#39;, &#39;lasso_cd&#39;, &#39;lars&#39;, &#39;omp&#39;, \</span>
<span class="sd">    &#39;threshold&#39;}</span>
<span class="sd">        Algorithm used to transform the data:</span>
<span class="sd">        lars: uses the least angle regression method (linear_model.lars_path)</span>
<span class="sd">        lasso_lars: uses Lars to compute the Lasso solution</span>
<span class="sd">        lasso_cd: uses the coordinate descent method to compute the</span>
<span class="sd">        Lasso solution (linear_model.Lasso). lasso_lars will be faster if</span>
<span class="sd">        the estimated components are sparse.</span>
<span class="sd">        omp: uses orthogonal matching pursuit to estimate the sparse solution</span>
<span class="sd">        threshold: squashes to zero all coefficients less than alpha from</span>
<span class="sd">        the projection ``dictionary * X&#39;``</span>

<span class="sd">    transform_n_nonzero_coefs : int, ``0.1 * n_features`` by default</span>
<span class="sd">        Number of nonzero coefficients to target in each column of the</span>
<span class="sd">        solution. This is only used by `algorithm=&#39;lars&#39;` and `algorithm=&#39;omp&#39;`</span>
<span class="sd">        and is overridden by `alpha` in the `omp` case.</span>

<span class="sd">    transform_alpha : float, 1. by default</span>
<span class="sd">        If `algorithm=&#39;lasso_lars&#39;` or `algorithm=&#39;lasso_cd&#39;`, `alpha` is the</span>
<span class="sd">        penalty applied to the L1 norm.</span>
<span class="sd">        If `algorithm=&#39;threshold&#39;`, `alpha` is the absolute value of the</span>
<span class="sd">        threshold below which coefficients will be squashed to zero.</span>
<span class="sd">        If `algorithm=&#39;omp&#39;`, `alpha` is the tolerance parameter: the value of</span>
<span class="sd">        the reconstruction error targeted. In this case, it overrides</span>
<span class="sd">        `n_nonzero_coefs`.</span>

<span class="sd">    split_sign : bool, False by default</span>
<span class="sd">        Whether to split the sparse feature vector into the concatenation of</span>
<span class="sd">        its negative part and its positive part. This can improve the</span>
<span class="sd">        performance of downstream classifiers.</span>

<span class="sd">    n_jobs : int,</span>
<span class="sd">        number of parallel jobs to run</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    components_ : array, [n_components, n_features]</span>
<span class="sd">        The unchanged dictionary atoms</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    DictionaryLearning</span>
<span class="sd">    MiniBatchDictionaryLearning</span>
<span class="sd">    SparsePCA</span>
<span class="sd">    MiniBatchSparsePCA</span>
<span class="sd">    sparse_encode</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_required_parameters</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;dictionary&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">transform_algorithm</span><span class="o">=</span><span class="s1">&#39;omp&#39;</span><span class="p">,</span>
                 <span class="n">transform_n_nonzero_coefs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform_alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">split_sign</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_sparse_coding_params</span><span class="p">(</span><span class="n">dictionary</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                       <span class="n">transform_algorithm</span><span class="p">,</span>
                                       <span class="n">transform_n_nonzero_coefs</span><span class="p">,</span>
                                       <span class="n">transform_alpha</span><span class="p">,</span> <span class="n">split_sign</span><span class="p">,</span> <span class="n">n_jobs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="n">dictionary</span>

<div class="viewcode-block" id="SparseCoder.fit"><a class="viewcode-back" href="../../../api_ibex_sklearn_decomposition_sparsecoder.html#ibex.sklearn.decomposition.SparseCoder.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Do nothing and return the estimator unchanged</span>

<span class="sd">        This method is just there to implement the usual API and hence</span>
<span class="sd">        work in pipelines.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            Training vector, where n_samples in the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns the object itself</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<span class="k">class</span> <span class="nc">DictionaryLearning</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">SparseCodingMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Dictionary learning</span>

<span class="sd">    Finds a dictionary (a set of atoms) that can best be used to represent data</span>
<span class="sd">    using a sparse code.</span>

<span class="sd">    Solves the optimization problem::</span>

<span class="sd">        (U^*,V^*) = argmin 0.5 || Y - U V ||_2^2 + alpha * || U ||_1</span>
<span class="sd">                    (U,V)</span>
<span class="sd">                    with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;DictionaryLearning&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_components : int,</span>
<span class="sd">        number of dictionary elements to extract</span>

<span class="sd">    alpha : float,</span>
<span class="sd">        sparsity controlling parameter</span>

<span class="sd">    max_iter : int,</span>
<span class="sd">        maximum number of iterations to perform</span>

<span class="sd">    tol : float,</span>
<span class="sd">        tolerance for numerical error</span>

<span class="sd">    fit_algorithm : {&#39;lars&#39;, &#39;cd&#39;}</span>
<span class="sd">        lars: uses the least angle regression method to solve the lasso problem</span>
<span class="sd">        (linear_model.lars_path)</span>
<span class="sd">        cd: uses the coordinate descent method to compute the</span>
<span class="sd">        Lasso solution (linear_model.Lasso). Lars will be faster if</span>
<span class="sd">        the estimated components are sparse.</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           *cd* coordinate descent method to improve speed.</span>

<span class="sd">    transform_algorithm : {&#39;lasso_lars&#39;, &#39;lasso_cd&#39;, &#39;lars&#39;, &#39;omp&#39;, \</span>
<span class="sd">    &#39;threshold&#39;}</span>
<span class="sd">        Algorithm used to transform the data</span>
<span class="sd">        lars: uses the least angle regression method (linear_model.lars_path)</span>
<span class="sd">        lasso_lars: uses Lars to compute the Lasso solution</span>
<span class="sd">        lasso_cd: uses the coordinate descent method to compute the</span>
<span class="sd">        Lasso solution (linear_model.Lasso). lasso_lars will be faster if</span>
<span class="sd">        the estimated components are sparse.</span>
<span class="sd">        omp: uses orthogonal matching pursuit to estimate the sparse solution</span>
<span class="sd">        threshold: squashes to zero all coefficients less than alpha from</span>
<span class="sd">        the projection ``dictionary * X&#39;``</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           *lasso_cd* coordinate descent method to improve speed.</span>

<span class="sd">    transform_n_nonzero_coefs : int, ``0.1 * n_features`` by default</span>
<span class="sd">        Number of nonzero coefficients to target in each column of the</span>
<span class="sd">        solution. This is only used by `algorithm=&#39;lars&#39;` and `algorithm=&#39;omp&#39;`</span>
<span class="sd">        and is overridden by `alpha` in the `omp` case.</span>

<span class="sd">    transform_alpha : float, 1. by default</span>
<span class="sd">        If `algorithm=&#39;lasso_lars&#39;` or `algorithm=&#39;lasso_cd&#39;`, `alpha` is the</span>
<span class="sd">        penalty applied to the L1 norm.</span>
<span class="sd">        If `algorithm=&#39;threshold&#39;`, `alpha` is the absolute value of the</span>
<span class="sd">        threshold below which coefficients will be squashed to zero.</span>
<span class="sd">        If `algorithm=&#39;omp&#39;`, `alpha` is the tolerance parameter: the value of</span>
<span class="sd">        the reconstruction error targeted. In this case, it overrides</span>
<span class="sd">        `n_nonzero_coefs`.</span>

<span class="sd">    n_jobs : int,</span>
<span class="sd">        number of parallel jobs to run</span>

<span class="sd">    code_init : array of shape (n_samples, n_components),</span>
<span class="sd">        initial value for the code, for warm restart</span>

<span class="sd">    dict_init : array of shape (n_components, n_features),</span>
<span class="sd">        initial values for the dictionary, for warm restart</span>

<span class="sd">    verbose : bool, optional (default: False)</span>
<span class="sd">        To control the verbosity of the procedure.</span>

<span class="sd">    split_sign : bool, False by default</span>
<span class="sd">        Whether to split the sparse feature vector into the concatenation of</span>
<span class="sd">        its negative part and its positive part. This can improve the</span>
<span class="sd">        performance of downstream classifiers.</span>

<span class="sd">    random_state : int, RandomState instance or None, optional (default=None)</span>
<span class="sd">        If int, random_state is the seed used by the random number generator;</span>
<span class="sd">        If RandomState instance, random_state is the random number generator;</span>
<span class="sd">        If None, the random number generator is the RandomState instance used</span>
<span class="sd">        by `np.random`.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    components_ : array, [n_components, n_features]</span>
<span class="sd">        dictionary atoms extracted from the data</span>

<span class="sd">    error_ : array</span>
<span class="sd">        vector of errors at each iteration</span>

<span class="sd">    n_iter_ : int</span>
<span class="sd">        Number of iterations run.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    **References:**</span>

<span class="sd">    J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning</span>
<span class="sd">    for sparse coding (http://www.di.ens.fr/sierra/pdfs/icml09.pdf)</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    SparseCoder</span>
<span class="sd">    MiniBatchDictionaryLearning</span>
<span class="sd">    SparsePCA</span>
<span class="sd">    MiniBatchSparsePCA</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                 <span class="n">fit_algorithm</span><span class="o">=</span><span class="s1">&#39;lars&#39;</span><span class="p">,</span> <span class="n">transform_algorithm</span><span class="o">=</span><span class="s1">&#39;omp&#39;</span><span class="p">,</span>
                 <span class="n">transform_n_nonzero_coefs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform_alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">code_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dict_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">split_sign</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_sparse_coding_params</span><span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">transform_algorithm</span><span class="p">,</span>
                                       <span class="n">transform_n_nonzero_coefs</span><span class="p">,</span>
                                       <span class="n">transform_alpha</span><span class="p">,</span> <span class="n">split_sign</span><span class="p">,</span> <span class="n">n_jobs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_algorithm</span> <span class="o">=</span> <span class="n">fit_algorithm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">code_init</span> <span class="o">=</span> <span class="n">code_init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dict_init</span> <span class="o">=</span> <span class="n">dict_init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

<div class="viewcode-block" id="DictionaryLearning.fit"><a class="viewcode-back" href="../../../api_ibex_sklearn_decomposition_dictionarylearning.html#ibex.sklearn.decomposition.DictionaryLearning.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit the model from data in X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            Training vector, where n_samples in the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns the object itself</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_components</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_components</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span>

        <span class="n">V</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="n">dict_learning</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">n_components</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
            <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_algorithm</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">code_init</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">code_init</span><span class="p">,</span>
            <span class="n">dict_init</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dict_init</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">return_n_iter</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="n">U</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">error_</span> <span class="o">=</span> <span class="n">E</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<span class="k">class</span> <span class="nc">MiniBatchDictionaryLearning</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">SparseCodingMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Mini-batch dictionary learning</span>

<span class="sd">    Finds a dictionary (a set of atoms) that can best be used to represent data</span>
<span class="sd">    using a sparse code.</span>

<span class="sd">    Solves the optimization problem::</span>

<span class="sd">       (U^*,V^*) = argmin 0.5 || Y - U V ||_2^2 + alpha * || U ||_1</span>
<span class="sd">                    (U,V)</span>
<span class="sd">                    with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;DictionaryLearning&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_components : int,</span>
<span class="sd">        number of dictionary elements to extract</span>

<span class="sd">    alpha : float,</span>
<span class="sd">        sparsity controlling parameter</span>

<span class="sd">    n_iter : int,</span>
<span class="sd">        total number of iterations to perform</span>

<span class="sd">    fit_algorithm : {&#39;lars&#39;, &#39;cd&#39;}</span>
<span class="sd">        lars: uses the least angle regression method to solve the lasso problem</span>
<span class="sd">        (linear_model.lars_path)</span>
<span class="sd">        cd: uses the coordinate descent method to compute the</span>
<span class="sd">        Lasso solution (linear_model.Lasso). Lars will be faster if</span>
<span class="sd">        the estimated components are sparse.</span>

<span class="sd">    n_jobs : int,</span>
<span class="sd">        number of parallel jobs to run</span>

<span class="sd">    batch_size : int,</span>
<span class="sd">        number of samples in each mini-batch</span>

<span class="sd">    shuffle : bool,</span>
<span class="sd">        whether to shuffle the samples before forming batches</span>

<span class="sd">    dict_init : array of shape (n_components, n_features),</span>
<span class="sd">        initial value of the dictionary for warm restart scenarios</span>

<span class="sd">    transform_algorithm : {&#39;lasso_lars&#39;, &#39;lasso_cd&#39;, &#39;lars&#39;, &#39;omp&#39;, \</span>
<span class="sd">    &#39;threshold&#39;}</span>
<span class="sd">        Algorithm used to transform the data.</span>
<span class="sd">        lars: uses the least angle regression method (linear_model.lars_path)</span>
<span class="sd">        lasso_lars: uses Lars to compute the Lasso solution</span>
<span class="sd">        lasso_cd: uses the coordinate descent method to compute the</span>
<span class="sd">        Lasso solution (linear_model.Lasso). lasso_lars will be faster if</span>
<span class="sd">        the estimated components are sparse.</span>
<span class="sd">        omp: uses orthogonal matching pursuit to estimate the sparse solution</span>
<span class="sd">        threshold: squashes to zero all coefficients less than alpha from</span>
<span class="sd">        the projection dictionary * X&#39;</span>

<span class="sd">    transform_n_nonzero_coefs : int, ``0.1 * n_features`` by default</span>
<span class="sd">        Number of nonzero coefficients to target in each column of the</span>
<span class="sd">        solution. This is only used by `algorithm=&#39;lars&#39;` and `algorithm=&#39;omp&#39;`</span>
<span class="sd">        and is overridden by `alpha` in the `omp` case.</span>

<span class="sd">    transform_alpha : float, 1. by default</span>
<span class="sd">        If `algorithm=&#39;lasso_lars&#39;` or `algorithm=&#39;lasso_cd&#39;`, `alpha` is the</span>
<span class="sd">        penalty applied to the L1 norm.</span>
<span class="sd">        If `algorithm=&#39;threshold&#39;`, `alpha` is the absolute value of the</span>
<span class="sd">        threshold below which coefficients will be squashed to zero.</span>
<span class="sd">        If `algorithm=&#39;omp&#39;`, `alpha` is the tolerance parameter: the value of</span>
<span class="sd">        the reconstruction error targeted. In this case, it overrides</span>
<span class="sd">        `n_nonzero_coefs`.</span>

<span class="sd">    verbose : bool, optional (default: False)</span>
<span class="sd">        To control the verbosity of the procedure.</span>

<span class="sd">    split_sign : bool, False by default</span>
<span class="sd">        Whether to split the sparse feature vector into the concatenation of</span>
<span class="sd">        its negative part and its positive part. This can improve the</span>
<span class="sd">        performance of downstream classifiers.</span>

<span class="sd">    random_state : int, RandomState instance or None, optional (default=None)</span>
<span class="sd">        If int, random_state is the seed used by the random number generator;</span>
<span class="sd">        If RandomState instance, random_state is the random number generator;</span>
<span class="sd">        If None, the random number generator is the RandomState instance used</span>
<span class="sd">        by `np.random`.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    components_ : array, [n_components, n_features]</span>
<span class="sd">        components extracted from the data</span>

<span class="sd">    inner_stats_ : tuple of (A, B) ndarrays</span>
<span class="sd">        Internal sufficient statistics that are kept by the algorithm.</span>
<span class="sd">        Keeping them is useful in online settings, to avoid loosing the</span>
<span class="sd">        history of the evolution, but they shouldn&#39;t have any use for the</span>
<span class="sd">        end user.</span>
<span class="sd">        A (n_components, n_components) is the dictionary covariance matrix.</span>
<span class="sd">        B (n_features, n_components) is the data approximation matrix</span>

<span class="sd">    n_iter_ : int</span>
<span class="sd">        Number of iterations run.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    **References:**</span>

<span class="sd">    J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning</span>
<span class="sd">    for sparse coding (http://www.di.ens.fr/sierra/pdfs/icml09.pdf)</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    SparseCoder</span>
<span class="sd">    DictionaryLearning</span>
<span class="sd">    SparsePCA</span>
<span class="sd">    MiniBatchSparsePCA</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                 <span class="n">fit_algorithm</span><span class="o">=</span><span class="s1">&#39;lars&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                 <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dict_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform_algorithm</span><span class="o">=</span><span class="s1">&#39;omp&#39;</span><span class="p">,</span>
                 <span class="n">transform_n_nonzero_coefs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform_alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">split_sign</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_sparse_coding_params</span><span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">transform_algorithm</span><span class="p">,</span>
                                       <span class="n">transform_n_nonzero_coefs</span><span class="p">,</span>
                                       <span class="n">transform_alpha</span><span class="p">,</span> <span class="n">split_sign</span><span class="p">,</span> <span class="n">n_jobs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_algorithm</span> <span class="o">=</span> <span class="n">fit_algorithm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dict_init</span> <span class="o">=</span> <span class="n">dict_init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split_sign</span> <span class="o">=</span> <span class="n">split_sign</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

<div class="viewcode-block" id="MiniBatchDictionaryLearning.fit"><a class="viewcode-back" href="../../../api_ibex_sklearn_decomposition_minibatchdictionarylearning.html#ibex.sklearn.decomposition.MiniBatchDictionaryLearning.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit the model from data in X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            Training vector, where n_samples in the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns the instance itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">U</span><span class="p">,</span> <span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="n">dict_learning_online</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
            <span class="n">n_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">return_code</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_algorithm</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">dict_init</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dict_init</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">return_inner_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_n_iter</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="n">U</span>
        <span class="c1"># Keep track of the state of the algorithm to be able to do</span>
        <span class="c1"># some online fitting (partial_fit)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_stats_</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iter_offset_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="MiniBatchDictionaryLearning.partial_fit"><a class="viewcode-back" href="../../../api_ibex_sklearn_decomposition_minibatchdictionarylearning.html#ibex.sklearn.decomposition.MiniBatchDictionaryLearning.partial_fit">[docs]</a>    <span class="k">def</span> <span class="nf">partial_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">iter_offset</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Updates the model using the data in X as a mini-batch.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            Training vector, where n_samples in the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        iter_offset : integer, optional</span>
<span class="sd">            The number of iteration on data batches that has been</span>
<span class="sd">            performed before this call to partial_fit. This is optional:</span>
<span class="sd">            if no number is passed, the memory of the object is</span>
<span class="sd">            used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns the instance itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;random_state_&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">random_state_</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;components_&#39;</span><span class="p">):</span>
            <span class="n">dict_init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">components_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dict_init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dict_init</span>
        <span class="n">inner_stats</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;inner_stats_&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">iter_offset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">iter_offset</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;iter_offset_&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">U</span><span class="p">,</span> <span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span> <span class="o">=</span> <span class="n">dict_learning_online</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
            <span class="n">n_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_algorithm</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">dict_init</span><span class="o">=</span><span class="n">dict_init</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="n">return_code</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">iter_offset</span><span class="o">=</span><span class="n">iter_offset</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state_</span><span class="p">,</span>
            <span class="n">return_inner_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inner_stats</span><span class="o">=</span><span class="n">inner_stats</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="n">U</span>

        <span class="c1"># Keep track of the state of the algorithm to be able to do</span>
        <span class="c1"># some online fitting (partial_fit)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_stats_</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iter_offset_</span> <span class="o">=</span> <span class="n">iter_offset</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span>
        <span class="k">return</span> <span class="bp">self</span></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../index.html">
              <img class="logo" src="../../../_static/logo.jpeg" alt="Logo"/>
            </a></p>
  <h3><a href="../../../index.html">Table Of Contents</a></h3>
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Ibex</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../frame_adapter.html">Adapting Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../input_verification_and_output_processing.html">Verification and Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../function_transformer.html">Transforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pipelines.html">Pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../feature_union.html">Uniting Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sklearn.html"><code class="docutils literal"><span class="pre">sklearn</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensorflow.html"><code class="docutils literal"><span class="pre">tensorflow</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../xgboost.html"><code class="docutils literal"><span class="pre">xgboost</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../extending.html">Extending</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api.html">API</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Ami Tavory, Shahar Azulay, Tali Raveh-Sadka.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
    </div>

    
    <a href="https://github.com/atavory/ibex" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>