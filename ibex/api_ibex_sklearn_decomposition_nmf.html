
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>NMF &#8212; ibex latest documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     'latest',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/logo.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="nmf">
<h1><code class="docutils literal"><span class="pre">NMF</span></code><a class="headerlink" href="#nmf" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="ibex.sklearn.decomposition.NMF">
<em class="property">class </em><code class="descclassname">ibex.sklearn.decomposition.</code><code class="descname">NMF</code><span class="sig-paren">(</span><em>n_components=None</em>, <em>init=None</em>, <em>solver='cd'</em>, <em>beta_loss='frobenius'</em>, <em>tol=0.0001</em>, <em>max_iter=200</em>, <em>random_state=None</em>, <em>alpha=0.0</em>, <em>l1_ratio=0.0</em>, <em>verbose=0</em>, <em>shuffle=False</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.decomposition.NMF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.decomposition.nmf.NMF</span></code>, <code class="xref py py-class docutils literal"><span class="pre">ibex._base.FrameMixin</span></code></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Non-Negative Matrix Factorization (NMF)</p>
<blockquote>
<div><p>Find two non-negative matrices (W, H) whose product approximates the non-
negative matrix X. This factorization can be used for example for
dimensionality reduction, source separation or topic extraction.</p>
<p>The objective function is:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mf">0.5</span> <span class="o">*</span> <span class="o">||</span><span class="n">X</span> <span class="o">-</span> <span class="n">WH</span><span class="o">||</span><span class="n">_Fro</span><span class="o">^</span><span class="mi">2</span>
<span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">l1_ratio</span> <span class="o">*</span> <span class="o">||</span><span class="n">vec</span><span class="p">(</span><span class="n">W</span><span class="p">)</span><span class="o">||</span><span class="n">_1</span>
<span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">l1_ratio</span> <span class="o">*</span> <span class="o">||</span><span class="n">vec</span><span class="p">(</span><span class="n">H</span><span class="p">)</span><span class="o">||</span><span class="n">_1</span>
<span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">l1_ratio</span><span class="p">)</span> <span class="o">*</span> <span class="o">||</span><span class="n">W</span><span class="o">||</span><span class="n">_Fro</span><span class="o">^</span><span class="mi">2</span>
<span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">l1_ratio</span><span class="p">)</span> <span class="o">*</span> <span class="o">||</span><span class="n">H</span><span class="o">||</span><span class="n">_Fro</span><span class="o">^</span><span class="mi">2</span>
</pre></div>
</div>
<p>Where:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">||</span><span class="n">A</span><span class="o">||</span><span class="n">_Fro</span><span class="o">^</span><span class="mi">2</span> <span class="o">=</span> \<span class="n">sum_</span><span class="p">{</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">}</span> <span class="n">A_</span><span class="p">{</span><span class="n">ij</span><span class="p">}</span><span class="o">^</span><span class="mi">2</span> <span class="p">(</span><span class="n">Frobenius</span> <span class="n">norm</span><span class="p">)</span>
<span class="o">||</span><span class="n">vec</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">||</span><span class="n">_1</span> <span class="o">=</span> \<span class="n">sum_</span><span class="p">{</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">}</span> <span class="nb">abs</span><span class="p">(</span><span class="n">A_</span><span class="p">{</span><span class="n">ij</span><span class="p">})</span> <span class="p">(</span><span class="n">Elementwise</span> <span class="n">L1</span> <span class="n">norm</span><span class="p">)</span>
</pre></div>
</div>
<p>For multiplicative-update (‘mu’) solver, the Frobenius norm
(0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss,
by changing the beta_loss parameter.</p>
<p>The objective function is minimized with an alternating minimization of W
and H.</p>
<p>Read more in the <a class="reference external" href="http://scikit-learn.org/stable/modules/decomposition.html#nmf" title="(in scikit-learn v0.19.1)"><span class="xref std std-ref">User Guide</span></a>.</p>
<dl class="docutils">
<dt>n_components <span class="classifier-delimiter">:</span> <span class="classifier">int or None</span></dt>
<dd>Number of components, if n_components is not set all features
are kept.</dd>
<dt>init <span class="classifier-delimiter">:</span> <span class="classifier">‘random’ | ‘nndsvd’ |  ‘nndsvda’ | ‘nndsvdar’ | ‘custom’</span></dt>
<dd><p class="first">Method used to initialize the procedure.
Default: ‘nndsvd’ if n_components &lt; n_features, otherwise random.
Valid options:</p>
<ul class="last simple">
<li><dl class="first docutils">
<dt>‘random’: non-negative random matrices, scaled with:</dt>
<dd>sqrt(X.mean() / n_components)</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘nndsvd’: Nonnegative Double Singular Value Decomposition (NNDSVD)</dt>
<dd>initialization (better for sparseness)</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘nndsvda’: NNDSVD with zeros filled with the average of X</dt>
<dd>(better when sparsity is not desired)</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘nndsvdar’: NNDSVD with zeros filled with small random values</dt>
<dd>(generally faster, less accurate alternative to NNDSVDa
for when sparsity is not desired)</dd>
</dl>
</li>
<li>‘custom’: use custom matrices W and H</li>
</ul>
</dd>
<dt>solver <span class="classifier-delimiter">:</span> <span class="classifier">‘cd’ | ‘mu’</span></dt>
<dd><p class="first">Numerical solver to use:
‘cd’ is a Coordinate Descent solver.
‘mu’ is a Multiplicative Update solver.</p>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.17: </span>Coordinate Descent solver.</p>
</div>
<div class="last versionadded">
<p><span class="versionmodified">New in version 0.19: </span>Multiplicative Update solver.</p>
</div>
</dd>
<dt>beta_loss <span class="classifier-delimiter">:</span> <span class="classifier">float or string, default ‘frobenius’</span></dt>
<dd><p class="first">String must be in {‘frobenius’, ‘kullback-leibler’, ‘itakura-saito’}.
Beta divergence to be minimized, measuring the distance between X
and the dot product WH. Note that values different from ‘frobenius’
(or 2) and ‘kullback-leibler’ (or 1) lead to significantly slower
fits. Note that for beta_loss &lt;= 0 (or ‘itakura-saito’), the input
matrix X cannot contain zeros. Used only in ‘mu’ solver.</p>
<div class="last versionadded">
<p><span class="versionmodified">New in version 0.19.</span></p>
</div>
</dd>
<dt>tol <span class="classifier-delimiter">:</span> <span class="classifier">float, default: 1e-4</span></dt>
<dd>Tolerance of the stopping condition.</dd>
<dt>max_iter <span class="classifier-delimiter">:</span> <span class="classifier">integer, default: 200</span></dt>
<dd>Maximum number of iterations before timing out.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional, default: None</span></dt>
<dd>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</dd>
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">double, default: 0.</span></dt>
<dd><p class="first">Constant that multiplies the regularization terms. Set it to zero to
have no regularization.</p>
<div class="last versionadded">
<p><span class="versionmodified">New in version 0.17: </span><em>alpha</em> used in the Coordinate Descent solver.</p>
</div>
</dd>
<dt>l1_ratio <span class="classifier-delimiter">:</span> <span class="classifier">double, default: 0.</span></dt>
<dd><p class="first">The regularization mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.
For l1_ratio = 0 the penalty is an elementwise L2 penalty
(aka Frobenius Norm).
For l1_ratio = 1 it is an elementwise L1 penalty.
For 0 &lt; l1_ratio &lt; 1, the penalty is a combination of L1 and L2.</p>
<div class="last versionadded">
<p><span class="versionmodified">New in version 0.17: </span>Regularization parameter <em>l1_ratio</em> used in the Coordinate Descent
solver.</p>
</div>
</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">bool, default=False</span></dt>
<dd>Whether to be verbose.</dd>
<dt>shuffle <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default: False</span></dt>
<dd><p class="first">If true, randomize the order of coordinates in the CD solver.</p>
<div class="last versionadded">
<p><span class="versionmodified">New in version 0.17: </span><em>shuffle</em> parameter used in the Coordinate Descent solver.</p>
</div>
</dd>
</dl>
<dl class="docutils">
<dt><a href="#id1"><span class="problematic" id="id2">components_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array, [n_components, n_features]</span></dt>
<dd>Factorization matrix, sometimes called ‘dictionary’.</dd>
<dt><a href="#id3"><span class="problematic" id="id4">reconstruction_err_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">number</span></dt>
<dd>Frobenius norm of the matrix difference, or beta-divergence, between
the training data <code class="docutils literal"><span class="pre">X</span></code> and the reconstructed data <code class="docutils literal"><span class="pre">WH</span></code> from
the fitted model.</dd>
<dt><a href="#id5"><span class="problematic" id="id6">n_iter_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Actual number of iterations.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="k">import</span> <span class="n">NMF</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">W</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">components_</span>
</pre></div>
</div>
<p>Cichocki, Andrzej, and P. H. A. N. Anh-Huy. “Fast local algorithms for
large scale nonnegative matrix and tensor factorizations.”
IEICE transactions on fundamentals of electronics, communications and
computer sciences 92.3: 708-721, 2009.</p>
<p>Fevotte, C., &amp; Idier, J. (2011). Algorithms for nonnegative matrix
factorization with the beta-divergence. Neural Computation, 23(9).</p>
</div></blockquote>
<dl class="method">
<dt id="ibex.sklearn.decomposition.NMF.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>**params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/decomposition/nmf.html#NMF.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.decomposition.NMF.fit" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Learn a NMF model for the data X.</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape (n_samples, n_features)</span></dt>
<dd>Data matrix to be decomposed</dd>
</dl>
<p>self</p>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.decomposition.NMF.fit_transform">
<code class="descname">fit_transform</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>W=None</em>, <em>H=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/decomposition/nmf.html#NMF.fit_transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.decomposition.NMF.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Learn a NMF model for the data X and returns the transformed data.</p>
<blockquote>
<div><p>This is more efficient than calling fit followed by transform.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape (n_samples, n_features)</span></dt>
<dd>Data matrix to be decomposed</dd>
<dt>W <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (n_samples, n_components)</span></dt>
<dd>If init=’custom’, it is used as initial guess for the solution.</dd>
<dt>H <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (n_components, n_features)</span></dt>
<dd>If init=’custom’, it is used as initial guess for the solution.</dd>
</dl>
<dl class="docutils">
<dt>W <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_samples, n_components)</span></dt>
<dd>Transformed data.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.decomposition.NMF.inverse_transform">
<code class="descname">inverse_transform</code><span class="sig-paren">(</span><em>W</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/decomposition/nmf.html#NMF.inverse_transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.decomposition.NMF.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Transform data back to its original space.</p>
<blockquote>
<div><dl class="docutils">
<dt>W <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape (n_samples, n_components)</span></dt>
<dd>Transformed data matrix</dd>
</dl>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape (n_samples, n_features)</span></dt>
<dd>Data matrix of original shape</dd>
</dl>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.18.</span></p>
</div>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.decomposition.NMF.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/decomposition/nmf.html#NMF.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.decomposition.NMF.transform" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Transform the data X according to the fitted NMF model</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape (n_samples, n_features)</span></dt>
<dd>Data matrix to be transformed by the model</dd>
</dl>
<dl class="docutils">
<dt>W <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_samples, n_components)</span></dt>
<dd>Transformed data</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.jpeg" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Ibex</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="frame_adapter.html">Adapting Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="input_verification_and_output_processing.html">Verification and Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_transformer.html">Transforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipelines.html">Pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_union.html">Uniting Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="sklearn.html"><code class="docutils literal"><span class="pre">sklearn</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorflow.html"><code class="docutils literal"><span class="pre">tensorflow</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost.html"><code class="docutils literal"><span class="pre">xgboost</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="extending.html">Extending</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/api_ibex_sklearn_decomposition_nmf.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Ami Tavory, Shahar Azulay, Tali Raveh-Sadka.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/api_ibex_sklearn_decomposition_nmf.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/atavory/ibex" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>