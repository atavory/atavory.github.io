
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>RandomTreesEmbedding &#8212; ibex latest documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     'latest',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/logo.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="randomtreesembedding">
<h1><code class="docutils literal"><span class="pre">RandomTreesEmbedding</span></code><a class="headerlink" href="#randomtreesembedding" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="ibex.sklearn.ensemble.RandomTreesEmbedding">
<em class="property">class </em><code class="descclassname">ibex.sklearn.ensemble.</code><code class="descname">RandomTreesEmbedding</code><span class="sig-paren">(</span><em>n_estimators=10</em>, <em>max_depth=5</em>, <em>min_samples_split=2</em>, <em>min_samples_leaf=1</em>, <em>min_weight_fraction_leaf=0.0</em>, <em>max_leaf_nodes=None</em>, <em>min_impurity_decrease=0.0</em>, <em>min_impurity_split=None</em>, <em>sparse_output=True</em>, <em>n_jobs=1</em>, <em>random_state=None</em>, <em>verbose=0</em>, <em>warm_start=False</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.ensemble.RandomTreesEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.ensemble.forest.RandomTreesEmbedding</span></code>, <code class="xref py py-class docutils literal"><span class="pre">ibex._base.FrameMixin</span></code></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. This class wraps the attribute <code class="docutils literal"><span class="pre">feature_importances_</span></code>
Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ibex.sklearn</span> <span class="k">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ibex.sklearn.ensemble</span> <span class="k">import</span> <span class="n">RandomForestClassifier</span> <span class="k">as</span> <span class="n">PdRandomForestClassifier</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">features</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">iris</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">],</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]],</span>
<span class="gp">... </span>    <span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="o">+</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="go">sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)</span>
<span class="go">0                5.1               3.5                1.4               0.2</span>
<span class="go">1                4.9               3.0                1.4               0.2</span>
<span class="go">2                4.7               3.2                1.3               0.2</span>
<span class="go">3                4.6               3.1                1.5               0.2</span>
<span class="go">4                5.0               3.6                1.4               0.2</span>
<span class="gp">...</span>
</pre></div>
</div>
<div class="last highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span>  <span class="n">PdRandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="go">sepal length (cm)    0.129268</span>
<span class="go">sepal width (cm)     0.015822</span>
<span class="go">petal length (cm)    0.444740</span>
<span class="go">petal width (cm)     0.410169</span>
<span class="go">dtype: float64</span>
</pre></div>
</div>
</div>
<p>An ensemble of totally random trees.</p>
<blockquote>
<div><p>An unsupervised transformation of a dataset to a high-dimensional
sparse representation. A datapoint is coded according to which leaf of
each tree it is sorted into. Using a one-hot encoding of the leaves,
this leads to a binary coding with as many ones as there are trees in
the forest.</p>
<p>The dimensionality of the resulting representation is
<code class="docutils literal"><span class="pre">n_out</span> <span class="pre">&lt;=</span> <span class="pre">n_estimators</span> <span class="pre">*</span> <span class="pre">max_leaf_nodes</span></code>. If <code class="docutils literal"><span class="pre">max_leaf_nodes</span> <span class="pre">==</span> <span class="pre">None</span></code>,
the number of leaf nodes is at most <code class="docutils literal"><span class="pre">n_estimators</span> <span class="pre">*</span> <span class="pre">2</span> <span class="pre">**</span> <span class="pre">max_depth</span></code>.</p>
<p>Read more in the <a class="reference external" href="http://scikit-learn.org/stable/modules/ensemble.html#random-trees-embedding" title="(in scikit-learn v0.19.1)"><span class="xref std std-ref">User Guide</span></a>.</p>
<dl class="docutils">
<dt>n_estimators <span class="classifier-delimiter">:</span> <span class="classifier">integer, optional (default=10)</span></dt>
<dd>Number of trees in the forest.</dd>
<dt>max_depth <span class="classifier-delimiter">:</span> <span class="classifier">integer, optional (default=5)</span></dt>
<dd>The maximum depth of each tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</dd>
<dt>min_samples_split <span class="classifier-delimiter">:</span> <span class="classifier">int, float, optional (default=2)</span></dt>
<dd><p class="first">The minimum number of samples required to split an internal node:</p>
<ul class="simple">
<li>If int, then consider <cite>min_samples_split</cite> as the minimum number.</li>
<li>If float, then <cite>min_samples_split</cite> is a percentage and
<cite>ceil(min_samples_split * n_samples)</cite> is the minimum
number of samples for each split.</li>
</ul>
<div class="last versionchanged">
<p><span class="versionmodified">Changed in version 0.18: </span>Added float values for percentages.</p>
</div>
</dd>
<dt>min_samples_leaf <span class="classifier-delimiter">:</span> <span class="classifier">int, float, optional (default=1)</span></dt>
<dd><p class="first">The minimum number of samples required to be at a leaf node:</p>
<ul class="simple">
<li>If int, then consider <cite>min_samples_leaf</cite> as the minimum number.</li>
<li>If float, then <cite>min_samples_leaf</cite> is a percentage and
<cite>ceil(min_samples_leaf * n_samples)</cite> is the minimum
number of samples for each node.</li>
</ul>
<div class="last versionchanged">
<p><span class="versionmodified">Changed in version 0.18: </span>Added float values for percentages.</p>
</div>
</dd>
<dt>min_weight_fraction_leaf <span class="classifier-delimiter">:</span> <span class="classifier">float, optional (default=0.)</span></dt>
<dd>The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</dd>
<dt>max_leaf_nodes <span class="classifier-delimiter">:</span> <span class="classifier">int or None, optional (default=None)</span></dt>
<dd>Grow trees with <code class="docutils literal"><span class="pre">max_leaf_nodes</span></code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</dd>
<dt>min_impurity_split <span class="classifier-delimiter">:</span> <span class="classifier">float,</span></dt>
<dd><p class="first">Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<div class="last deprecated">
<p><span class="versionmodified">Deprecated since version 0.19: </span><code class="docutils literal"><span class="pre">min_impurity_split</span></code> has been deprecated in favor of
<code class="docutils literal"><span class="pre">min_impurity_decrease</span></code> in 0.19 and will be removed in 0.21.
Use <code class="docutils literal"><span class="pre">min_impurity_decrease</span></code> instead.</p>
</div>
</dd>
<dt>min_impurity_decrease <span class="classifier-delimiter">:</span> <span class="classifier">float, optional (default=0.)</span></dt>
<dd><p class="first">A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">N_t</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">impurity</span> <span class="o">-</span> <span class="n">N_t_R</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">right_impurity</span>
                    <span class="o">-</span> <span class="n">N_t_L</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">left_impurity</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal"><span class="pre">N</span></code> is the total number of samples, <code class="docutils literal"><span class="pre">N_t</span></code> is the number of
samples at the current node, <code class="docutils literal"><span class="pre">N_t_L</span></code> is the number of samples in the
left child, and <code class="docutils literal"><span class="pre">N_t_R</span></code> is the number of samples in the right child.</p>
<p><code class="docutils literal"><span class="pre">N</span></code>, <code class="docutils literal"><span class="pre">N_t</span></code>, <code class="docutils literal"><span class="pre">N_t_R</span></code> and <code class="docutils literal"><span class="pre">N_t_L</span></code> all refer to the weighted sum,
if <code class="docutils literal"><span class="pre">sample_weight</span></code> is passed.</p>
<div class="last versionadded">
<p><span class="versionmodified">New in version 0.19.</span></p>
</div>
</dd>
<dt>bootstrap <span class="classifier-delimiter">:</span> <span class="classifier">boolean, optional (default=True)</span></dt>
<dd>Whether bootstrap samples are used when building trees.</dd>
<dt>sparse_output <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional (default=True)</span></dt>
<dd>Whether or not to return a sparse CSR matrix, as default behavior,
or to return a dense array compatible with dense pipeline operators.</dd>
<dt>n_jobs <span class="classifier-delimiter">:</span> <span class="classifier">integer, optional (default=1)</span></dt>
<dd>The number of jobs to run in parallel for both <cite>fit</cite> and <cite>predict</cite>.
If -1, then the number of jobs is set to the number of cores.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional (default=None)</span></dt>
<dd>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">int, optional (default=0)</span></dt>
<dd>Controls the verbosity of the tree building process.</dd>
<dt>warm_start <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional (default=False)</span></dt>
<dd>When set to <code class="docutils literal"><span class="pre">True</span></code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id3"><span class="problematic" id="id4">estimators_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">list of DecisionTreeClassifier</span></dt>
<dd>The collection of fitted sub-estimators.</dd>
</dl>
<table class="docutils footnote" frame="void" id="id1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td>P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”,
Machine Learning, 63(1), 3-42, 2006.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td>Moosmann, F. and Triggs, B. and Jurie, F.  “Fast discriminative
visual codebooks using randomized clustering forests”
NIPS 2007</td></tr>
</tbody>
</table>
</div></blockquote>
<dl class="method">
<dt id="ibex.sklearn.ensemble.RandomTreesEmbedding.apply">
<code class="descname">apply</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#ibex.sklearn.ensemble.RandomTreesEmbedding.apply" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Apply trees in the forest to X, return leaf indices.</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like or sparse matrix, shape = [n_samples, n_features]</span></dt>
<dd>The input samples. Internally, its dtype will be converted to
<code class="docutils literal"><span class="pre">dtype=np.float32</span></code>. If a sparse matrix is provided, it will be
converted into a sparse <code class="docutils literal"><span class="pre">csr_matrix</span></code>.</dd>
</dl>
<dl class="docutils">
<dt>X_leaves <span class="classifier-delimiter">:</span> <span class="classifier">array_like, shape = [n_samples, n_estimators]</span></dt>
<dd>For each datapoint x in X and for each tree in the forest,
return the index of the leaf x ends up in.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.ensemble.RandomTreesEmbedding.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/ensemble/forest.html#RandomTreesEmbedding.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.ensemble.RandomTreesEmbedding.fit" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Fit estimator.</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like or sparse matrix, shape=(n_samples, n_features)</span></dt>
<dd>The input samples. Use <code class="docutils literal"><span class="pre">dtype=np.float32</span></code> for maximum
efficiency. Sparse matrices are also supported, use sparse
<code class="docutils literal"><span class="pre">csc_matrix</span></code> for maximum efficiency.</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples] or None</span></dt>
<dd>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</dd>
</dl>
<dl class="docutils">
<dt>self <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd>Returns self.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.ensemble.RandomTreesEmbedding.fit_transform">
<code class="descname">fit_transform</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/ensemble/forest.html#RandomTreesEmbedding.fit_transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.ensemble.RandomTreesEmbedding.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Fit estimator and transform dataset.</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like or sparse matrix, shape=(n_samples, n_features)</span></dt>
<dd>Input data used to build forests. Use <code class="docutils literal"><span class="pre">dtype=np.float32</span></code> for
maximum efficiency.</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples] or None</span></dt>
<dd>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</dd>
</dl>
<dl class="docutils">
<dt>X_transformed <span class="classifier-delimiter">:</span> <span class="classifier">sparse matrix, shape=(n_samples, n_out)</span></dt>
<dd>Transformed dataset.</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="ibex.sklearn.ensemble.RandomTreesEmbedding.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sklearn/ensemble/forest.html#RandomTreesEmbedding.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ibex.sklearn.ensemble.RandomTreesEmbedding.transform" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The documentation following is of the class wrapped by this class. There
are some changes, in particular:</p>
<blockquote class="last">
<div><ul class="simple">
<li>A parameter <code class="docutils literal"><span class="pre">X</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.DataFrame</span></code></a>.</li>
<li>A parameter <code class="docutils literal"><span class="pre">y</span></code> denotes a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series" title="(in pandas v0.21.0)"><code class="xref py py-class docutils literal"><span class="pre">pandas.Series</span></code></a>.</li>
</ul>
</div></blockquote>
</div>
<p>Transform dataset.</p>
<blockquote>
<div><dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like or sparse matrix, shape=(n_samples, n_features)</span></dt>
<dd>Input data to be transformed. Use <code class="docutils literal"><span class="pre">dtype=np.float32</span></code> for maximum
efficiency. Sparse matrices are also supported, use sparse
<code class="docutils literal"><span class="pre">csr_matrix</span></code> for maximum efficiency.</dd>
</dl>
<dl class="docutils">
<dt>X_transformed <span class="classifier-delimiter">:</span> <span class="classifier">sparse matrix, shape=(n_samples, n_out)</span></dt>
<dd>Transformed dataset.</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.jpeg" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Ibex</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="frame_adapter.html">Adapting Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="input_verification_and_output_processing.html">Verification and Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_transformer.html">Transforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipelines.html">Pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_union.html">Uniting Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="sklearn.html"><code class="docutils literal"><span class="pre">sklearn</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorflow.html"><code class="docutils literal"><span class="pre">tensorflow</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost.html"><code class="docutils literal"><span class="pre">xgboost</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="extending.html">Extending</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/api_ibex_sklearn_ensemble_randomtreesembedding.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Ami Tavory, Shahar Azulay, Tali Raveh-Sadka.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/api_ibex_sklearn_ensemble_randomtreesembedding.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/atavory/ibex" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>